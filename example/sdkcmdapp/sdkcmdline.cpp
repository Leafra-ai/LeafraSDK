#include "leafra/leafra_core.h"
#include "leafra/leafra_chunker.h"
#include "leafra/types.h"
#include <iostream>
#include <fstream>
#include <string>
#include <vector>
#include <sstream>

using namespace leafra;

/**
 * LeafraSDK Command Line Application
 * 
 * End-to-end testing and development tool for the LeafraSDK.
 * This application provides command line access to test the complete SDK 
 * functionality including document parsing, chunking, and processing.
 * 
 * Usage:
 *   ./sdkcmdline                    - Process internal sample document
 *   ./sdkcmdline file1.txt          - Process single file
 *   ./sdkcmdline file1.pdf file2.txt - Process multiple files
 * 
 * Supported Platforms: macOS, Linux, Windows
 * Not supported: iOS, Android (command line tool for development)
 */

void print_separator(const std::string& title) {
    std::cout << "\n" << std::string(60, '=') << std::endl;
    std::cout << "  " << title << std::endl;
    std::cout << std::string(60, '=') << std::endl;
}

void print_usage(const char* program_name) {
    std::cout << "\nUsage: " << program_name << " [options] [file1] [file2] ... [fileN]" << std::endl;
    std::cout << "\nOptions:" << std::endl;
    std::cout << "  No arguments              - Process internal sample document (demo mode)" << std::endl;
    std::cout << "  file1 file2...            - Process one or more user files" << std::endl;
    std::cout << "  -h, --help                - Show this help message" << std::endl;
    std::cout << "  --print_chunks_full       - Print full content of all chunks" << std::endl;
    std::cout << "  --print_chunks_brief N    - Print first N lines of each chunk" << std::endl;
    std::cout << "  --semantic_search \"query\" [max_results] - Perform semantic search (default: 5 results)" << std::endl;
    std::cout << "\nSupported file types:" << std::endl;
    std::cout << "  â€¢ Text files (.txt)" << std::endl;
    std::cout << "  â€¢ PDF files (.pdf)" << std::endl;
    std::cout << "  â€¢ Word documents (.docx)" << std::endl;
    std::cout << "  â€¢ Excel files (.xlsx)" << std::endl;
    std::cout << "\nExamples:" << std::endl;
    std::cout << "  " << program_name << "                              # Demo mode with sample document" << std::endl;
    std::cout << "  " << program_name << " document.pdf                 # Process single PDF" << std::endl;
    std::cout << "  " << program_name << " file1.txt file2.pdf          # Process multiple files" << std::endl;
    std::cout << "  " << program_name << " --print_chunks_full doc.txt  # Process and show full chunks" << std::endl;
    std::cout << "  " << program_name << " --print_chunks_brief 3 doc.txt # Process and show first 3 lines of each chunk" << std::endl;
    std::cout << "  " << program_name << " --semantic_search \"machine learning\"     # Search indexed content (5 results)" << std::endl;
    std::cout << "  " << program_name << " --semantic_search \"AI technology\" 10  # Search with 10 results" << std::endl;
}

void create_sample_text_file(const std::string& filename) {
    std::ofstream file(filename);
    
    // Check if file opened successfully
    if (!file.is_open()) {
        std::cerr << "âŒ Error: Could not create sample file: " << filename << std::endl;
        std::cerr << "   Check permissions and disk space" << std::endl;
        return;
    }
    
    std::cout << "ðŸ“ Creating sample text file: " << filename << std::endl;
    
    file << "ðŸŒ International Document Chunking Test ðŸ“\n\n";
    
    file << "This is a comprehensive UTF-8 document designed to test the chunking system's ";
    file << "ability to handle diverse character encodings and international text. ";
    file << "The SentencePiece tokenizer should properly process all these characters. ";
    file << "Each chunk will be token-aware and respect Unicode word boundaries. ðŸ”¤\n\n";
    
    file << "ðŸ“Š Languages & Scripts:\n";
    file << "â€¢ English: Hello World! How are you today?\n";
    file << "â€¢ French: Bonjour le monde! Comment allez-vous? CafÃ©, rÃ©sumÃ©, naÃ¯ve, NoÃ«l\n";
    file << "â€¢ German: Hallo Welt! Wie geht es Ihnen? StraÃŸe, MÃ¼nchen, GrÃ¶ÃŸe, WeiÃŸ\n";
    file << "â€¢ Spanish: Â¡Hola mundo! Â¿CÃ³mo estÃ¡ usted? NiÃ±o, seÃ±or, maÃ±ana, corazÃ³n\n";
    file << "â€¢ Russian: ÐŸÑ€Ð¸Ð²ÐµÑ‚ Ð¼Ð¸Ñ€! ÐšÐ°Ðº Ð´ÐµÐ»Ð°? ÐœÐ¾ÑÐºÐ²Ð°, Ð Ð¾ÑÑÐ¸Ñ, Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ\n";
    file << "â€¢ Japanese: ã“ã‚“ã«ã¡ã¯ä¸–ç•Œï¼å…ƒæ°—ã§ã™ã‹ï¼Ÿæ±äº¬ã€æ—¥æœ¬ã€æƒ…å ±\n";
    file << "â€¢ Chinese: ä½ å¥½ä¸–ç•Œï¼ä½ å¥½å—ï¼ŸåŒ—äº¬ï¼Œä¸­å›½ï¼Œä¿¡æ¯\n";
    file << "â€¢ Arabic: Ù…Ø±Ø­Ø¨Ø§ Ø¨Ø§Ù„Ø¹Ø§Ù„Ù…! ÙƒÙŠÙ Ø­Ø§Ù„ÙƒØŸ Ù…Ø¹Ù„ÙˆÙ…Ø§ØªØŒ ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§\n\n";
    
    file << "ðŸ”£ Special Characters & Symbols:\n";
    file << "Mathematical: âˆ‘ âˆ âˆ« âˆš âˆž â‰ˆ â‰  â‰¤ â‰¥ Â± Ã— Ã· Ï€ Î± Î² Î³ Î´ Î» Î¼ Ïƒ Ï† Ïˆ Ï‰\n";
    file << "Currency: $ â‚¬ Â£ Â¥ â‚¹ â‚½ â‚© â‚ª Â¢ â‚µ â‚¡ â‚¦ â‚¨ â‚« â‚± â‚²\n";
    file << "Arrows: â† â†’ â†‘ â†“ â†– â†— â†˜ â†™ â‡ â‡’ â‡‘ â‡“ â†” â†• â‡” â‡•\n";
    file << "Shapes: â–² â–¼ â—„ â–º â—† â—‡ â–  â–¡ â— â—‹ â˜… â˜† â™  â™£ â™¥ â™¦\n";
    file << "Weather: â˜€ â˜ â˜‚ â˜ƒ â„ â›… â›ˆ ðŸŒˆ ðŸŒ™ â­\n";
    file << "Emojis: ðŸ˜€ ðŸ˜ƒ ðŸ˜„ ðŸ˜ ðŸ˜† ðŸ˜… ðŸ˜‚ ðŸ¤£ ðŸ˜Š ðŸ˜‡ ðŸ™‚ ðŸ™ƒ ðŸ˜‰ ðŸ˜Œ ðŸ˜ ðŸ¥° ðŸ˜˜ ðŸ˜—\n\n";
    
    file << "ðŸ“ Technical Content:\n";
    file << "This document demonstrates how the LeafraSDK chunking system handles UTF-8 ";
    file << "encoded text with various character sets. The token estimation should accurately ";
    file << "count tokens across different languages and scripts. Character boundaries must ";
    file << "be preserved properly, especially for multi-byte UTF-8 sequences.\n\n";
    
    file << "ðŸ”§ Configuration Details:\n";
    file << "â€¢ Token-based chunking with SentencePiece integration âœ…\n";
    file << "â€¢ Word boundary preservation for international text ðŸŒ\n";
    file << "â€¢ Overlap percentage handling across language transitions ðŸ”„\n";
    file << "â€¢ Metadata extraction from multilingual documents ðŸ“‹\n";
    file << "â€¢ Character encoding validation and normalization ðŸ”¤\n\n";
    
    file << "ðŸŽ¯ Test Scenarios:\n";
    file << "1. Mixed language paragraphs with transitions between scripts\n";
    file << "2. Special character sequences that might affect tokenization\n";
    file << "3. Emoji and symbol placement within sentences ðŸ“±\n";
    file << "4. Mathematical expressions: E = mcÂ² âˆ´ F = ma âˆµ aÂ² + bÂ² = cÂ²\n";
    file << "5. Code snippets: function(Ï€, Î±) { return âˆš(xÂ² + yÂ²); } // UTF-8 vars\n";
    file << "6. URLs with Unicode: https://æµ‹è¯•.example.com/è·¯å¾„?å‚æ•°=å€¼\n";
    file << "7. Email addresses: uÅ¼ytkownik@Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ñƒ.Ñ€Ñ„, Ñ‚ÐµÑÑ‚@Ù…Ø«Ø§Ù„.ÙƒÙˆÙ…\n\n";
    
    file << "ðŸ“š Extended Content for Chunking:\n";
    file << "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor ";
    file << "incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis ";
    file << "nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. ";
    file << "Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore ";
    file << "eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, ";
    file << "sunt in culpa qui officia deserunt mollit anim id est laborum.\n\n";
    
    file << "Ã‘oÃ±o pequeÃ±o soÃ±Ã³ con niÃ±os en EspaÃ±a. El seÃ±or GarcÃ­a visitÃ³ SÃ£o Paulo ";
    file << "para encontrar informaciÃ³n sobre tecnologÃ­a avanzada. Les rÃ©sumÃ©s franÃ§ais ";
    file << "contiennent des caractÃ¨res accentuÃ©s comme Ã©, Ã¨, Ãª, Ã«, Ã , Ã¹, Ã§. Deutsche ";
    file << "StraÃŸennamen enthalten oft Umlaute: MÃ¼nchen, KÃ¶ln, DÃ¼sseldorf, GrÃ¶ÃŸe.\n\n";
    
    file << "ðŸŒ Conclusion:\n";
    file << "This UTF-8 test document validates that the LeafraSDK chunking system properly ";
    file << "handles international character sets, maintains character encoding integrity, ";
    file << "and produces accurate token counts across diverse linguistic content. The ";
    file << "SentencePiece integration should seamlessly process all included characters ";
    file << "while preserving semantic boundaries. Success! âœ¨ðŸŽ‰\n";
    
    file.close();
    
    // Verify file was actually created and has content
    std::ifstream verify_file(filename);
    if (verify_file.is_open()) {
        verify_file.seekg(0, std::ios::end);
        std::streamsize size = verify_file.tellg();
        verify_file.close();
        
        std::cout << "âœ… Sample file created successfully: " << filename 
                  << " (" << size << " bytes)" << std::endl;
    } else {
        std::cerr << "âŒ Failed to create sample file: " << filename << std::endl;
        std::cerr << "   File does not exist after creation attempt" << std::endl;
    }
}

bool file_exists(const std::string& filename) {
    std::ifstream file(filename);
    return file.good();
}

int main(int argc, char* argv[]) {
    print_separator("LeafraSDK Command Line Application");
    
    // Parse command line arguments
    std::vector<std::string> input_files;
    bool demo_mode = true;
    bool print_chunks_full = false;
    bool print_chunks_brief = false;
    int max_lines = 0;
    bool semantic_search_mode = false;
    std::string search_query;
    int max_results = 5;
    
    // Parse arguments
    for (int i = 1; i < argc; i++) {
        std::string arg = argv[i];
        
        if (arg == "-h" || arg == "--help" || arg == "help") {
            print_usage(argv[0]);
            return 0;
        } else if (arg == "--print_chunks_full") {
            print_chunks_full = true;
        } else if (arg == "--print_chunks_brief") {
            print_chunks_brief = true;
            // Next argument should be the max_lines number
            if (i + 1 < argc) {
                i++; // Move to next argument
                try {
                    max_lines = std::stoi(argv[i]);
                    if (max_lines <= 0) {
                        std::cerr << "âŒ Error: max_lines must be a positive number" << std::endl;
                        return 1;
                    }
                } catch (const std::exception& e) {
                    std::cerr << "âŒ Error: Invalid number for max_lines: " << argv[i] << std::endl;
                    return 1;
                }
            } else {
                std::cerr << "âŒ Error: --print_chunks_brief requires a number argument" << std::endl;
                return 1;
            }
        } else if (arg == "--semantic_search") {
            semantic_search_mode = true;
            demo_mode = false;
            // Next argument should be the search query
            if (i + 1 < argc) {
                i++; // Move to next argument
                search_query = argv[i];
                if (search_query.empty()) {
                    std::cerr << "âŒ Error: Search query cannot be empty" << std::endl;
                    return 1;
                }
                // Check if there's an optional max_results parameter
                if (i + 1 < argc) {
                    std::string next_arg = argv[i + 1];
                    // Check if next argument is a number (not starting with -)
                    if (!next_arg.empty() && next_arg[0] != '-' && std::isdigit(next_arg[0])) {
                        i++; // Move to next argument
                        try {
                            max_results = std::stoi(next_arg);
                            if (max_results <= 0) {
                                std::cerr << "âŒ Error: max_results must be a positive number" << std::endl;
                                return 1;
                            }
                        } catch (const std::exception& e) {
                            std::cerr << "âŒ Error: Invalid number for max_results: " << next_arg << std::endl;
                            return 1;
                        }
                    }
                }
            } else {
                std::cerr << "âŒ Error: --semantic_search requires a query string argument" << std::endl;
                return 1;
            }
        } else {
            // It's a file argument
            if (file_exists(arg)) {
                input_files.push_back(arg);
                demo_mode = false;
            } else {
                std::cerr << "âš ï¸  Warning: File not found: " << arg << std::endl;
            }
        }
    }
    
    if (input_files.empty() && !demo_mode && !semantic_search_mode) {
        std::cerr << "âŒ Error: No valid files found!" << std::endl;
        print_usage(argv[0]);
        return 1;
    }
    
    try {
        std::string sample_file = "sample_document.txt";
        
        // Setup files to process
        if (demo_mode) {
            // Create sample file for demo
            create_sample_text_file(sample_file);
            input_files.push_back(sample_file);
            std::cout << "ðŸ“„ Demo Mode: Created sample document: " << sample_file << std::endl;
        } else if (semantic_search_mode) {
            // Semantic search mode - no files needed, searches indexed content
            std::cout << "ðŸ” Semantic Search Mode: Searching indexed content" << std::endl;
            std::cout << "ðŸ”Ž Query: \"" << search_query << "\"" << std::endl;
            std::cout << "ðŸ“Š Max Results: " << max_results << std::endl;
        } else {
            // User provided files
            std::cout << "ðŸ“ User Files Mode: Processing " << input_files.size() << " file(s)" << std::endl;
            for (size_t i = 0; i < input_files.size(); i++) {
                std::cout << "  " << (i + 1) << ". " << input_files[i] << std::endl;
            }
        }
        
        // Create LeafraSDK instance
        auto sdk = LeafraCore::create();
        
        // Configure the SDK with chunking enabled
        Config config;
        config.name = "LeafraSDK-CLI";
        config.version = "1.0.0";
        config.debug_mode = true;  // Enable detailed logging for development
        
        // Configure chunking settings for testing
        config.chunking.enabled = true;
        config.chunking.chunk_size = 500;  // 500 tokens per chunk
        config.chunking.overlap_percentage = 0.2;  // 20% overlap
        config.chunking.size_unit = ChunkSizeUnit::TOKENS;
        config.chunking.token_method = TokenApproximationMethod::SIMPLE;
        config.chunking.preserve_word_boundaries = true;
        config.chunking.include_metadata = true;
        
        // Configure SentencePiece tokenization (optional - will fallback if model not found)
        config.tokenizer.enable_sentencepiece = true;
        
        //TODO AD: change this to model path like we do for the embedding_inference.model_path
        config.tokenizer.model_name = "multilingual-e5-small"; // Model name corresponds to folder in models/
        
        // Resolve the model path from the model name
        bool model_found = config.tokenizer.resolve_model_path();
        if (model_found) {
            std::cout << "ðŸ“ Found SentencePiece model: " << config.tokenizer.model_name << std::endl;
            std::cout << "   Model file: " << config.tokenizer.sentencepiece_model_path << std::endl;
            if (!config.tokenizer.sentencepiece_json_path.empty()) {
                std::cout << "   Config file: " << config.tokenizer.sentencepiece_json_path << std::endl;
            } else {
                std::cout << "   Config file: not found (optional)" << std::endl;
            }
        } else {
            std::cout << "âš ï¸  SentencePiece model '" << config.tokenizer.model_name << "' not found" << std::endl;
            std::cout << "   Expected location: sdk/corecpp/third_party/models/embedding/" << config.tokenizer.model_name << "/sentencepiece.bpe.model" << std::endl;
            std::cout << "   Expected config: sdk/corecpp/third_party/models/embedding/" << config.tokenizer.model_name << "/tokenizer_config.json" << std::endl;
            std::cout << "   Using fallback: " << config.tokenizer.sentencepiece_model_path << std::endl;
        }
        
        // Set chunk printing options based on command line flags
        config.chunking.print_chunks_full = print_chunks_full;
        config.chunking.print_chunks_brief = print_chunks_brief;
        config.chunking.max_lines = max_lines;
        
        config.embedding_inference.enabled = true;
        config.embedding_inference.framework = "coreml";
        config.embedding_inference.model_path = std::string(LEAFRA_SDK_MODELS_ROOT) + "/embedding/generated_models/coreml/model.mlmodelc";
        config.vector_search.enabled = true;
        //AD TEMP
        //config.vector_search.index_type = "HNSW";
        config.vector_search.index_type = "FLAT";
        config.vector_search.metric = "COSINE";
        config.vector_search.dimension = 384;

        print_separator("SDK Configuration");
        std::cout << "Application: " << config.name << std::endl;
        std::cout << "Platform: Desktop (macOS/Linux/Windows)" << std::endl;
        std::cout << "Purpose: End-to-end SDK testing and development" << std::endl;
        std::cout << "Mode: " << (demo_mode ? "Demo (sample document)" : "User files") << std::endl;
        std::cout << "Files to process: " << input_files.size() << std::endl;
        std::cout << "Chunking Enabled: " << (config.chunking.enabled ? "Yes" : "No") << std::endl;
        std::cout << "Chunk Size: " << config.chunking.chunk_size << " tokens" << std::endl;
        std::cout << "Overlap: " << (config.chunking.overlap_percentage * 100) << "%" << std::endl;
        std::cout << "Token Method: Simple approximation" << std::endl;
        std::cout << "Preserve Word Boundaries: " << (config.chunking.preserve_word_boundaries ? "Yes" : "No") << std::endl;
        std::cout << "SentencePiece Enabled: " << (config.tokenizer.enable_sentencepiece ? "Yes" : "No") << std::endl;
        if (config.tokenizer.enable_sentencepiece && !config.tokenizer.sentencepiece_model_path.empty()) {
            std::cout << "SentencePiece Model: " << config.tokenizer.sentencepiece_model_path << std::endl;
        }
        std::cout << "Embedding Inference Enabled: " << (config.embedding_inference.enabled ? "Yes" : "No") << std::endl;
        std::cout << "Embedding Framework: " << config.embedding_inference.framework << std::endl;
        std::cout << "Embedding Model Path: " << config.embedding_inference.model_path << std::endl;
        
        
        // Set up event callback to monitor SDK operations
        std::vector<std::string> events;
        sdk->set_event_callback([&events](const std::string& event) {
            events.push_back(event);
            std::cout << "ðŸ“¢ Event: " << event << std::endl;
        });
        
        // Initialize SDK
        print_separator("SDK Initialization");
        ResultCode init_result = sdk->initialize(config);
        if (init_result != ResultCode::SUCCESS) {
            std::cerr << "âŒ Failed to initialize SDK!" << std::endl;
            return 1;
        }
        std::cout << "âœ… SDK initialized successfully!" << std::endl;
        std::cout << "ðŸ”§ Development mode: " << (config.debug_mode ? "Enabled" : "Disabled") << std::endl;
        
        // Handle semantic search mode
        if (semantic_search_mode) {
            print_separator("Semantic Search");
            std::cout << "ðŸ” Performing semantic search..." << std::endl;
            std::cout << "Query: \"" << search_query << "\"" << std::endl;
            std::cout << "Max Results: " << max_results << std::endl;
            
#ifdef LEAFRA_HAS_FAISS
            std::vector<FaissIndex::SearchResult> search_results;
            ResultCode search_result = sdk->semantic_search(search_query, max_results, search_results);
            
            if (search_result == ResultCode::SUCCESS) {
                std::cout << "\nâœ… Semantic search completed successfully!" << std::endl;
                std::cout << "ðŸ“Š Found " << search_results.size() << " results:" << std::endl;
                
                for (size_t i = 0; i < search_results.size(); i++) {
                    const auto& result = search_results[i];
                    std::cout << "\nðŸ” Result " << (i + 1) << ":" << std::endl;
                    std::cout << "   ðŸ“„ File: " << result.filename << std::endl;
                    std::cout << "   ðŸ“– Page: " << result.page_number << std::endl;
                    std::cout << "   ðŸ§© Chunk: " << result.chunk_index << std::endl;
                    std::cout << "   ðŸ“ Distance: " << result.distance << std::endl;
                    std::cout << "   ðŸ“ Content: " << std::endl;
                    
                    // Print content with proper formatting
                    std::string content = result.content;
                    if (content.length() > 200) {
                        content = content.substr(0, 200) + "...";
                    }
                    std::cout << "      " << content << std::endl;
                }
            } else {
                std::cout << "\nâŒ Semantic search failed!" << std::endl;
                std::cout << "   Make sure you have processed some documents first." << std::endl;
            }
#else
            std::cout << "âŒ FAISS support not compiled - semantic search unavailable" << std::endl;
#endif
            
            // Skip normal processing for semantic search mode
            print_separator("SDK Shutdown");
            std::cout << "Cleaning up resources..." << std::endl;
            sdk->shutdown();
            std::cout << "âœ… Cleanup completed" << std::endl;
            
            print_separator("Search Summary");
            std::cout << "âœ… Semantic search completed!" << std::endl;
            return 0;
        }
        
        // Process the files (end-to-end testing)
        print_separator("End-to-End Document Processing");
        if (demo_mode) {
            std::cout << "Processing sample file: " << sample_file << std::endl;
        } else {
            std::cout << "Processing " << input_files.size() << " user file(s):" << std::endl;
            for (const auto& file : input_files) {
                std::cout << "  â€¢ " << file << std::endl;
            }
        }
        std::cout << "Testing: Parsing â†’ Chunking â†’ Processing pipeline" << std::endl;
        
        ResultCode process_result = sdk->process_user_files(input_files);
        
        if (process_result == ResultCode::SUCCESS) {
            std::cout << "\nâœ… End-to-end processing completed successfully!" << std::endl;
        } else {
            std::cout << "\nâŒ End-to-end processing failed!" << std::endl;
        }
        
        // Display captured events
        print_separator("SDK Event Summary");
        std::cout << "Total events captured: " << events.size() << std::endl;
        
        // Filter and display important events
        std::cout << "\nKey processing events:" << std::endl;
        for (const auto& event : events) {
            if (event.find("chunk") != std::string::npos || 
                event.find("ðŸ§©") != std::string::npos || 
                event.find("ðŸ“Š") != std::string::npos ||
                event.find("ðŸ”—") != std::string::npos ||
                event.find("âœ…") != std::string::npos ||
                event.find("initialized") != std::string::npos) {
                std::cout << "  â€¢ " << event << std::endl;
            }
        }
        
        // Cleanup and shutdown
        print_separator("SDK Shutdown");
        std::cout << "Cleaning up resources..." << std::endl;
        sdk->shutdown();
        
        // Only remove sample file if we created it
        if (demo_mode) {
            std::remove(sample_file.c_str());
        }
        std::cout << "âœ… Cleanup completed" << std::endl;
        
        print_separator("Test Summary");
        std::cout << "âœ… LeafraSDK command line testing completed successfully!" << std::endl;
        std::cout << "ðŸ”§ This tool makes SDK development faster and more reliable." << std::endl;
        std::cout << "ðŸ“‹ All SDK components tested: Parsing, Chunking, Events, Configuration" << std::endl;
        std::cout << "ðŸ–¥ï¸  Platform: Desktop environments (macOS/Linux/Windows)" << std::endl;
        if (!demo_mode) {
            std::cout << "ðŸ“ Processed " << input_files.size() << " user file(s) successfully!" << std::endl;
        }
        
    } catch (const std::exception& e) {
        std::cerr << "âŒ Error: " << e.what() << std::endl;
        return 1;
    }
    
    return 0;
} 