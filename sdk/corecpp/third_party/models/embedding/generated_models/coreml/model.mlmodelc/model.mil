program(1.0)
[buildInfo = dict<tensor<string, []>, tensor<string, []>>({{"coremlc-component-MIL", "3402.3.2"}, {"coremlc-version", "3402.4.1"}, {"coremltools-component-torch", "2.7.0"}, {"coremltools-source-dialect", "TorchScript"}, {"coremltools-version", "8.2"}})]
{
    func main<ios15>(tensor<int32, [1, 512]> attention_mask, tensor<int32, [1, 512]> input_ids) {
            tensor<fp32, [250037, 384]> model_embeddings_word_embeddings_weight = const()[name = tensor<string, []>("model_embeddings_word_embeddings_weight"), val = tensor<fp32, [250037, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(64)))];
            tensor<fp32, [384]> model_embeddings_LayerNorm_bias = const()[name = tensor<string, []>("model_embeddings_LayerNorm_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(384056960)))];
            tensor<fp32, [384]> model_embeddings_LayerNorm_weight = const()[name = tensor<string, []>("model_embeddings_LayerNorm_weight"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(384058560)))];
            tensor<fp32, [384]> model_encoder_layer_0_attention_self_query_bias = const()[name = tensor<string, []>("model_encoder_layer_0_attention_self_query_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(384060160)))];
            tensor<fp32, [384, 384]> model_encoder_layer_0_attention_self_query_weight = const()[name = tensor<string, []>("model_encoder_layer_0_attention_self_query_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(384061760)))];
            tensor<fp32, [384]> model_encoder_layer_0_attention_self_key_bias = const()[name = tensor<string, []>("model_encoder_layer_0_attention_self_key_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(384651648)))];
            tensor<fp32, [384, 384]> model_encoder_layer_0_attention_self_key_weight = const()[name = tensor<string, []>("model_encoder_layer_0_attention_self_key_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(384653248)))];
            tensor<fp32, [384]> model_encoder_layer_0_attention_self_value_bias = const()[name = tensor<string, []>("model_encoder_layer_0_attention_self_value_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(385243136)))];
            tensor<fp32, [384, 384]> model_encoder_layer_0_attention_self_value_weight = const()[name = tensor<string, []>("model_encoder_layer_0_attention_self_value_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(385244736)))];
            tensor<fp32, [384]> model_encoder_layer_0_attention_output_dense_bias = const()[name = tensor<string, []>("model_encoder_layer_0_attention_output_dense_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(385834624)))];
            tensor<fp32, [384, 384]> model_encoder_layer_0_attention_output_dense_weight = const()[name = tensor<string, []>("model_encoder_layer_0_attention_output_dense_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(385836224)))];
            tensor<fp32, [384]> model_encoder_layer_0_attention_output_LayerNorm_bias = const()[name = tensor<string, []>("model_encoder_layer_0_attention_output_LayerNorm_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(386426112)))];
            tensor<fp32, [384]> model_encoder_layer_0_attention_output_LayerNorm_weight = const()[name = tensor<string, []>("model_encoder_layer_0_attention_output_LayerNorm_weight"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(386427712)))];
            tensor<fp32, [1536]> model_encoder_layer_0_intermediate_dense_bias = const()[name = tensor<string, []>("model_encoder_layer_0_intermediate_dense_bias"), val = tensor<fp32, [1536]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(386429312)))];
            tensor<fp32, [1536, 384]> model_encoder_layer_0_intermediate_dense_weight = const()[name = tensor<string, []>("model_encoder_layer_0_intermediate_dense_weight"), val = tensor<fp32, [1536, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(386435520)))];
            tensor<fp32, [384]> model_encoder_layer_0_output_dense_bias = const()[name = tensor<string, []>("model_encoder_layer_0_output_dense_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(388794880)))];
            tensor<fp32, [384, 1536]> model_encoder_layer_0_output_dense_weight = const()[name = tensor<string, []>("model_encoder_layer_0_output_dense_weight"), val = tensor<fp32, [384, 1536]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(388796480)))];
            tensor<fp32, [384]> model_encoder_layer_0_output_LayerNorm_bias = const()[name = tensor<string, []>("model_encoder_layer_0_output_LayerNorm_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(391155840)))];
            tensor<fp32, [384]> model_encoder_layer_0_output_LayerNorm_weight = const()[name = tensor<string, []>("model_encoder_layer_0_output_LayerNorm_weight"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(391157440)))];
            tensor<fp32, [384]> model_encoder_layer_1_attention_self_query_bias = const()[name = tensor<string, []>("model_encoder_layer_1_attention_self_query_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(391159040)))];
            tensor<fp32, [384, 384]> model_encoder_layer_1_attention_self_query_weight = const()[name = tensor<string, []>("model_encoder_layer_1_attention_self_query_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(391160640)))];
            tensor<fp32, [384]> model_encoder_layer_1_attention_self_key_bias = const()[name = tensor<string, []>("model_encoder_layer_1_attention_self_key_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(391750528)))];
            tensor<fp32, [384, 384]> model_encoder_layer_1_attention_self_key_weight = const()[name = tensor<string, []>("model_encoder_layer_1_attention_self_key_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(391752128)))];
            tensor<fp32, [384]> model_encoder_layer_1_attention_self_value_bias = const()[name = tensor<string, []>("model_encoder_layer_1_attention_self_value_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(392342016)))];
            tensor<fp32, [384, 384]> model_encoder_layer_1_attention_self_value_weight = const()[name = tensor<string, []>("model_encoder_layer_1_attention_self_value_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(392343616)))];
            tensor<fp32, [384]> model_encoder_layer_1_attention_output_dense_bias = const()[name = tensor<string, []>("model_encoder_layer_1_attention_output_dense_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(392933504)))];
            tensor<fp32, [384, 384]> model_encoder_layer_1_attention_output_dense_weight = const()[name = tensor<string, []>("model_encoder_layer_1_attention_output_dense_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(392935104)))];
            tensor<fp32, [384]> model_encoder_layer_1_attention_output_LayerNorm_bias = const()[name = tensor<string, []>("model_encoder_layer_1_attention_output_LayerNorm_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(393524992)))];
            tensor<fp32, [384]> model_encoder_layer_1_attention_output_LayerNorm_weight = const()[name = tensor<string, []>("model_encoder_layer_1_attention_output_LayerNorm_weight"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(393526592)))];
            tensor<fp32, [1536]> model_encoder_layer_1_intermediate_dense_bias = const()[name = tensor<string, []>("model_encoder_layer_1_intermediate_dense_bias"), val = tensor<fp32, [1536]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(393528192)))];
            tensor<fp32, [1536, 384]> model_encoder_layer_1_intermediate_dense_weight = const()[name = tensor<string, []>("model_encoder_layer_1_intermediate_dense_weight"), val = tensor<fp32, [1536, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(393534400)))];
            tensor<fp32, [384]> model_encoder_layer_1_output_dense_bias = const()[name = tensor<string, []>("model_encoder_layer_1_output_dense_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(395893760)))];
            tensor<fp32, [384, 1536]> model_encoder_layer_1_output_dense_weight = const()[name = tensor<string, []>("model_encoder_layer_1_output_dense_weight"), val = tensor<fp32, [384, 1536]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(395895360)))];
            tensor<fp32, [384]> model_encoder_layer_1_output_LayerNorm_bias = const()[name = tensor<string, []>("model_encoder_layer_1_output_LayerNorm_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(398254720)))];
            tensor<fp32, [384]> model_encoder_layer_1_output_LayerNorm_weight = const()[name = tensor<string, []>("model_encoder_layer_1_output_LayerNorm_weight"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(398256320)))];
            tensor<fp32, [384]> model_encoder_layer_2_attention_self_query_bias = const()[name = tensor<string, []>("model_encoder_layer_2_attention_self_query_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(398257920)))];
            tensor<fp32, [384, 384]> model_encoder_layer_2_attention_self_query_weight = const()[name = tensor<string, []>("model_encoder_layer_2_attention_self_query_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(398259520)))];
            tensor<fp32, [384]> model_encoder_layer_2_attention_self_key_bias = const()[name = tensor<string, []>("model_encoder_layer_2_attention_self_key_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(398849408)))];
            tensor<fp32, [384, 384]> model_encoder_layer_2_attention_self_key_weight = const()[name = tensor<string, []>("model_encoder_layer_2_attention_self_key_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(398851008)))];
            tensor<fp32, [384]> model_encoder_layer_2_attention_self_value_bias = const()[name = tensor<string, []>("model_encoder_layer_2_attention_self_value_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(399440896)))];
            tensor<fp32, [384, 384]> model_encoder_layer_2_attention_self_value_weight = const()[name = tensor<string, []>("model_encoder_layer_2_attention_self_value_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(399442496)))];
            tensor<fp32, [384]> model_encoder_layer_2_attention_output_dense_bias = const()[name = tensor<string, []>("model_encoder_layer_2_attention_output_dense_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(400032384)))];
            tensor<fp32, [384, 384]> model_encoder_layer_2_attention_output_dense_weight = const()[name = tensor<string, []>("model_encoder_layer_2_attention_output_dense_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(400033984)))];
            tensor<fp32, [384]> model_encoder_layer_2_attention_output_LayerNorm_bias = const()[name = tensor<string, []>("model_encoder_layer_2_attention_output_LayerNorm_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(400623872)))];
            tensor<fp32, [384]> model_encoder_layer_2_attention_output_LayerNorm_weight = const()[name = tensor<string, []>("model_encoder_layer_2_attention_output_LayerNorm_weight"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(400625472)))];
            tensor<fp32, [1536]> model_encoder_layer_2_intermediate_dense_bias = const()[name = tensor<string, []>("model_encoder_layer_2_intermediate_dense_bias"), val = tensor<fp32, [1536]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(400627072)))];
            tensor<fp32, [1536, 384]> model_encoder_layer_2_intermediate_dense_weight = const()[name = tensor<string, []>("model_encoder_layer_2_intermediate_dense_weight"), val = tensor<fp32, [1536, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(400633280)))];
            tensor<fp32, [384]> model_encoder_layer_2_output_dense_bias = const()[name = tensor<string, []>("model_encoder_layer_2_output_dense_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(402992640)))];
            tensor<fp32, [384, 1536]> model_encoder_layer_2_output_dense_weight = const()[name = tensor<string, []>("model_encoder_layer_2_output_dense_weight"), val = tensor<fp32, [384, 1536]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(402994240)))];
            tensor<fp32, [384]> model_encoder_layer_2_output_LayerNorm_bias = const()[name = tensor<string, []>("model_encoder_layer_2_output_LayerNorm_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(405353600)))];
            tensor<fp32, [384]> model_encoder_layer_2_output_LayerNorm_weight = const()[name = tensor<string, []>("model_encoder_layer_2_output_LayerNorm_weight"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(405355200)))];
            tensor<fp32, [384]> model_encoder_layer_3_attention_self_query_bias = const()[name = tensor<string, []>("model_encoder_layer_3_attention_self_query_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(405356800)))];
            tensor<fp32, [384, 384]> model_encoder_layer_3_attention_self_query_weight = const()[name = tensor<string, []>("model_encoder_layer_3_attention_self_query_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(405358400)))];
            tensor<fp32, [384]> model_encoder_layer_3_attention_self_key_bias = const()[name = tensor<string, []>("model_encoder_layer_3_attention_self_key_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(405948288)))];
            tensor<fp32, [384, 384]> model_encoder_layer_3_attention_self_key_weight = const()[name = tensor<string, []>("model_encoder_layer_3_attention_self_key_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(405949888)))];
            tensor<fp32, [384]> model_encoder_layer_3_attention_self_value_bias = const()[name = tensor<string, []>("model_encoder_layer_3_attention_self_value_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(406539776)))];
            tensor<fp32, [384, 384]> model_encoder_layer_3_attention_self_value_weight = const()[name = tensor<string, []>("model_encoder_layer_3_attention_self_value_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(406541376)))];
            tensor<fp32, [384]> model_encoder_layer_3_attention_output_dense_bias = const()[name = tensor<string, []>("model_encoder_layer_3_attention_output_dense_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(407131264)))];
            tensor<fp32, [384, 384]> model_encoder_layer_3_attention_output_dense_weight = const()[name = tensor<string, []>("model_encoder_layer_3_attention_output_dense_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(407132864)))];
            tensor<fp32, [384]> model_encoder_layer_3_attention_output_LayerNorm_bias = const()[name = tensor<string, []>("model_encoder_layer_3_attention_output_LayerNorm_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(407722752)))];
            tensor<fp32, [384]> model_encoder_layer_3_attention_output_LayerNorm_weight = const()[name = tensor<string, []>("model_encoder_layer_3_attention_output_LayerNorm_weight"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(407724352)))];
            tensor<fp32, [1536]> model_encoder_layer_3_intermediate_dense_bias = const()[name = tensor<string, []>("model_encoder_layer_3_intermediate_dense_bias"), val = tensor<fp32, [1536]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(407725952)))];
            tensor<fp32, [1536, 384]> model_encoder_layer_3_intermediate_dense_weight = const()[name = tensor<string, []>("model_encoder_layer_3_intermediate_dense_weight"), val = tensor<fp32, [1536, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(407732160)))];
            tensor<fp32, [384]> model_encoder_layer_3_output_dense_bias = const()[name = tensor<string, []>("model_encoder_layer_3_output_dense_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(410091520)))];
            tensor<fp32, [384, 1536]> model_encoder_layer_3_output_dense_weight = const()[name = tensor<string, []>("model_encoder_layer_3_output_dense_weight"), val = tensor<fp32, [384, 1536]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(410093120)))];
            tensor<fp32, [384]> model_encoder_layer_3_output_LayerNorm_bias = const()[name = tensor<string, []>("model_encoder_layer_3_output_LayerNorm_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(412452480)))];
            tensor<fp32, [384]> model_encoder_layer_3_output_LayerNorm_weight = const()[name = tensor<string, []>("model_encoder_layer_3_output_LayerNorm_weight"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(412454080)))];
            tensor<fp32, [384]> model_encoder_layer_4_attention_self_query_bias = const()[name = tensor<string, []>("model_encoder_layer_4_attention_self_query_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(412455680)))];
            tensor<fp32, [384, 384]> model_encoder_layer_4_attention_self_query_weight = const()[name = tensor<string, []>("model_encoder_layer_4_attention_self_query_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(412457280)))];
            tensor<fp32, [384]> model_encoder_layer_4_attention_self_key_bias = const()[name = tensor<string, []>("model_encoder_layer_4_attention_self_key_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(413047168)))];
            tensor<fp32, [384, 384]> model_encoder_layer_4_attention_self_key_weight = const()[name = tensor<string, []>("model_encoder_layer_4_attention_self_key_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(413048768)))];
            tensor<fp32, [384]> model_encoder_layer_4_attention_self_value_bias = const()[name = tensor<string, []>("model_encoder_layer_4_attention_self_value_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(413638656)))];
            tensor<fp32, [384, 384]> model_encoder_layer_4_attention_self_value_weight = const()[name = tensor<string, []>("model_encoder_layer_4_attention_self_value_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(413640256)))];
            tensor<fp32, [384]> model_encoder_layer_4_attention_output_dense_bias = const()[name = tensor<string, []>("model_encoder_layer_4_attention_output_dense_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(414230144)))];
            tensor<fp32, [384, 384]> model_encoder_layer_4_attention_output_dense_weight = const()[name = tensor<string, []>("model_encoder_layer_4_attention_output_dense_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(414231744)))];
            tensor<fp32, [384]> model_encoder_layer_4_attention_output_LayerNorm_bias = const()[name = tensor<string, []>("model_encoder_layer_4_attention_output_LayerNorm_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(414821632)))];
            tensor<fp32, [384]> model_encoder_layer_4_attention_output_LayerNorm_weight = const()[name = tensor<string, []>("model_encoder_layer_4_attention_output_LayerNorm_weight"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(414823232)))];
            tensor<fp32, [1536]> model_encoder_layer_4_intermediate_dense_bias = const()[name = tensor<string, []>("model_encoder_layer_4_intermediate_dense_bias"), val = tensor<fp32, [1536]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(414824832)))];
            tensor<fp32, [1536, 384]> model_encoder_layer_4_intermediate_dense_weight = const()[name = tensor<string, []>("model_encoder_layer_4_intermediate_dense_weight"), val = tensor<fp32, [1536, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(414831040)))];
            tensor<fp32, [384]> model_encoder_layer_4_output_dense_bias = const()[name = tensor<string, []>("model_encoder_layer_4_output_dense_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(417190400)))];
            tensor<fp32, [384, 1536]> model_encoder_layer_4_output_dense_weight = const()[name = tensor<string, []>("model_encoder_layer_4_output_dense_weight"), val = tensor<fp32, [384, 1536]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(417192000)))];
            tensor<fp32, [384]> model_encoder_layer_4_output_LayerNorm_bias = const()[name = tensor<string, []>("model_encoder_layer_4_output_LayerNorm_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(419551360)))];
            tensor<fp32, [384]> model_encoder_layer_4_output_LayerNorm_weight = const()[name = tensor<string, []>("model_encoder_layer_4_output_LayerNorm_weight"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(419552960)))];
            tensor<fp32, [384]> model_encoder_layer_5_attention_self_query_bias = const()[name = tensor<string, []>("model_encoder_layer_5_attention_self_query_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(419554560)))];
            tensor<fp32, [384, 384]> model_encoder_layer_5_attention_self_query_weight = const()[name = tensor<string, []>("model_encoder_layer_5_attention_self_query_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(419556160)))];
            tensor<fp32, [384]> model_encoder_layer_5_attention_self_key_bias = const()[name = tensor<string, []>("model_encoder_layer_5_attention_self_key_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(420146048)))];
            tensor<fp32, [384, 384]> model_encoder_layer_5_attention_self_key_weight = const()[name = tensor<string, []>("model_encoder_layer_5_attention_self_key_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(420147648)))];
            tensor<fp32, [384]> model_encoder_layer_5_attention_self_value_bias = const()[name = tensor<string, []>("model_encoder_layer_5_attention_self_value_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(420737536)))];
            tensor<fp32, [384, 384]> model_encoder_layer_5_attention_self_value_weight = const()[name = tensor<string, []>("model_encoder_layer_5_attention_self_value_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(420739136)))];
            tensor<fp32, [384]> model_encoder_layer_5_attention_output_dense_bias = const()[name = tensor<string, []>("model_encoder_layer_5_attention_output_dense_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(421329024)))];
            tensor<fp32, [384, 384]> model_encoder_layer_5_attention_output_dense_weight = const()[name = tensor<string, []>("model_encoder_layer_5_attention_output_dense_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(421330624)))];
            tensor<fp32, [384]> model_encoder_layer_5_attention_output_LayerNorm_bias = const()[name = tensor<string, []>("model_encoder_layer_5_attention_output_LayerNorm_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(421920512)))];
            tensor<fp32, [384]> model_encoder_layer_5_attention_output_LayerNorm_weight = const()[name = tensor<string, []>("model_encoder_layer_5_attention_output_LayerNorm_weight"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(421922112)))];
            tensor<fp32, [1536]> model_encoder_layer_5_intermediate_dense_bias = const()[name = tensor<string, []>("model_encoder_layer_5_intermediate_dense_bias"), val = tensor<fp32, [1536]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(421923712)))];
            tensor<fp32, [1536, 384]> model_encoder_layer_5_intermediate_dense_weight = const()[name = tensor<string, []>("model_encoder_layer_5_intermediate_dense_weight"), val = tensor<fp32, [1536, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(421929920)))];
            tensor<fp32, [384]> model_encoder_layer_5_output_dense_bias = const()[name = tensor<string, []>("model_encoder_layer_5_output_dense_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(424289280)))];
            tensor<fp32, [384, 1536]> model_encoder_layer_5_output_dense_weight = const()[name = tensor<string, []>("model_encoder_layer_5_output_dense_weight"), val = tensor<fp32, [384, 1536]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(424290880)))];
            tensor<fp32, [384]> model_encoder_layer_5_output_LayerNorm_bias = const()[name = tensor<string, []>("model_encoder_layer_5_output_LayerNorm_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(426650240)))];
            tensor<fp32, [384]> model_encoder_layer_5_output_LayerNorm_weight = const()[name = tensor<string, []>("model_encoder_layer_5_output_LayerNorm_weight"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(426651840)))];
            tensor<fp32, [384]> model_encoder_layer_6_attention_self_query_bias = const()[name = tensor<string, []>("model_encoder_layer_6_attention_self_query_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(426653440)))];
            tensor<fp32, [384, 384]> model_encoder_layer_6_attention_self_query_weight = const()[name = tensor<string, []>("model_encoder_layer_6_attention_self_query_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(426655040)))];
            tensor<fp32, [384]> model_encoder_layer_6_attention_self_key_bias = const()[name = tensor<string, []>("model_encoder_layer_6_attention_self_key_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(427244928)))];
            tensor<fp32, [384, 384]> model_encoder_layer_6_attention_self_key_weight = const()[name = tensor<string, []>("model_encoder_layer_6_attention_self_key_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(427246528)))];
            tensor<fp32, [384]> model_encoder_layer_6_attention_self_value_bias = const()[name = tensor<string, []>("model_encoder_layer_6_attention_self_value_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(427836416)))];
            tensor<fp32, [384, 384]> model_encoder_layer_6_attention_self_value_weight = const()[name = tensor<string, []>("model_encoder_layer_6_attention_self_value_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(427838016)))];
            tensor<fp32, [384]> model_encoder_layer_6_attention_output_dense_bias = const()[name = tensor<string, []>("model_encoder_layer_6_attention_output_dense_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(428427904)))];
            tensor<fp32, [384, 384]> model_encoder_layer_6_attention_output_dense_weight = const()[name = tensor<string, []>("model_encoder_layer_6_attention_output_dense_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(428429504)))];
            tensor<fp32, [384]> model_encoder_layer_6_attention_output_LayerNorm_bias = const()[name = tensor<string, []>("model_encoder_layer_6_attention_output_LayerNorm_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(429019392)))];
            tensor<fp32, [384]> model_encoder_layer_6_attention_output_LayerNorm_weight = const()[name = tensor<string, []>("model_encoder_layer_6_attention_output_LayerNorm_weight"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(429020992)))];
            tensor<fp32, [1536]> model_encoder_layer_6_intermediate_dense_bias = const()[name = tensor<string, []>("model_encoder_layer_6_intermediate_dense_bias"), val = tensor<fp32, [1536]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(429022592)))];
            tensor<fp32, [1536, 384]> model_encoder_layer_6_intermediate_dense_weight = const()[name = tensor<string, []>("model_encoder_layer_6_intermediate_dense_weight"), val = tensor<fp32, [1536, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(429028800)))];
            tensor<fp32, [384]> model_encoder_layer_6_output_dense_bias = const()[name = tensor<string, []>("model_encoder_layer_6_output_dense_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(431388160)))];
            tensor<fp32, [384, 1536]> model_encoder_layer_6_output_dense_weight = const()[name = tensor<string, []>("model_encoder_layer_6_output_dense_weight"), val = tensor<fp32, [384, 1536]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(431389760)))];
            tensor<fp32, [384]> model_encoder_layer_6_output_LayerNorm_bias = const()[name = tensor<string, []>("model_encoder_layer_6_output_LayerNorm_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(433749120)))];
            tensor<fp32, [384]> model_encoder_layer_6_output_LayerNorm_weight = const()[name = tensor<string, []>("model_encoder_layer_6_output_LayerNorm_weight"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(433750720)))];
            tensor<fp32, [384]> model_encoder_layer_7_attention_self_query_bias = const()[name = tensor<string, []>("model_encoder_layer_7_attention_self_query_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(433752320)))];
            tensor<fp32, [384, 384]> model_encoder_layer_7_attention_self_query_weight = const()[name = tensor<string, []>("model_encoder_layer_7_attention_self_query_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(433753920)))];
            tensor<fp32, [384]> model_encoder_layer_7_attention_self_key_bias = const()[name = tensor<string, []>("model_encoder_layer_7_attention_self_key_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(434343808)))];
            tensor<fp32, [384, 384]> model_encoder_layer_7_attention_self_key_weight = const()[name = tensor<string, []>("model_encoder_layer_7_attention_self_key_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(434345408)))];
            tensor<fp32, [384]> model_encoder_layer_7_attention_self_value_bias = const()[name = tensor<string, []>("model_encoder_layer_7_attention_self_value_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(434935296)))];
            tensor<fp32, [384, 384]> model_encoder_layer_7_attention_self_value_weight = const()[name = tensor<string, []>("model_encoder_layer_7_attention_self_value_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(434936896)))];
            tensor<fp32, [384]> model_encoder_layer_7_attention_output_dense_bias = const()[name = tensor<string, []>("model_encoder_layer_7_attention_output_dense_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(435526784)))];
            tensor<fp32, [384, 384]> model_encoder_layer_7_attention_output_dense_weight = const()[name = tensor<string, []>("model_encoder_layer_7_attention_output_dense_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(435528384)))];
            tensor<fp32, [384]> model_encoder_layer_7_attention_output_LayerNorm_bias = const()[name = tensor<string, []>("model_encoder_layer_7_attention_output_LayerNorm_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(436118272)))];
            tensor<fp32, [384]> model_encoder_layer_7_attention_output_LayerNorm_weight = const()[name = tensor<string, []>("model_encoder_layer_7_attention_output_LayerNorm_weight"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(436119872)))];
            tensor<fp32, [1536]> model_encoder_layer_7_intermediate_dense_bias = const()[name = tensor<string, []>("model_encoder_layer_7_intermediate_dense_bias"), val = tensor<fp32, [1536]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(436121472)))];
            tensor<fp32, [1536, 384]> model_encoder_layer_7_intermediate_dense_weight = const()[name = tensor<string, []>("model_encoder_layer_7_intermediate_dense_weight"), val = tensor<fp32, [1536, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(436127680)))];
            tensor<fp32, [384]> model_encoder_layer_7_output_dense_bias = const()[name = tensor<string, []>("model_encoder_layer_7_output_dense_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(438487040)))];
            tensor<fp32, [384, 1536]> model_encoder_layer_7_output_dense_weight = const()[name = tensor<string, []>("model_encoder_layer_7_output_dense_weight"), val = tensor<fp32, [384, 1536]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(438488640)))];
            tensor<fp32, [384]> model_encoder_layer_7_output_LayerNorm_bias = const()[name = tensor<string, []>("model_encoder_layer_7_output_LayerNorm_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(440848000)))];
            tensor<fp32, [384]> model_encoder_layer_7_output_LayerNorm_weight = const()[name = tensor<string, []>("model_encoder_layer_7_output_LayerNorm_weight"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(440849600)))];
            tensor<fp32, [384]> model_encoder_layer_8_attention_self_query_bias = const()[name = tensor<string, []>("model_encoder_layer_8_attention_self_query_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(440851200)))];
            tensor<fp32, [384, 384]> model_encoder_layer_8_attention_self_query_weight = const()[name = tensor<string, []>("model_encoder_layer_8_attention_self_query_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(440852800)))];
            tensor<fp32, [384]> model_encoder_layer_8_attention_self_key_bias = const()[name = tensor<string, []>("model_encoder_layer_8_attention_self_key_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(441442688)))];
            tensor<fp32, [384, 384]> model_encoder_layer_8_attention_self_key_weight = const()[name = tensor<string, []>("model_encoder_layer_8_attention_self_key_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(441444288)))];
            tensor<fp32, [384]> model_encoder_layer_8_attention_self_value_bias = const()[name = tensor<string, []>("model_encoder_layer_8_attention_self_value_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(442034176)))];
            tensor<fp32, [384, 384]> model_encoder_layer_8_attention_self_value_weight = const()[name = tensor<string, []>("model_encoder_layer_8_attention_self_value_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(442035776)))];
            tensor<fp32, [384]> model_encoder_layer_8_attention_output_dense_bias = const()[name = tensor<string, []>("model_encoder_layer_8_attention_output_dense_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(442625664)))];
            tensor<fp32, [384, 384]> model_encoder_layer_8_attention_output_dense_weight = const()[name = tensor<string, []>("model_encoder_layer_8_attention_output_dense_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(442627264)))];
            tensor<fp32, [384]> model_encoder_layer_8_attention_output_LayerNorm_bias = const()[name = tensor<string, []>("model_encoder_layer_8_attention_output_LayerNorm_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(443217152)))];
            tensor<fp32, [384]> model_encoder_layer_8_attention_output_LayerNorm_weight = const()[name = tensor<string, []>("model_encoder_layer_8_attention_output_LayerNorm_weight"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(443218752)))];
            tensor<fp32, [1536]> model_encoder_layer_8_intermediate_dense_bias = const()[name = tensor<string, []>("model_encoder_layer_8_intermediate_dense_bias"), val = tensor<fp32, [1536]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(443220352)))];
            tensor<fp32, [1536, 384]> model_encoder_layer_8_intermediate_dense_weight = const()[name = tensor<string, []>("model_encoder_layer_8_intermediate_dense_weight"), val = tensor<fp32, [1536, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(443226560)))];
            tensor<fp32, [384]> model_encoder_layer_8_output_dense_bias = const()[name = tensor<string, []>("model_encoder_layer_8_output_dense_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(445585920)))];
            tensor<fp32, [384, 1536]> model_encoder_layer_8_output_dense_weight = const()[name = tensor<string, []>("model_encoder_layer_8_output_dense_weight"), val = tensor<fp32, [384, 1536]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(445587520)))];
            tensor<fp32, [384]> model_encoder_layer_8_output_LayerNorm_bias = const()[name = tensor<string, []>("model_encoder_layer_8_output_LayerNorm_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(447946880)))];
            tensor<fp32, [384]> model_encoder_layer_8_output_LayerNorm_weight = const()[name = tensor<string, []>("model_encoder_layer_8_output_LayerNorm_weight"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(447948480)))];
            tensor<fp32, [384]> model_encoder_layer_9_attention_self_query_bias = const()[name = tensor<string, []>("model_encoder_layer_9_attention_self_query_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(447950080)))];
            tensor<fp32, [384, 384]> model_encoder_layer_9_attention_self_query_weight = const()[name = tensor<string, []>("model_encoder_layer_9_attention_self_query_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(447951680)))];
            tensor<fp32, [384]> model_encoder_layer_9_attention_self_key_bias = const()[name = tensor<string, []>("model_encoder_layer_9_attention_self_key_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(448541568)))];
            tensor<fp32, [384, 384]> model_encoder_layer_9_attention_self_key_weight = const()[name = tensor<string, []>("model_encoder_layer_9_attention_self_key_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(448543168)))];
            tensor<fp32, [384]> model_encoder_layer_9_attention_self_value_bias = const()[name = tensor<string, []>("model_encoder_layer_9_attention_self_value_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(449133056)))];
            tensor<fp32, [384, 384]> model_encoder_layer_9_attention_self_value_weight = const()[name = tensor<string, []>("model_encoder_layer_9_attention_self_value_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(449134656)))];
            tensor<fp32, [384]> model_encoder_layer_9_attention_output_dense_bias = const()[name = tensor<string, []>("model_encoder_layer_9_attention_output_dense_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(449724544)))];
            tensor<fp32, [384, 384]> model_encoder_layer_9_attention_output_dense_weight = const()[name = tensor<string, []>("model_encoder_layer_9_attention_output_dense_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(449726144)))];
            tensor<fp32, [384]> model_encoder_layer_9_attention_output_LayerNorm_bias = const()[name = tensor<string, []>("model_encoder_layer_9_attention_output_LayerNorm_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(450316032)))];
            tensor<fp32, [384]> model_encoder_layer_9_attention_output_LayerNorm_weight = const()[name = tensor<string, []>("model_encoder_layer_9_attention_output_LayerNorm_weight"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(450317632)))];
            tensor<fp32, [1536]> model_encoder_layer_9_intermediate_dense_bias = const()[name = tensor<string, []>("model_encoder_layer_9_intermediate_dense_bias"), val = tensor<fp32, [1536]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(450319232)))];
            tensor<fp32, [1536, 384]> model_encoder_layer_9_intermediate_dense_weight = const()[name = tensor<string, []>("model_encoder_layer_9_intermediate_dense_weight"), val = tensor<fp32, [1536, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(450325440)))];
            tensor<fp32, [384]> model_encoder_layer_9_output_dense_bias = const()[name = tensor<string, []>("model_encoder_layer_9_output_dense_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(452684800)))];
            tensor<fp32, [384, 1536]> model_encoder_layer_9_output_dense_weight = const()[name = tensor<string, []>("model_encoder_layer_9_output_dense_weight"), val = tensor<fp32, [384, 1536]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(452686400)))];
            tensor<fp32, [384]> model_encoder_layer_9_output_LayerNorm_bias = const()[name = tensor<string, []>("model_encoder_layer_9_output_LayerNorm_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(455045760)))];
            tensor<fp32, [384]> model_encoder_layer_9_output_LayerNorm_weight = const()[name = tensor<string, []>("model_encoder_layer_9_output_LayerNorm_weight"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(455047360)))];
            tensor<fp32, [384]> model_encoder_layer_10_attention_self_query_bias = const()[name = tensor<string, []>("model_encoder_layer_10_attention_self_query_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(455048960)))];
            tensor<fp32, [384, 384]> model_encoder_layer_10_attention_self_query_weight = const()[name = tensor<string, []>("model_encoder_layer_10_attention_self_query_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(455050560)))];
            tensor<fp32, [384]> model_encoder_layer_10_attention_self_key_bias = const()[name = tensor<string, []>("model_encoder_layer_10_attention_self_key_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(455640448)))];
            tensor<fp32, [384, 384]> model_encoder_layer_10_attention_self_key_weight = const()[name = tensor<string, []>("model_encoder_layer_10_attention_self_key_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(455642048)))];
            tensor<fp32, [384]> model_encoder_layer_10_attention_self_value_bias = const()[name = tensor<string, []>("model_encoder_layer_10_attention_self_value_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(456231936)))];
            tensor<fp32, [384, 384]> model_encoder_layer_10_attention_self_value_weight = const()[name = tensor<string, []>("model_encoder_layer_10_attention_self_value_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(456233536)))];
            tensor<fp32, [384]> model_encoder_layer_10_attention_output_dense_bias = const()[name = tensor<string, []>("model_encoder_layer_10_attention_output_dense_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(456823424)))];
            tensor<fp32, [384, 384]> model_encoder_layer_10_attention_output_dense_weight = const()[name = tensor<string, []>("model_encoder_layer_10_attention_output_dense_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(456825024)))];
            tensor<fp32, [384]> model_encoder_layer_10_attention_output_LayerNorm_bias = const()[name = tensor<string, []>("model_encoder_layer_10_attention_output_LayerNorm_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(457414912)))];
            tensor<fp32, [384]> model_encoder_layer_10_attention_output_LayerNorm_weight = const()[name = tensor<string, []>("model_encoder_layer_10_attention_output_LayerNorm_weight"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(457416512)))];
            tensor<fp32, [1536]> model_encoder_layer_10_intermediate_dense_bias = const()[name = tensor<string, []>("model_encoder_layer_10_intermediate_dense_bias"), val = tensor<fp32, [1536]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(457418112)))];
            tensor<fp32, [1536, 384]> model_encoder_layer_10_intermediate_dense_weight = const()[name = tensor<string, []>("model_encoder_layer_10_intermediate_dense_weight"), val = tensor<fp32, [1536, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(457424320)))];
            tensor<fp32, [384]> model_encoder_layer_10_output_dense_bias = const()[name = tensor<string, []>("model_encoder_layer_10_output_dense_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(459783680)))];
            tensor<fp32, [384, 1536]> model_encoder_layer_10_output_dense_weight = const()[name = tensor<string, []>("model_encoder_layer_10_output_dense_weight"), val = tensor<fp32, [384, 1536]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(459785280)))];
            tensor<fp32, [384]> model_encoder_layer_10_output_LayerNorm_bias = const()[name = tensor<string, []>("model_encoder_layer_10_output_LayerNorm_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(462144640)))];
            tensor<fp32, [384]> model_encoder_layer_10_output_LayerNorm_weight = const()[name = tensor<string, []>("model_encoder_layer_10_output_LayerNorm_weight"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(462146240)))];
            tensor<fp32, [384]> model_encoder_layer_11_attention_self_query_bias = const()[name = tensor<string, []>("model_encoder_layer_11_attention_self_query_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(462147840)))];
            tensor<fp32, [384, 384]> model_encoder_layer_11_attention_self_query_weight = const()[name = tensor<string, []>("model_encoder_layer_11_attention_self_query_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(462149440)))];
            tensor<fp32, [384]> model_encoder_layer_11_attention_self_key_bias = const()[name = tensor<string, []>("model_encoder_layer_11_attention_self_key_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(462739328)))];
            tensor<fp32, [384, 384]> model_encoder_layer_11_attention_self_key_weight = const()[name = tensor<string, []>("model_encoder_layer_11_attention_self_key_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(462740928)))];
            tensor<fp32, [384]> model_encoder_layer_11_attention_self_value_bias = const()[name = tensor<string, []>("model_encoder_layer_11_attention_self_value_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(463330816)))];
            tensor<fp32, [384, 384]> model_encoder_layer_11_attention_self_value_weight = const()[name = tensor<string, []>("model_encoder_layer_11_attention_self_value_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(463332416)))];
            tensor<fp32, [384]> model_encoder_layer_11_attention_output_dense_bias = const()[name = tensor<string, []>("model_encoder_layer_11_attention_output_dense_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(463922304)))];
            tensor<fp32, [384, 384]> model_encoder_layer_11_attention_output_dense_weight = const()[name = tensor<string, []>("model_encoder_layer_11_attention_output_dense_weight"), val = tensor<fp32, [384, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(463923904)))];
            tensor<fp32, [384]> model_encoder_layer_11_attention_output_LayerNorm_bias = const()[name = tensor<string, []>("model_encoder_layer_11_attention_output_LayerNorm_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(464513792)))];
            tensor<fp32, [384]> model_encoder_layer_11_attention_output_LayerNorm_weight = const()[name = tensor<string, []>("model_encoder_layer_11_attention_output_LayerNorm_weight"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(464515392)))];
            tensor<fp32, [1536]> model_encoder_layer_11_intermediate_dense_bias = const()[name = tensor<string, []>("model_encoder_layer_11_intermediate_dense_bias"), val = tensor<fp32, [1536]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(464516992)))];
            tensor<fp32, [1536, 384]> model_encoder_layer_11_intermediate_dense_weight = const()[name = tensor<string, []>("model_encoder_layer_11_intermediate_dense_weight"), val = tensor<fp32, [1536, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(464523200)))];
            tensor<fp32, [384]> model_encoder_layer_11_output_dense_bias = const()[name = tensor<string, []>("model_encoder_layer_11_output_dense_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(466882560)))];
            tensor<fp32, [384, 1536]> model_encoder_layer_11_output_dense_weight = const()[name = tensor<string, []>("model_encoder_layer_11_output_dense_weight"), val = tensor<fp32, [384, 1536]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(466884160)))];
            tensor<fp32, [384]> model_encoder_layer_11_output_LayerNorm_bias = const()[name = tensor<string, []>("model_encoder_layer_11_output_LayerNorm_bias"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(469243520)))];
            tensor<fp32, [384]> model_encoder_layer_11_output_LayerNorm_weight = const()[name = tensor<string, []>("model_encoder_layer_11_output_LayerNorm_weight"), val = tensor<fp32, [384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(469245120)))];
            tensor<fp32, []> var_8 = const()[name = tensor<string, []>("op_8"), val = tensor<fp32, []>(-0x1.fffffep+127)];
            tensor<fp32, []> var_10 = const()[name = tensor<string, []>("op_10"), val = tensor<fp32, []>(0x1p+0)];
            tensor<fp32, []> var_17 = const()[name = tensor<string, []>("op_17"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<int32, []> inputs_embeds_axis_0 = const()[name = tensor<string, []>("inputs_embeds_axis_0"), val = tensor<int32, []>(0)];
            tensor<fp32, [1, 512, 384]> inputs_embeds = gather(axis = inputs_embeds_axis_0, indices = input_ids, x = model_embeddings_word_embeddings_weight)[name = tensor<string, []>("inputs_embeds")];
            tensor<fp32, [1, 512, 384]> token_type_embeddings_1 = const()[name = tensor<string, []>("token_type_embeddings_1"), val = tensor<fp32, [1, 512, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(469246720)))];
            tensor<fp32, [1, 512, 384]> embeddings_1 = add(x = inputs_embeds, y = token_type_embeddings_1)[name = tensor<string, []>("embeddings_1")];
            tensor<fp32, [1, 512, 384]> position_embeddings_1 = const()[name = tensor<string, []>("position_embeddings_1"), val = tensor<fp32, [1, 512, 384]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(470033216)))];
            tensor<fp32, [1, 512, 384]> input_5 = add(x = embeddings_1, y = position_embeddings_1)[name = tensor<string, []>("input_5")];
            tensor<int32, [1]> input_7_axes_0 = const()[name = tensor<string, []>("input_7_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp32, [1, 512, 384]> input_7 = layer_norm(axes = input_7_axes_0, beta = model_embeddings_LayerNorm_bias, epsilon = var_17, gamma = model_embeddings_LayerNorm_weight, x = input_5)[name = tensor<string, []>("input_7")];
            tensor<int32, [1]> var_62_axes_0 = const()[name = tensor<string, []>("op_62_axes_0"), val = tensor<int32, [1]>([1])];
            tensor<int32, [1, 1, 512]> var_62 = expand_dims(axes = var_62_axes_0, x = attention_mask)[name = tensor<string, []>("op_62")];
            tensor<int32, [1]> var_63_axes_0 = const()[name = tensor<string, []>("op_63_axes_0"), val = tensor<int32, [1]>([2])];
            tensor<int32, [1, 1, 1, 512]> var_63 = expand_dims(axes = var_63_axes_0, x = var_62)[name = tensor<string, []>("op_63")];
            tensor<int32, [4]> var_66_reps_0 = const()[name = tensor<string, []>("op_66_reps_0"), val = tensor<int32, [4]>([1, 1, 512, 1])];
            tensor<int32, [1, 1, 512, 512]> var_66 = tile(reps = var_66_reps_0, x = var_63)[name = tensor<string, []>("op_66")];
            tensor<string, []> cast_3_dtype_0 = const()[name = tensor<string, []>("cast_3_dtype_0"), val = tensor<string, []>("fp32")];
            tensor<fp32, [1, 1, 512, 512]> cast_3 = cast(dtype = cast_3_dtype_0, x = var_66)[name = tensor<string, []>("cast_60")];
            tensor<fp32, [1, 1, 512, 512]> inverted_mask = sub(x = var_10, y = cast_3)[name = tensor<string, []>("inverted_mask")];
            tensor<string, []> cast_4_dtype_0 = const()[name = tensor<string, []>("cast_4_dtype_0"), val = tensor<string, []>("bool")];
            tensor<bool, [1, 1, 512, 512]> cast_4 = cast(dtype = cast_4_dtype_0, x = inverted_mask)[name = tensor<string, []>("cast_59")];
            tensor<fp32, [1, 1, 512, 512]> attention_mask_1 = select(a = var_8, b = inverted_mask, cond = cast_4)[name = tensor<string, []>("attention_mask")];
            tensor<fp32, [1, 512, 384]> x_1 = linear(bias = model_encoder_layer_0_attention_self_query_bias, weight = model_encoder_layer_0_attention_self_query_weight, x = input_7)[name = tensor<string, []>("linear_0")];
            tensor<int32, [4]> var_110 = const()[name = tensor<string, []>("op_110"), val = tensor<int32, [4]>([1, 512, 12, 32])];
            tensor<fp32, [1, 512, 12, 32]> x_3 = reshape(shape = var_110, x = x_1)[name = tensor<string, []>("x_3")];
            tensor<fp32, [1, 512, 384]> x_5 = linear(bias = model_encoder_layer_0_attention_self_key_bias, weight = model_encoder_layer_0_attention_self_key_weight, x = input_7)[name = tensor<string, []>("linear_1")];
            tensor<int32, [4]> var_119 = const()[name = tensor<string, []>("op_119"), val = tensor<int32, [4]>([1, 512, 12, 32])];
            tensor<fp32, [1, 512, 12, 32]> x_7 = reshape(shape = var_119, x = x_5)[name = tensor<string, []>("x_7")];
            tensor<fp32, [1, 512, 384]> x_9 = linear(bias = model_encoder_layer_0_attention_self_value_bias, weight = model_encoder_layer_0_attention_self_value_weight, x = input_7)[name = tensor<string, []>("linear_2")];
            tensor<int32, [4]> var_128 = const()[name = tensor<string, []>("op_128"), val = tensor<int32, [4]>([1, 512, 12, 32])];
            tensor<fp32, [1, 512, 12, 32]> x_11 = reshape(shape = var_128, x = x_9)[name = tensor<string, []>("x_11")];
            tensor<int32, [4]> var_130 = const()[name = tensor<string, []>("op_130"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp32, []> mul_0_y_0 = const()[name = tensor<string, []>("mul_0_y_0"), val = tensor<fp32, []>(0x1.6a09e6p-3)];
            tensor<fp32, [1, 512, 12, 32]> mul_0 = mul(x = x_3, y = mul_0_y_0)[name = tensor<string, []>("mul_0")];
            tensor<bool, []> matmul_0_transpose_y_0 = const()[name = tensor<string, []>("matmul_0_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> matmul_0_transpose_x_0 = const()[name = tensor<string, []>("matmul_0_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_48_perm_0 = const()[name = tensor<string, []>("transpose_48_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_49_perm_0 = const()[name = tensor<string, []>("transpose_49_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<fp32, [1, 12, 512, 32]> transpose_49 = transpose(perm = transpose_49_perm_0, x = x_7)[name = tensor<string, []>("transpose_117")];
            tensor<fp32, [1, 12, 512, 32]> transpose_48 = transpose(perm = transpose_48_perm_0, x = mul_0)[name = tensor<string, []>("transpose_118")];
            tensor<fp32, [1, 12, 512, 512]> matmul_0 = matmul(transpose_x = matmul_0_transpose_x_0, transpose_y = matmul_0_transpose_y_0, x = transpose_48, y = transpose_49)[name = tensor<string, []>("matmul_0")];
            tensor<fp32, [1, 12, 512, 512]> add_0 = add(x = matmul_0, y = attention_mask_1)[name = tensor<string, []>("add_0")];
            tensor<int32, []> softmax_0_axis_0 = const()[name = tensor<string, []>("softmax_0_axis_0"), val = tensor<int32, []>(-1)];
            tensor<fp32, [1, 12, 512, 512]> softmax_0 = softmax(axis = softmax_0_axis_0, x = add_0)[name = tensor<string, []>("softmax_0")];
            tensor<bool, []> attn_output_1_transpose_x_0 = const()[name = tensor<string, []>("attn_output_1_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_1_transpose_y_0 = const()[name = tensor<string, []>("attn_output_1_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp32, [1, 12, 512, 32]> value_layer_1 = transpose(perm = var_130, x = x_11)[name = tensor<string, []>("transpose_119")];
            tensor<fp32, [1, 12, 512, 32]> attn_output_1 = matmul(transpose_x = attn_output_1_transpose_x_0, transpose_y = attn_output_1_transpose_y_0, x = softmax_0, y = value_layer_1)[name = tensor<string, []>("attn_output_1")];
            tensor<int32, [4]> attn_output_3_perm_0 = const()[name = tensor<string, []>("attn_output_3_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_134 = const()[name = tensor<string, []>("op_134"), val = tensor<int32, [3]>([1, 512, 384])];
            tensor<fp32, [1, 512, 12, 32]> attn_output_3 = transpose(perm = attn_output_3_perm_0, x = attn_output_1)[name = tensor<string, []>("transpose_116")];
            tensor<fp32, [1, 512, 384]> input_9 = reshape(shape = var_134, x = attn_output_3)[name = tensor<string, []>("input_9")];
            tensor<fp32, [1, 512, 384]> input_11 = linear(bias = model_encoder_layer_0_attention_output_dense_bias, weight = model_encoder_layer_0_attention_output_dense_weight, x = input_9)[name = tensor<string, []>("linear_3")];
            tensor<fp32, [1, 512, 384]> input_13 = add(x = input_11, y = input_7)[name = tensor<string, []>("input_13")];
            tensor<int32, [1]> input_15_axes_0 = const()[name = tensor<string, []>("input_15_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp32, [1, 512, 384]> input_15 = layer_norm(axes = input_15_axes_0, beta = model_encoder_layer_0_attention_output_LayerNorm_bias, epsilon = var_17, gamma = model_encoder_layer_0_attention_output_LayerNorm_weight, x = input_13)[name = tensor<string, []>("input_15")];
            tensor<fp32, [1, 512, 1536]> input_17 = linear(bias = model_encoder_layer_0_intermediate_dense_bias, weight = model_encoder_layer_0_intermediate_dense_weight, x = input_15)[name = tensor<string, []>("linear_4")];
            tensor<string, []> input_19_mode_0 = const()[name = tensor<string, []>("input_19_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp32, [1, 512, 1536]> input_19 = gelu(mode = input_19_mode_0, x = input_17)[name = tensor<string, []>("input_19")];
            tensor<fp32, [1, 512, 384]> input_21 = linear(bias = model_encoder_layer_0_output_dense_bias, weight = model_encoder_layer_0_output_dense_weight, x = input_19)[name = tensor<string, []>("linear_5")];
            tensor<fp32, [1, 512, 384]> input_23 = add(x = input_21, y = input_15)[name = tensor<string, []>("input_23")];
            tensor<int32, [1]> hidden_states_7_axes_0 = const()[name = tensor<string, []>("hidden_states_7_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp32, [1, 512, 384]> hidden_states_7 = layer_norm(axes = hidden_states_7_axes_0, beta = model_encoder_layer_0_output_LayerNorm_bias, epsilon = var_17, gamma = model_encoder_layer_0_output_LayerNorm_weight, x = input_23)[name = tensor<string, []>("hidden_states_7")];
            tensor<fp32, [1, 512, 384]> x_13 = linear(bias = model_encoder_layer_1_attention_self_query_bias, weight = model_encoder_layer_1_attention_self_query_weight, x = hidden_states_7)[name = tensor<string, []>("linear_6")];
            tensor<int32, [4]> var_178 = const()[name = tensor<string, []>("op_178"), val = tensor<int32, [4]>([1, 512, 12, 32])];
            tensor<fp32, [1, 512, 12, 32]> x_15 = reshape(shape = var_178, x = x_13)[name = tensor<string, []>("x_15")];
            tensor<fp32, [1, 512, 384]> x_17 = linear(bias = model_encoder_layer_1_attention_self_key_bias, weight = model_encoder_layer_1_attention_self_key_weight, x = hidden_states_7)[name = tensor<string, []>("linear_7")];
            tensor<int32, [4]> var_187 = const()[name = tensor<string, []>("op_187"), val = tensor<int32, [4]>([1, 512, 12, 32])];
            tensor<fp32, [1, 512, 12, 32]> x_19 = reshape(shape = var_187, x = x_17)[name = tensor<string, []>("x_19")];
            tensor<fp32, [1, 512, 384]> x_21 = linear(bias = model_encoder_layer_1_attention_self_value_bias, weight = model_encoder_layer_1_attention_self_value_weight, x = hidden_states_7)[name = tensor<string, []>("linear_8")];
            tensor<int32, [4]> var_196 = const()[name = tensor<string, []>("op_196"), val = tensor<int32, [4]>([1, 512, 12, 32])];
            tensor<fp32, [1, 512, 12, 32]> x_23 = reshape(shape = var_196, x = x_21)[name = tensor<string, []>("x_23")];
            tensor<int32, [4]> var_198 = const()[name = tensor<string, []>("op_198"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp32, []> mul_1_y_0 = const()[name = tensor<string, []>("mul_1_y_0"), val = tensor<fp32, []>(0x1.6a09e6p-3)];
            tensor<fp32, [1, 512, 12, 32]> mul_1 = mul(x = x_15, y = mul_1_y_0)[name = tensor<string, []>("mul_1")];
            tensor<bool, []> matmul_1_transpose_y_0 = const()[name = tensor<string, []>("matmul_1_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> matmul_1_transpose_x_0 = const()[name = tensor<string, []>("matmul_1_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_50_perm_0 = const()[name = tensor<string, []>("transpose_50_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_51_perm_0 = const()[name = tensor<string, []>("transpose_51_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<fp32, [1, 12, 512, 32]> transpose_51 = transpose(perm = transpose_51_perm_0, x = x_19)[name = tensor<string, []>("transpose_113")];
            tensor<fp32, [1, 12, 512, 32]> transpose_50 = transpose(perm = transpose_50_perm_0, x = mul_1)[name = tensor<string, []>("transpose_114")];
            tensor<fp32, [1, 12, 512, 512]> matmul_1 = matmul(transpose_x = matmul_1_transpose_x_0, transpose_y = matmul_1_transpose_y_0, x = transpose_50, y = transpose_51)[name = tensor<string, []>("matmul_1")];
            tensor<fp32, [1, 12, 512, 512]> add_1 = add(x = matmul_1, y = attention_mask_1)[name = tensor<string, []>("add_1")];
            tensor<int32, []> softmax_1_axis_0 = const()[name = tensor<string, []>("softmax_1_axis_0"), val = tensor<int32, []>(-1)];
            tensor<fp32, [1, 12, 512, 512]> softmax_1 = softmax(axis = softmax_1_axis_0, x = add_1)[name = tensor<string, []>("softmax_1")];
            tensor<bool, []> attn_output_5_transpose_x_0 = const()[name = tensor<string, []>("attn_output_5_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_5_transpose_y_0 = const()[name = tensor<string, []>("attn_output_5_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp32, [1, 12, 512, 32]> value_layer_3 = transpose(perm = var_198, x = x_23)[name = tensor<string, []>("transpose_115")];
            tensor<fp32, [1, 12, 512, 32]> attn_output_5 = matmul(transpose_x = attn_output_5_transpose_x_0, transpose_y = attn_output_5_transpose_y_0, x = softmax_1, y = value_layer_3)[name = tensor<string, []>("attn_output_5")];
            tensor<int32, [4]> attn_output_7_perm_0 = const()[name = tensor<string, []>("attn_output_7_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_202 = const()[name = tensor<string, []>("op_202"), val = tensor<int32, [3]>([1, 512, 384])];
            tensor<fp32, [1, 512, 12, 32]> attn_output_7 = transpose(perm = attn_output_7_perm_0, x = attn_output_5)[name = tensor<string, []>("transpose_112")];
            tensor<fp32, [1, 512, 384]> input_25 = reshape(shape = var_202, x = attn_output_7)[name = tensor<string, []>("input_25")];
            tensor<fp32, [1, 512, 384]> input_27 = linear(bias = model_encoder_layer_1_attention_output_dense_bias, weight = model_encoder_layer_1_attention_output_dense_weight, x = input_25)[name = tensor<string, []>("linear_9")];
            tensor<fp32, [1, 512, 384]> input_29 = add(x = input_27, y = hidden_states_7)[name = tensor<string, []>("input_29")];
            tensor<int32, [1]> input_31_axes_0 = const()[name = tensor<string, []>("input_31_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp32, [1, 512, 384]> input_31 = layer_norm(axes = input_31_axes_0, beta = model_encoder_layer_1_attention_output_LayerNorm_bias, epsilon = var_17, gamma = model_encoder_layer_1_attention_output_LayerNorm_weight, x = input_29)[name = tensor<string, []>("input_31")];
            tensor<fp32, [1, 512, 1536]> input_33 = linear(bias = model_encoder_layer_1_intermediate_dense_bias, weight = model_encoder_layer_1_intermediate_dense_weight, x = input_31)[name = tensor<string, []>("linear_10")];
            tensor<string, []> input_35_mode_0 = const()[name = tensor<string, []>("input_35_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp32, [1, 512, 1536]> input_35 = gelu(mode = input_35_mode_0, x = input_33)[name = tensor<string, []>("input_35")];
            tensor<fp32, [1, 512, 384]> input_37 = linear(bias = model_encoder_layer_1_output_dense_bias, weight = model_encoder_layer_1_output_dense_weight, x = input_35)[name = tensor<string, []>("linear_11")];
            tensor<fp32, [1, 512, 384]> input_39 = add(x = input_37, y = input_31)[name = tensor<string, []>("input_39")];
            tensor<int32, [1]> hidden_states_13_axes_0 = const()[name = tensor<string, []>("hidden_states_13_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp32, [1, 512, 384]> hidden_states_13 = layer_norm(axes = hidden_states_13_axes_0, beta = model_encoder_layer_1_output_LayerNorm_bias, epsilon = var_17, gamma = model_encoder_layer_1_output_LayerNorm_weight, x = input_39)[name = tensor<string, []>("hidden_states_13")];
            tensor<fp32, [1, 512, 384]> x_25 = linear(bias = model_encoder_layer_2_attention_self_query_bias, weight = model_encoder_layer_2_attention_self_query_weight, x = hidden_states_13)[name = tensor<string, []>("linear_12")];
            tensor<int32, [4]> var_246 = const()[name = tensor<string, []>("op_246"), val = tensor<int32, [4]>([1, 512, 12, 32])];
            tensor<fp32, [1, 512, 12, 32]> x_27 = reshape(shape = var_246, x = x_25)[name = tensor<string, []>("x_27")];
            tensor<fp32, [1, 512, 384]> x_29 = linear(bias = model_encoder_layer_2_attention_self_key_bias, weight = model_encoder_layer_2_attention_self_key_weight, x = hidden_states_13)[name = tensor<string, []>("linear_13")];
            tensor<int32, [4]> var_255 = const()[name = tensor<string, []>("op_255"), val = tensor<int32, [4]>([1, 512, 12, 32])];
            tensor<fp32, [1, 512, 12, 32]> x_31 = reshape(shape = var_255, x = x_29)[name = tensor<string, []>("x_31")];
            tensor<fp32, [1, 512, 384]> x_33 = linear(bias = model_encoder_layer_2_attention_self_value_bias, weight = model_encoder_layer_2_attention_self_value_weight, x = hidden_states_13)[name = tensor<string, []>("linear_14")];
            tensor<int32, [4]> var_264 = const()[name = tensor<string, []>("op_264"), val = tensor<int32, [4]>([1, 512, 12, 32])];
            tensor<fp32, [1, 512, 12, 32]> x_35 = reshape(shape = var_264, x = x_33)[name = tensor<string, []>("x_35")];
            tensor<int32, [4]> var_266 = const()[name = tensor<string, []>("op_266"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp32, []> mul_2_y_0 = const()[name = tensor<string, []>("mul_2_y_0"), val = tensor<fp32, []>(0x1.6a09e6p-3)];
            tensor<fp32, [1, 512, 12, 32]> mul_2 = mul(x = x_27, y = mul_2_y_0)[name = tensor<string, []>("mul_2")];
            tensor<bool, []> matmul_2_transpose_y_0 = const()[name = tensor<string, []>("matmul_2_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> matmul_2_transpose_x_0 = const()[name = tensor<string, []>("matmul_2_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_52_perm_0 = const()[name = tensor<string, []>("transpose_52_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_53_perm_0 = const()[name = tensor<string, []>("transpose_53_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<fp32, [1, 12, 512, 32]> transpose_53 = transpose(perm = transpose_53_perm_0, x = x_31)[name = tensor<string, []>("transpose_109")];
            tensor<fp32, [1, 12, 512, 32]> transpose_52 = transpose(perm = transpose_52_perm_0, x = mul_2)[name = tensor<string, []>("transpose_110")];
            tensor<fp32, [1, 12, 512, 512]> matmul_2 = matmul(transpose_x = matmul_2_transpose_x_0, transpose_y = matmul_2_transpose_y_0, x = transpose_52, y = transpose_53)[name = tensor<string, []>("matmul_2")];
            tensor<fp32, [1, 12, 512, 512]> add_2 = add(x = matmul_2, y = attention_mask_1)[name = tensor<string, []>("add_2")];
            tensor<int32, []> softmax_2_axis_0 = const()[name = tensor<string, []>("softmax_2_axis_0"), val = tensor<int32, []>(-1)];
            tensor<fp32, [1, 12, 512, 512]> softmax_2 = softmax(axis = softmax_2_axis_0, x = add_2)[name = tensor<string, []>("softmax_2")];
            tensor<bool, []> attn_output_9_transpose_x_0 = const()[name = tensor<string, []>("attn_output_9_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_9_transpose_y_0 = const()[name = tensor<string, []>("attn_output_9_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp32, [1, 12, 512, 32]> value_layer_5 = transpose(perm = var_266, x = x_35)[name = tensor<string, []>("transpose_111")];
            tensor<fp32, [1, 12, 512, 32]> attn_output_9 = matmul(transpose_x = attn_output_9_transpose_x_0, transpose_y = attn_output_9_transpose_y_0, x = softmax_2, y = value_layer_5)[name = tensor<string, []>("attn_output_9")];
            tensor<int32, [4]> attn_output_11_perm_0 = const()[name = tensor<string, []>("attn_output_11_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_270 = const()[name = tensor<string, []>("op_270"), val = tensor<int32, [3]>([1, 512, 384])];
            tensor<fp32, [1, 512, 12, 32]> attn_output_11 = transpose(perm = attn_output_11_perm_0, x = attn_output_9)[name = tensor<string, []>("transpose_108")];
            tensor<fp32, [1, 512, 384]> input_41 = reshape(shape = var_270, x = attn_output_11)[name = tensor<string, []>("input_41")];
            tensor<fp32, [1, 512, 384]> input_43 = linear(bias = model_encoder_layer_2_attention_output_dense_bias, weight = model_encoder_layer_2_attention_output_dense_weight, x = input_41)[name = tensor<string, []>("linear_15")];
            tensor<fp32, [1, 512, 384]> input_45 = add(x = input_43, y = hidden_states_13)[name = tensor<string, []>("input_45")];
            tensor<int32, [1]> input_47_axes_0 = const()[name = tensor<string, []>("input_47_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp32, [1, 512, 384]> input_47 = layer_norm(axes = input_47_axes_0, beta = model_encoder_layer_2_attention_output_LayerNorm_bias, epsilon = var_17, gamma = model_encoder_layer_2_attention_output_LayerNorm_weight, x = input_45)[name = tensor<string, []>("input_47")];
            tensor<fp32, [1, 512, 1536]> input_49 = linear(bias = model_encoder_layer_2_intermediate_dense_bias, weight = model_encoder_layer_2_intermediate_dense_weight, x = input_47)[name = tensor<string, []>("linear_16")];
            tensor<string, []> input_51_mode_0 = const()[name = tensor<string, []>("input_51_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp32, [1, 512, 1536]> input_51 = gelu(mode = input_51_mode_0, x = input_49)[name = tensor<string, []>("input_51")];
            tensor<fp32, [1, 512, 384]> input_53 = linear(bias = model_encoder_layer_2_output_dense_bias, weight = model_encoder_layer_2_output_dense_weight, x = input_51)[name = tensor<string, []>("linear_17")];
            tensor<fp32, [1, 512, 384]> input_55 = add(x = input_53, y = input_47)[name = tensor<string, []>("input_55")];
            tensor<int32, [1]> hidden_states_19_axes_0 = const()[name = tensor<string, []>("hidden_states_19_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp32, [1, 512, 384]> hidden_states_19 = layer_norm(axes = hidden_states_19_axes_0, beta = model_encoder_layer_2_output_LayerNorm_bias, epsilon = var_17, gamma = model_encoder_layer_2_output_LayerNorm_weight, x = input_55)[name = tensor<string, []>("hidden_states_19")];
            tensor<fp32, [1, 512, 384]> x_37 = linear(bias = model_encoder_layer_3_attention_self_query_bias, weight = model_encoder_layer_3_attention_self_query_weight, x = hidden_states_19)[name = tensor<string, []>("linear_18")];
            tensor<int32, [4]> var_314 = const()[name = tensor<string, []>("op_314"), val = tensor<int32, [4]>([1, 512, 12, 32])];
            tensor<fp32, [1, 512, 12, 32]> x_39 = reshape(shape = var_314, x = x_37)[name = tensor<string, []>("x_39")];
            tensor<fp32, [1, 512, 384]> x_41 = linear(bias = model_encoder_layer_3_attention_self_key_bias, weight = model_encoder_layer_3_attention_self_key_weight, x = hidden_states_19)[name = tensor<string, []>("linear_19")];
            tensor<int32, [4]> var_323 = const()[name = tensor<string, []>("op_323"), val = tensor<int32, [4]>([1, 512, 12, 32])];
            tensor<fp32, [1, 512, 12, 32]> x_43 = reshape(shape = var_323, x = x_41)[name = tensor<string, []>("x_43")];
            tensor<fp32, [1, 512, 384]> x_45 = linear(bias = model_encoder_layer_3_attention_self_value_bias, weight = model_encoder_layer_3_attention_self_value_weight, x = hidden_states_19)[name = tensor<string, []>("linear_20")];
            tensor<int32, [4]> var_332 = const()[name = tensor<string, []>("op_332"), val = tensor<int32, [4]>([1, 512, 12, 32])];
            tensor<fp32, [1, 512, 12, 32]> x_47 = reshape(shape = var_332, x = x_45)[name = tensor<string, []>("x_47")];
            tensor<int32, [4]> var_334 = const()[name = tensor<string, []>("op_334"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp32, []> mul_3_y_0 = const()[name = tensor<string, []>("mul_3_y_0"), val = tensor<fp32, []>(0x1.6a09e6p-3)];
            tensor<fp32, [1, 512, 12, 32]> mul_3 = mul(x = x_39, y = mul_3_y_0)[name = tensor<string, []>("mul_3")];
            tensor<bool, []> matmul_3_transpose_y_0 = const()[name = tensor<string, []>("matmul_3_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> matmul_3_transpose_x_0 = const()[name = tensor<string, []>("matmul_3_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_54_perm_0 = const()[name = tensor<string, []>("transpose_54_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_55_perm_0 = const()[name = tensor<string, []>("transpose_55_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<fp32, [1, 12, 512, 32]> transpose_55 = transpose(perm = transpose_55_perm_0, x = x_43)[name = tensor<string, []>("transpose_105")];
            tensor<fp32, [1, 12, 512, 32]> transpose_54 = transpose(perm = transpose_54_perm_0, x = mul_3)[name = tensor<string, []>("transpose_106")];
            tensor<fp32, [1, 12, 512, 512]> matmul_3 = matmul(transpose_x = matmul_3_transpose_x_0, transpose_y = matmul_3_transpose_y_0, x = transpose_54, y = transpose_55)[name = tensor<string, []>("matmul_3")];
            tensor<fp32, [1, 12, 512, 512]> add_3 = add(x = matmul_3, y = attention_mask_1)[name = tensor<string, []>("add_3")];
            tensor<int32, []> softmax_3_axis_0 = const()[name = tensor<string, []>("softmax_3_axis_0"), val = tensor<int32, []>(-1)];
            tensor<fp32, [1, 12, 512, 512]> softmax_3 = softmax(axis = softmax_3_axis_0, x = add_3)[name = tensor<string, []>("softmax_3")];
            tensor<bool, []> attn_output_13_transpose_x_0 = const()[name = tensor<string, []>("attn_output_13_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_13_transpose_y_0 = const()[name = tensor<string, []>("attn_output_13_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp32, [1, 12, 512, 32]> value_layer_7 = transpose(perm = var_334, x = x_47)[name = tensor<string, []>("transpose_107")];
            tensor<fp32, [1, 12, 512, 32]> attn_output_13 = matmul(transpose_x = attn_output_13_transpose_x_0, transpose_y = attn_output_13_transpose_y_0, x = softmax_3, y = value_layer_7)[name = tensor<string, []>("attn_output_13")];
            tensor<int32, [4]> attn_output_15_perm_0 = const()[name = tensor<string, []>("attn_output_15_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_338 = const()[name = tensor<string, []>("op_338"), val = tensor<int32, [3]>([1, 512, 384])];
            tensor<fp32, [1, 512, 12, 32]> attn_output_15 = transpose(perm = attn_output_15_perm_0, x = attn_output_13)[name = tensor<string, []>("transpose_104")];
            tensor<fp32, [1, 512, 384]> input_57 = reshape(shape = var_338, x = attn_output_15)[name = tensor<string, []>("input_57")];
            tensor<fp32, [1, 512, 384]> input_59 = linear(bias = model_encoder_layer_3_attention_output_dense_bias, weight = model_encoder_layer_3_attention_output_dense_weight, x = input_57)[name = tensor<string, []>("linear_21")];
            tensor<fp32, [1, 512, 384]> input_61 = add(x = input_59, y = hidden_states_19)[name = tensor<string, []>("input_61")];
            tensor<int32, [1]> input_63_axes_0 = const()[name = tensor<string, []>("input_63_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp32, [1, 512, 384]> input_63 = layer_norm(axes = input_63_axes_0, beta = model_encoder_layer_3_attention_output_LayerNorm_bias, epsilon = var_17, gamma = model_encoder_layer_3_attention_output_LayerNorm_weight, x = input_61)[name = tensor<string, []>("input_63")];
            tensor<fp32, [1, 512, 1536]> input_65 = linear(bias = model_encoder_layer_3_intermediate_dense_bias, weight = model_encoder_layer_3_intermediate_dense_weight, x = input_63)[name = tensor<string, []>("linear_22")];
            tensor<string, []> input_67_mode_0 = const()[name = tensor<string, []>("input_67_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp32, [1, 512, 1536]> input_67 = gelu(mode = input_67_mode_0, x = input_65)[name = tensor<string, []>("input_67")];
            tensor<fp32, [1, 512, 384]> input_69 = linear(bias = model_encoder_layer_3_output_dense_bias, weight = model_encoder_layer_3_output_dense_weight, x = input_67)[name = tensor<string, []>("linear_23")];
            tensor<fp32, [1, 512, 384]> input_71 = add(x = input_69, y = input_63)[name = tensor<string, []>("input_71")];
            tensor<int32, [1]> hidden_states_25_axes_0 = const()[name = tensor<string, []>("hidden_states_25_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp32, [1, 512, 384]> hidden_states_25 = layer_norm(axes = hidden_states_25_axes_0, beta = model_encoder_layer_3_output_LayerNorm_bias, epsilon = var_17, gamma = model_encoder_layer_3_output_LayerNorm_weight, x = input_71)[name = tensor<string, []>("hidden_states_25")];
            tensor<fp32, [1, 512, 384]> x_49 = linear(bias = model_encoder_layer_4_attention_self_query_bias, weight = model_encoder_layer_4_attention_self_query_weight, x = hidden_states_25)[name = tensor<string, []>("linear_24")];
            tensor<int32, [4]> var_382 = const()[name = tensor<string, []>("op_382"), val = tensor<int32, [4]>([1, 512, 12, 32])];
            tensor<fp32, [1, 512, 12, 32]> x_51 = reshape(shape = var_382, x = x_49)[name = tensor<string, []>("x_51")];
            tensor<fp32, [1, 512, 384]> x_53 = linear(bias = model_encoder_layer_4_attention_self_key_bias, weight = model_encoder_layer_4_attention_self_key_weight, x = hidden_states_25)[name = tensor<string, []>("linear_25")];
            tensor<int32, [4]> var_391 = const()[name = tensor<string, []>("op_391"), val = tensor<int32, [4]>([1, 512, 12, 32])];
            tensor<fp32, [1, 512, 12, 32]> x_55 = reshape(shape = var_391, x = x_53)[name = tensor<string, []>("x_55")];
            tensor<fp32, [1, 512, 384]> x_57 = linear(bias = model_encoder_layer_4_attention_self_value_bias, weight = model_encoder_layer_4_attention_self_value_weight, x = hidden_states_25)[name = tensor<string, []>("linear_26")];
            tensor<int32, [4]> var_400 = const()[name = tensor<string, []>("op_400"), val = tensor<int32, [4]>([1, 512, 12, 32])];
            tensor<fp32, [1, 512, 12, 32]> x_59 = reshape(shape = var_400, x = x_57)[name = tensor<string, []>("x_59")];
            tensor<int32, [4]> var_402 = const()[name = tensor<string, []>("op_402"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp32, []> mul_4_y_0 = const()[name = tensor<string, []>("mul_4_y_0"), val = tensor<fp32, []>(0x1.6a09e6p-3)];
            tensor<fp32, [1, 512, 12, 32]> mul_4 = mul(x = x_51, y = mul_4_y_0)[name = tensor<string, []>("mul_4")];
            tensor<bool, []> matmul_4_transpose_y_0 = const()[name = tensor<string, []>("matmul_4_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> matmul_4_transpose_x_0 = const()[name = tensor<string, []>("matmul_4_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_56_perm_0 = const()[name = tensor<string, []>("transpose_56_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_57_perm_0 = const()[name = tensor<string, []>("transpose_57_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<fp32, [1, 12, 512, 32]> transpose_57 = transpose(perm = transpose_57_perm_0, x = x_55)[name = tensor<string, []>("transpose_101")];
            tensor<fp32, [1, 12, 512, 32]> transpose_56 = transpose(perm = transpose_56_perm_0, x = mul_4)[name = tensor<string, []>("transpose_102")];
            tensor<fp32, [1, 12, 512, 512]> matmul_4 = matmul(transpose_x = matmul_4_transpose_x_0, transpose_y = matmul_4_transpose_y_0, x = transpose_56, y = transpose_57)[name = tensor<string, []>("matmul_4")];
            tensor<fp32, [1, 12, 512, 512]> add_4 = add(x = matmul_4, y = attention_mask_1)[name = tensor<string, []>("add_4")];
            tensor<int32, []> softmax_4_axis_0 = const()[name = tensor<string, []>("softmax_4_axis_0"), val = tensor<int32, []>(-1)];
            tensor<fp32, [1, 12, 512, 512]> softmax_4 = softmax(axis = softmax_4_axis_0, x = add_4)[name = tensor<string, []>("softmax_4")];
            tensor<bool, []> attn_output_17_transpose_x_0 = const()[name = tensor<string, []>("attn_output_17_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_17_transpose_y_0 = const()[name = tensor<string, []>("attn_output_17_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp32, [1, 12, 512, 32]> value_layer_9 = transpose(perm = var_402, x = x_59)[name = tensor<string, []>("transpose_103")];
            tensor<fp32, [1, 12, 512, 32]> attn_output_17 = matmul(transpose_x = attn_output_17_transpose_x_0, transpose_y = attn_output_17_transpose_y_0, x = softmax_4, y = value_layer_9)[name = tensor<string, []>("attn_output_17")];
            tensor<int32, [4]> attn_output_19_perm_0 = const()[name = tensor<string, []>("attn_output_19_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_406 = const()[name = tensor<string, []>("op_406"), val = tensor<int32, [3]>([1, 512, 384])];
            tensor<fp32, [1, 512, 12, 32]> attn_output_19 = transpose(perm = attn_output_19_perm_0, x = attn_output_17)[name = tensor<string, []>("transpose_100")];
            tensor<fp32, [1, 512, 384]> input_73 = reshape(shape = var_406, x = attn_output_19)[name = tensor<string, []>("input_73")];
            tensor<fp32, [1, 512, 384]> input_75 = linear(bias = model_encoder_layer_4_attention_output_dense_bias, weight = model_encoder_layer_4_attention_output_dense_weight, x = input_73)[name = tensor<string, []>("linear_27")];
            tensor<fp32, [1, 512, 384]> input_77 = add(x = input_75, y = hidden_states_25)[name = tensor<string, []>("input_77")];
            tensor<int32, [1]> input_79_axes_0 = const()[name = tensor<string, []>("input_79_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp32, [1, 512, 384]> input_79 = layer_norm(axes = input_79_axes_0, beta = model_encoder_layer_4_attention_output_LayerNorm_bias, epsilon = var_17, gamma = model_encoder_layer_4_attention_output_LayerNorm_weight, x = input_77)[name = tensor<string, []>("input_79")];
            tensor<fp32, [1, 512, 1536]> input_81 = linear(bias = model_encoder_layer_4_intermediate_dense_bias, weight = model_encoder_layer_4_intermediate_dense_weight, x = input_79)[name = tensor<string, []>("linear_28")];
            tensor<string, []> input_83_mode_0 = const()[name = tensor<string, []>("input_83_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp32, [1, 512, 1536]> input_83 = gelu(mode = input_83_mode_0, x = input_81)[name = tensor<string, []>("input_83")];
            tensor<fp32, [1, 512, 384]> input_85 = linear(bias = model_encoder_layer_4_output_dense_bias, weight = model_encoder_layer_4_output_dense_weight, x = input_83)[name = tensor<string, []>("linear_29")];
            tensor<fp32, [1, 512, 384]> input_87 = add(x = input_85, y = input_79)[name = tensor<string, []>("input_87")];
            tensor<int32, [1]> hidden_states_31_axes_0 = const()[name = tensor<string, []>("hidden_states_31_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp32, [1, 512, 384]> hidden_states_31 = layer_norm(axes = hidden_states_31_axes_0, beta = model_encoder_layer_4_output_LayerNorm_bias, epsilon = var_17, gamma = model_encoder_layer_4_output_LayerNorm_weight, x = input_87)[name = tensor<string, []>("hidden_states_31")];
            tensor<fp32, [1, 512, 384]> x_61 = linear(bias = model_encoder_layer_5_attention_self_query_bias, weight = model_encoder_layer_5_attention_self_query_weight, x = hidden_states_31)[name = tensor<string, []>("linear_30")];
            tensor<int32, [4]> var_450 = const()[name = tensor<string, []>("op_450"), val = tensor<int32, [4]>([1, 512, 12, 32])];
            tensor<fp32, [1, 512, 12, 32]> x_63 = reshape(shape = var_450, x = x_61)[name = tensor<string, []>("x_63")];
            tensor<fp32, [1, 512, 384]> x_65 = linear(bias = model_encoder_layer_5_attention_self_key_bias, weight = model_encoder_layer_5_attention_self_key_weight, x = hidden_states_31)[name = tensor<string, []>("linear_31")];
            tensor<int32, [4]> var_459 = const()[name = tensor<string, []>("op_459"), val = tensor<int32, [4]>([1, 512, 12, 32])];
            tensor<fp32, [1, 512, 12, 32]> x_67 = reshape(shape = var_459, x = x_65)[name = tensor<string, []>("x_67")];
            tensor<fp32, [1, 512, 384]> x_69 = linear(bias = model_encoder_layer_5_attention_self_value_bias, weight = model_encoder_layer_5_attention_self_value_weight, x = hidden_states_31)[name = tensor<string, []>("linear_32")];
            tensor<int32, [4]> var_468 = const()[name = tensor<string, []>("op_468"), val = tensor<int32, [4]>([1, 512, 12, 32])];
            tensor<fp32, [1, 512, 12, 32]> x_71 = reshape(shape = var_468, x = x_69)[name = tensor<string, []>("x_71")];
            tensor<int32, [4]> var_470 = const()[name = tensor<string, []>("op_470"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp32, []> mul_5_y_0 = const()[name = tensor<string, []>("mul_5_y_0"), val = tensor<fp32, []>(0x1.6a09e6p-3)];
            tensor<fp32, [1, 512, 12, 32]> mul_5 = mul(x = x_63, y = mul_5_y_0)[name = tensor<string, []>("mul_5")];
            tensor<bool, []> matmul_5_transpose_y_0 = const()[name = tensor<string, []>("matmul_5_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> matmul_5_transpose_x_0 = const()[name = tensor<string, []>("matmul_5_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_58_perm_0 = const()[name = tensor<string, []>("transpose_58_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_59_perm_0 = const()[name = tensor<string, []>("transpose_59_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<fp32, [1, 12, 512, 32]> transpose_59 = transpose(perm = transpose_59_perm_0, x = x_67)[name = tensor<string, []>("transpose_97")];
            tensor<fp32, [1, 12, 512, 32]> transpose_58 = transpose(perm = transpose_58_perm_0, x = mul_5)[name = tensor<string, []>("transpose_98")];
            tensor<fp32, [1, 12, 512, 512]> matmul_5 = matmul(transpose_x = matmul_5_transpose_x_0, transpose_y = matmul_5_transpose_y_0, x = transpose_58, y = transpose_59)[name = tensor<string, []>("matmul_5")];
            tensor<fp32, [1, 12, 512, 512]> add_5 = add(x = matmul_5, y = attention_mask_1)[name = tensor<string, []>("add_5")];
            tensor<int32, []> softmax_5_axis_0 = const()[name = tensor<string, []>("softmax_5_axis_0"), val = tensor<int32, []>(-1)];
            tensor<fp32, [1, 12, 512, 512]> softmax_5 = softmax(axis = softmax_5_axis_0, x = add_5)[name = tensor<string, []>("softmax_5")];
            tensor<bool, []> attn_output_21_transpose_x_0 = const()[name = tensor<string, []>("attn_output_21_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_21_transpose_y_0 = const()[name = tensor<string, []>("attn_output_21_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp32, [1, 12, 512, 32]> value_layer_11 = transpose(perm = var_470, x = x_71)[name = tensor<string, []>("transpose_99")];
            tensor<fp32, [1, 12, 512, 32]> attn_output_21 = matmul(transpose_x = attn_output_21_transpose_x_0, transpose_y = attn_output_21_transpose_y_0, x = softmax_5, y = value_layer_11)[name = tensor<string, []>("attn_output_21")];
            tensor<int32, [4]> attn_output_23_perm_0 = const()[name = tensor<string, []>("attn_output_23_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_474 = const()[name = tensor<string, []>("op_474"), val = tensor<int32, [3]>([1, 512, 384])];
            tensor<fp32, [1, 512, 12, 32]> attn_output_23 = transpose(perm = attn_output_23_perm_0, x = attn_output_21)[name = tensor<string, []>("transpose_96")];
            tensor<fp32, [1, 512, 384]> input_89 = reshape(shape = var_474, x = attn_output_23)[name = tensor<string, []>("input_89")];
            tensor<fp32, [1, 512, 384]> input_91 = linear(bias = model_encoder_layer_5_attention_output_dense_bias, weight = model_encoder_layer_5_attention_output_dense_weight, x = input_89)[name = tensor<string, []>("linear_33")];
            tensor<fp32, [1, 512, 384]> input_93 = add(x = input_91, y = hidden_states_31)[name = tensor<string, []>("input_93")];
            tensor<int32, [1]> input_95_axes_0 = const()[name = tensor<string, []>("input_95_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp32, [1, 512, 384]> input_95 = layer_norm(axes = input_95_axes_0, beta = model_encoder_layer_5_attention_output_LayerNorm_bias, epsilon = var_17, gamma = model_encoder_layer_5_attention_output_LayerNorm_weight, x = input_93)[name = tensor<string, []>("input_95")];
            tensor<fp32, [1, 512, 1536]> input_97 = linear(bias = model_encoder_layer_5_intermediate_dense_bias, weight = model_encoder_layer_5_intermediate_dense_weight, x = input_95)[name = tensor<string, []>("linear_34")];
            tensor<string, []> input_99_mode_0 = const()[name = tensor<string, []>("input_99_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp32, [1, 512, 1536]> input_99 = gelu(mode = input_99_mode_0, x = input_97)[name = tensor<string, []>("input_99")];
            tensor<fp32, [1, 512, 384]> input_101 = linear(bias = model_encoder_layer_5_output_dense_bias, weight = model_encoder_layer_5_output_dense_weight, x = input_99)[name = tensor<string, []>("linear_35")];
            tensor<fp32, [1, 512, 384]> input_103 = add(x = input_101, y = input_95)[name = tensor<string, []>("input_103")];
            tensor<int32, [1]> hidden_states_37_axes_0 = const()[name = tensor<string, []>("hidden_states_37_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp32, [1, 512, 384]> hidden_states_37 = layer_norm(axes = hidden_states_37_axes_0, beta = model_encoder_layer_5_output_LayerNorm_bias, epsilon = var_17, gamma = model_encoder_layer_5_output_LayerNorm_weight, x = input_103)[name = tensor<string, []>("hidden_states_37")];
            tensor<fp32, [1, 512, 384]> x_73 = linear(bias = model_encoder_layer_6_attention_self_query_bias, weight = model_encoder_layer_6_attention_self_query_weight, x = hidden_states_37)[name = tensor<string, []>("linear_36")];
            tensor<int32, [4]> var_518 = const()[name = tensor<string, []>("op_518"), val = tensor<int32, [4]>([1, 512, 12, 32])];
            tensor<fp32, [1, 512, 12, 32]> x_75 = reshape(shape = var_518, x = x_73)[name = tensor<string, []>("x_75")];
            tensor<fp32, [1, 512, 384]> x_77 = linear(bias = model_encoder_layer_6_attention_self_key_bias, weight = model_encoder_layer_6_attention_self_key_weight, x = hidden_states_37)[name = tensor<string, []>("linear_37")];
            tensor<int32, [4]> var_527 = const()[name = tensor<string, []>("op_527"), val = tensor<int32, [4]>([1, 512, 12, 32])];
            tensor<fp32, [1, 512, 12, 32]> x_79 = reshape(shape = var_527, x = x_77)[name = tensor<string, []>("x_79")];
            tensor<fp32, [1, 512, 384]> x_81 = linear(bias = model_encoder_layer_6_attention_self_value_bias, weight = model_encoder_layer_6_attention_self_value_weight, x = hidden_states_37)[name = tensor<string, []>("linear_38")];
            tensor<int32, [4]> var_536 = const()[name = tensor<string, []>("op_536"), val = tensor<int32, [4]>([1, 512, 12, 32])];
            tensor<fp32, [1, 512, 12, 32]> x_83 = reshape(shape = var_536, x = x_81)[name = tensor<string, []>("x_83")];
            tensor<int32, [4]> var_538 = const()[name = tensor<string, []>("op_538"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp32, []> mul_6_y_0 = const()[name = tensor<string, []>("mul_6_y_0"), val = tensor<fp32, []>(0x1.6a09e6p-3)];
            tensor<fp32, [1, 512, 12, 32]> mul_6 = mul(x = x_75, y = mul_6_y_0)[name = tensor<string, []>("mul_6")];
            tensor<bool, []> matmul_6_transpose_y_0 = const()[name = tensor<string, []>("matmul_6_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> matmul_6_transpose_x_0 = const()[name = tensor<string, []>("matmul_6_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_60_perm_0 = const()[name = tensor<string, []>("transpose_60_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_61_perm_0 = const()[name = tensor<string, []>("transpose_61_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<fp32, [1, 12, 512, 32]> transpose_61 = transpose(perm = transpose_61_perm_0, x = x_79)[name = tensor<string, []>("transpose_93")];
            tensor<fp32, [1, 12, 512, 32]> transpose_60 = transpose(perm = transpose_60_perm_0, x = mul_6)[name = tensor<string, []>("transpose_94")];
            tensor<fp32, [1, 12, 512, 512]> matmul_6 = matmul(transpose_x = matmul_6_transpose_x_0, transpose_y = matmul_6_transpose_y_0, x = transpose_60, y = transpose_61)[name = tensor<string, []>("matmul_6")];
            tensor<fp32, [1, 12, 512, 512]> add_6 = add(x = matmul_6, y = attention_mask_1)[name = tensor<string, []>("add_6")];
            tensor<int32, []> softmax_6_axis_0 = const()[name = tensor<string, []>("softmax_6_axis_0"), val = tensor<int32, []>(-1)];
            tensor<fp32, [1, 12, 512, 512]> softmax_6 = softmax(axis = softmax_6_axis_0, x = add_6)[name = tensor<string, []>("softmax_6")];
            tensor<bool, []> attn_output_25_transpose_x_0 = const()[name = tensor<string, []>("attn_output_25_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_25_transpose_y_0 = const()[name = tensor<string, []>("attn_output_25_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp32, [1, 12, 512, 32]> value_layer_13 = transpose(perm = var_538, x = x_83)[name = tensor<string, []>("transpose_95")];
            tensor<fp32, [1, 12, 512, 32]> attn_output_25 = matmul(transpose_x = attn_output_25_transpose_x_0, transpose_y = attn_output_25_transpose_y_0, x = softmax_6, y = value_layer_13)[name = tensor<string, []>("attn_output_25")];
            tensor<int32, [4]> attn_output_27_perm_0 = const()[name = tensor<string, []>("attn_output_27_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_542 = const()[name = tensor<string, []>("op_542"), val = tensor<int32, [3]>([1, 512, 384])];
            tensor<fp32, [1, 512, 12, 32]> attn_output_27 = transpose(perm = attn_output_27_perm_0, x = attn_output_25)[name = tensor<string, []>("transpose_92")];
            tensor<fp32, [1, 512, 384]> input_105 = reshape(shape = var_542, x = attn_output_27)[name = tensor<string, []>("input_105")];
            tensor<fp32, [1, 512, 384]> input_107 = linear(bias = model_encoder_layer_6_attention_output_dense_bias, weight = model_encoder_layer_6_attention_output_dense_weight, x = input_105)[name = tensor<string, []>("linear_39")];
            tensor<fp32, [1, 512, 384]> input_109 = add(x = input_107, y = hidden_states_37)[name = tensor<string, []>("input_109")];
            tensor<int32, [1]> input_111_axes_0 = const()[name = tensor<string, []>("input_111_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp32, [1, 512, 384]> input_111 = layer_norm(axes = input_111_axes_0, beta = model_encoder_layer_6_attention_output_LayerNorm_bias, epsilon = var_17, gamma = model_encoder_layer_6_attention_output_LayerNorm_weight, x = input_109)[name = tensor<string, []>("input_111")];
            tensor<fp32, [1, 512, 1536]> input_113 = linear(bias = model_encoder_layer_6_intermediate_dense_bias, weight = model_encoder_layer_6_intermediate_dense_weight, x = input_111)[name = tensor<string, []>("linear_40")];
            tensor<string, []> input_115_mode_0 = const()[name = tensor<string, []>("input_115_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp32, [1, 512, 1536]> input_115 = gelu(mode = input_115_mode_0, x = input_113)[name = tensor<string, []>("input_115")];
            tensor<fp32, [1, 512, 384]> input_117 = linear(bias = model_encoder_layer_6_output_dense_bias, weight = model_encoder_layer_6_output_dense_weight, x = input_115)[name = tensor<string, []>("linear_41")];
            tensor<fp32, [1, 512, 384]> input_119 = add(x = input_117, y = input_111)[name = tensor<string, []>("input_119")];
            tensor<int32, [1]> hidden_states_43_axes_0 = const()[name = tensor<string, []>("hidden_states_43_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp32, [1, 512, 384]> hidden_states_43 = layer_norm(axes = hidden_states_43_axes_0, beta = model_encoder_layer_6_output_LayerNorm_bias, epsilon = var_17, gamma = model_encoder_layer_6_output_LayerNorm_weight, x = input_119)[name = tensor<string, []>("hidden_states_43")];
            tensor<fp32, [1, 512, 384]> x_85 = linear(bias = model_encoder_layer_7_attention_self_query_bias, weight = model_encoder_layer_7_attention_self_query_weight, x = hidden_states_43)[name = tensor<string, []>("linear_42")];
            tensor<int32, [4]> var_586 = const()[name = tensor<string, []>("op_586"), val = tensor<int32, [4]>([1, 512, 12, 32])];
            tensor<fp32, [1, 512, 12, 32]> x_87 = reshape(shape = var_586, x = x_85)[name = tensor<string, []>("x_87")];
            tensor<fp32, [1, 512, 384]> x_89 = linear(bias = model_encoder_layer_7_attention_self_key_bias, weight = model_encoder_layer_7_attention_self_key_weight, x = hidden_states_43)[name = tensor<string, []>("linear_43")];
            tensor<int32, [4]> var_595 = const()[name = tensor<string, []>("op_595"), val = tensor<int32, [4]>([1, 512, 12, 32])];
            tensor<fp32, [1, 512, 12, 32]> x_91 = reshape(shape = var_595, x = x_89)[name = tensor<string, []>("x_91")];
            tensor<fp32, [1, 512, 384]> x_93 = linear(bias = model_encoder_layer_7_attention_self_value_bias, weight = model_encoder_layer_7_attention_self_value_weight, x = hidden_states_43)[name = tensor<string, []>("linear_44")];
            tensor<int32, [4]> var_604 = const()[name = tensor<string, []>("op_604"), val = tensor<int32, [4]>([1, 512, 12, 32])];
            tensor<fp32, [1, 512, 12, 32]> x_95 = reshape(shape = var_604, x = x_93)[name = tensor<string, []>("x_95")];
            tensor<int32, [4]> var_606 = const()[name = tensor<string, []>("op_606"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp32, []> mul_7_y_0 = const()[name = tensor<string, []>("mul_7_y_0"), val = tensor<fp32, []>(0x1.6a09e6p-3)];
            tensor<fp32, [1, 512, 12, 32]> mul_7 = mul(x = x_87, y = mul_7_y_0)[name = tensor<string, []>("mul_7")];
            tensor<bool, []> matmul_7_transpose_y_0 = const()[name = tensor<string, []>("matmul_7_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> matmul_7_transpose_x_0 = const()[name = tensor<string, []>("matmul_7_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_62_perm_0 = const()[name = tensor<string, []>("transpose_62_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_63_perm_0 = const()[name = tensor<string, []>("transpose_63_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<fp32, [1, 12, 512, 32]> transpose_63 = transpose(perm = transpose_63_perm_0, x = x_91)[name = tensor<string, []>("transpose_89")];
            tensor<fp32, [1, 12, 512, 32]> transpose_62 = transpose(perm = transpose_62_perm_0, x = mul_7)[name = tensor<string, []>("transpose_90")];
            tensor<fp32, [1, 12, 512, 512]> matmul_7 = matmul(transpose_x = matmul_7_transpose_x_0, transpose_y = matmul_7_transpose_y_0, x = transpose_62, y = transpose_63)[name = tensor<string, []>("matmul_7")];
            tensor<fp32, [1, 12, 512, 512]> add_7 = add(x = matmul_7, y = attention_mask_1)[name = tensor<string, []>("add_7")];
            tensor<int32, []> softmax_7_axis_0 = const()[name = tensor<string, []>("softmax_7_axis_0"), val = tensor<int32, []>(-1)];
            tensor<fp32, [1, 12, 512, 512]> softmax_7 = softmax(axis = softmax_7_axis_0, x = add_7)[name = tensor<string, []>("softmax_7")];
            tensor<bool, []> attn_output_29_transpose_x_0 = const()[name = tensor<string, []>("attn_output_29_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_29_transpose_y_0 = const()[name = tensor<string, []>("attn_output_29_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp32, [1, 12, 512, 32]> value_layer_15 = transpose(perm = var_606, x = x_95)[name = tensor<string, []>("transpose_91")];
            tensor<fp32, [1, 12, 512, 32]> attn_output_29 = matmul(transpose_x = attn_output_29_transpose_x_0, transpose_y = attn_output_29_transpose_y_0, x = softmax_7, y = value_layer_15)[name = tensor<string, []>("attn_output_29")];
            tensor<int32, [4]> attn_output_31_perm_0 = const()[name = tensor<string, []>("attn_output_31_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_610 = const()[name = tensor<string, []>("op_610"), val = tensor<int32, [3]>([1, 512, 384])];
            tensor<fp32, [1, 512, 12, 32]> attn_output_31 = transpose(perm = attn_output_31_perm_0, x = attn_output_29)[name = tensor<string, []>("transpose_88")];
            tensor<fp32, [1, 512, 384]> input_121 = reshape(shape = var_610, x = attn_output_31)[name = tensor<string, []>("input_121")];
            tensor<fp32, [1, 512, 384]> input_123 = linear(bias = model_encoder_layer_7_attention_output_dense_bias, weight = model_encoder_layer_7_attention_output_dense_weight, x = input_121)[name = tensor<string, []>("linear_45")];
            tensor<fp32, [1, 512, 384]> input_125 = add(x = input_123, y = hidden_states_43)[name = tensor<string, []>("input_125")];
            tensor<int32, [1]> input_127_axes_0 = const()[name = tensor<string, []>("input_127_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp32, [1, 512, 384]> input_127 = layer_norm(axes = input_127_axes_0, beta = model_encoder_layer_7_attention_output_LayerNorm_bias, epsilon = var_17, gamma = model_encoder_layer_7_attention_output_LayerNorm_weight, x = input_125)[name = tensor<string, []>("input_127")];
            tensor<fp32, [1, 512, 1536]> input_129 = linear(bias = model_encoder_layer_7_intermediate_dense_bias, weight = model_encoder_layer_7_intermediate_dense_weight, x = input_127)[name = tensor<string, []>("linear_46")];
            tensor<string, []> input_131_mode_0 = const()[name = tensor<string, []>("input_131_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp32, [1, 512, 1536]> input_131 = gelu(mode = input_131_mode_0, x = input_129)[name = tensor<string, []>("input_131")];
            tensor<fp32, [1, 512, 384]> input_133 = linear(bias = model_encoder_layer_7_output_dense_bias, weight = model_encoder_layer_7_output_dense_weight, x = input_131)[name = tensor<string, []>("linear_47")];
            tensor<fp32, [1, 512, 384]> input_135 = add(x = input_133, y = input_127)[name = tensor<string, []>("input_135")];
            tensor<int32, [1]> hidden_states_49_axes_0 = const()[name = tensor<string, []>("hidden_states_49_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp32, [1, 512, 384]> hidden_states_49 = layer_norm(axes = hidden_states_49_axes_0, beta = model_encoder_layer_7_output_LayerNorm_bias, epsilon = var_17, gamma = model_encoder_layer_7_output_LayerNorm_weight, x = input_135)[name = tensor<string, []>("hidden_states_49")];
            tensor<fp32, [1, 512, 384]> x_97 = linear(bias = model_encoder_layer_8_attention_self_query_bias, weight = model_encoder_layer_8_attention_self_query_weight, x = hidden_states_49)[name = tensor<string, []>("linear_48")];
            tensor<int32, [4]> var_654 = const()[name = tensor<string, []>("op_654"), val = tensor<int32, [4]>([1, 512, 12, 32])];
            tensor<fp32, [1, 512, 12, 32]> x_99 = reshape(shape = var_654, x = x_97)[name = tensor<string, []>("x_99")];
            tensor<fp32, [1, 512, 384]> x_101 = linear(bias = model_encoder_layer_8_attention_self_key_bias, weight = model_encoder_layer_8_attention_self_key_weight, x = hidden_states_49)[name = tensor<string, []>("linear_49")];
            tensor<int32, [4]> var_663 = const()[name = tensor<string, []>("op_663"), val = tensor<int32, [4]>([1, 512, 12, 32])];
            tensor<fp32, [1, 512, 12, 32]> x_103 = reshape(shape = var_663, x = x_101)[name = tensor<string, []>("x_103")];
            tensor<fp32, [1, 512, 384]> x_105 = linear(bias = model_encoder_layer_8_attention_self_value_bias, weight = model_encoder_layer_8_attention_self_value_weight, x = hidden_states_49)[name = tensor<string, []>("linear_50")];
            tensor<int32, [4]> var_672 = const()[name = tensor<string, []>("op_672"), val = tensor<int32, [4]>([1, 512, 12, 32])];
            tensor<fp32, [1, 512, 12, 32]> x_107 = reshape(shape = var_672, x = x_105)[name = tensor<string, []>("x_107")];
            tensor<int32, [4]> var_674 = const()[name = tensor<string, []>("op_674"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp32, []> mul_8_y_0 = const()[name = tensor<string, []>("mul_8_y_0"), val = tensor<fp32, []>(0x1.6a09e6p-3)];
            tensor<fp32, [1, 512, 12, 32]> mul_8 = mul(x = x_99, y = mul_8_y_0)[name = tensor<string, []>("mul_8")];
            tensor<bool, []> matmul_8_transpose_y_0 = const()[name = tensor<string, []>("matmul_8_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> matmul_8_transpose_x_0 = const()[name = tensor<string, []>("matmul_8_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_64_perm_0 = const()[name = tensor<string, []>("transpose_64_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_65_perm_0 = const()[name = tensor<string, []>("transpose_65_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<fp32, [1, 12, 512, 32]> transpose_65 = transpose(perm = transpose_65_perm_0, x = x_103)[name = tensor<string, []>("transpose_85")];
            tensor<fp32, [1, 12, 512, 32]> transpose_64 = transpose(perm = transpose_64_perm_0, x = mul_8)[name = tensor<string, []>("transpose_86")];
            tensor<fp32, [1, 12, 512, 512]> matmul_8 = matmul(transpose_x = matmul_8_transpose_x_0, transpose_y = matmul_8_transpose_y_0, x = transpose_64, y = transpose_65)[name = tensor<string, []>("matmul_8")];
            tensor<fp32, [1, 12, 512, 512]> add_8 = add(x = matmul_8, y = attention_mask_1)[name = tensor<string, []>("add_8")];
            tensor<int32, []> softmax_8_axis_0 = const()[name = tensor<string, []>("softmax_8_axis_0"), val = tensor<int32, []>(-1)];
            tensor<fp32, [1, 12, 512, 512]> softmax_8 = softmax(axis = softmax_8_axis_0, x = add_8)[name = tensor<string, []>("softmax_8")];
            tensor<bool, []> attn_output_33_transpose_x_0 = const()[name = tensor<string, []>("attn_output_33_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_33_transpose_y_0 = const()[name = tensor<string, []>("attn_output_33_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp32, [1, 12, 512, 32]> value_layer_17 = transpose(perm = var_674, x = x_107)[name = tensor<string, []>("transpose_87")];
            tensor<fp32, [1, 12, 512, 32]> attn_output_33 = matmul(transpose_x = attn_output_33_transpose_x_0, transpose_y = attn_output_33_transpose_y_0, x = softmax_8, y = value_layer_17)[name = tensor<string, []>("attn_output_33")];
            tensor<int32, [4]> attn_output_35_perm_0 = const()[name = tensor<string, []>("attn_output_35_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_678 = const()[name = tensor<string, []>("op_678"), val = tensor<int32, [3]>([1, 512, 384])];
            tensor<fp32, [1, 512, 12, 32]> attn_output_35 = transpose(perm = attn_output_35_perm_0, x = attn_output_33)[name = tensor<string, []>("transpose_84")];
            tensor<fp32, [1, 512, 384]> input_137 = reshape(shape = var_678, x = attn_output_35)[name = tensor<string, []>("input_137")];
            tensor<fp32, [1, 512, 384]> input_139 = linear(bias = model_encoder_layer_8_attention_output_dense_bias, weight = model_encoder_layer_8_attention_output_dense_weight, x = input_137)[name = tensor<string, []>("linear_51")];
            tensor<fp32, [1, 512, 384]> input_141 = add(x = input_139, y = hidden_states_49)[name = tensor<string, []>("input_141")];
            tensor<int32, [1]> input_143_axes_0 = const()[name = tensor<string, []>("input_143_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp32, [1, 512, 384]> input_143 = layer_norm(axes = input_143_axes_0, beta = model_encoder_layer_8_attention_output_LayerNorm_bias, epsilon = var_17, gamma = model_encoder_layer_8_attention_output_LayerNorm_weight, x = input_141)[name = tensor<string, []>("input_143")];
            tensor<fp32, [1, 512, 1536]> input_145 = linear(bias = model_encoder_layer_8_intermediate_dense_bias, weight = model_encoder_layer_8_intermediate_dense_weight, x = input_143)[name = tensor<string, []>("linear_52")];
            tensor<string, []> input_147_mode_0 = const()[name = tensor<string, []>("input_147_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp32, [1, 512, 1536]> input_147 = gelu(mode = input_147_mode_0, x = input_145)[name = tensor<string, []>("input_147")];
            tensor<fp32, [1, 512, 384]> input_149 = linear(bias = model_encoder_layer_8_output_dense_bias, weight = model_encoder_layer_8_output_dense_weight, x = input_147)[name = tensor<string, []>("linear_53")];
            tensor<fp32, [1, 512, 384]> input_151 = add(x = input_149, y = input_143)[name = tensor<string, []>("input_151")];
            tensor<int32, [1]> hidden_states_55_axes_0 = const()[name = tensor<string, []>("hidden_states_55_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp32, [1, 512, 384]> hidden_states_55 = layer_norm(axes = hidden_states_55_axes_0, beta = model_encoder_layer_8_output_LayerNorm_bias, epsilon = var_17, gamma = model_encoder_layer_8_output_LayerNorm_weight, x = input_151)[name = tensor<string, []>("hidden_states_55")];
            tensor<fp32, [1, 512, 384]> x_109 = linear(bias = model_encoder_layer_9_attention_self_query_bias, weight = model_encoder_layer_9_attention_self_query_weight, x = hidden_states_55)[name = tensor<string, []>("linear_54")];
            tensor<int32, [4]> var_722 = const()[name = tensor<string, []>("op_722"), val = tensor<int32, [4]>([1, 512, 12, 32])];
            tensor<fp32, [1, 512, 12, 32]> x_111 = reshape(shape = var_722, x = x_109)[name = tensor<string, []>("x_111")];
            tensor<fp32, [1, 512, 384]> x_113 = linear(bias = model_encoder_layer_9_attention_self_key_bias, weight = model_encoder_layer_9_attention_self_key_weight, x = hidden_states_55)[name = tensor<string, []>("linear_55")];
            tensor<int32, [4]> var_731 = const()[name = tensor<string, []>("op_731"), val = tensor<int32, [4]>([1, 512, 12, 32])];
            tensor<fp32, [1, 512, 12, 32]> x_115 = reshape(shape = var_731, x = x_113)[name = tensor<string, []>("x_115")];
            tensor<fp32, [1, 512, 384]> x_117 = linear(bias = model_encoder_layer_9_attention_self_value_bias, weight = model_encoder_layer_9_attention_self_value_weight, x = hidden_states_55)[name = tensor<string, []>("linear_56")];
            tensor<int32, [4]> var_740 = const()[name = tensor<string, []>("op_740"), val = tensor<int32, [4]>([1, 512, 12, 32])];
            tensor<fp32, [1, 512, 12, 32]> x_119 = reshape(shape = var_740, x = x_117)[name = tensor<string, []>("x_119")];
            tensor<int32, [4]> var_742 = const()[name = tensor<string, []>("op_742"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp32, []> mul_9_y_0 = const()[name = tensor<string, []>("mul_9_y_0"), val = tensor<fp32, []>(0x1.6a09e6p-3)];
            tensor<fp32, [1, 512, 12, 32]> mul_9 = mul(x = x_111, y = mul_9_y_0)[name = tensor<string, []>("mul_9")];
            tensor<bool, []> matmul_9_transpose_y_0 = const()[name = tensor<string, []>("matmul_9_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> matmul_9_transpose_x_0 = const()[name = tensor<string, []>("matmul_9_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_66_perm_0 = const()[name = tensor<string, []>("transpose_66_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_67_perm_0 = const()[name = tensor<string, []>("transpose_67_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<fp32, [1, 12, 512, 32]> transpose_67 = transpose(perm = transpose_67_perm_0, x = x_115)[name = tensor<string, []>("transpose_81")];
            tensor<fp32, [1, 12, 512, 32]> transpose_66 = transpose(perm = transpose_66_perm_0, x = mul_9)[name = tensor<string, []>("transpose_82")];
            tensor<fp32, [1, 12, 512, 512]> matmul_9 = matmul(transpose_x = matmul_9_transpose_x_0, transpose_y = matmul_9_transpose_y_0, x = transpose_66, y = transpose_67)[name = tensor<string, []>("matmul_9")];
            tensor<fp32, [1, 12, 512, 512]> add_9 = add(x = matmul_9, y = attention_mask_1)[name = tensor<string, []>("add_9")];
            tensor<int32, []> softmax_9_axis_0 = const()[name = tensor<string, []>("softmax_9_axis_0"), val = tensor<int32, []>(-1)];
            tensor<fp32, [1, 12, 512, 512]> softmax_9 = softmax(axis = softmax_9_axis_0, x = add_9)[name = tensor<string, []>("softmax_9")];
            tensor<bool, []> attn_output_37_transpose_x_0 = const()[name = tensor<string, []>("attn_output_37_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_37_transpose_y_0 = const()[name = tensor<string, []>("attn_output_37_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp32, [1, 12, 512, 32]> value_layer_19 = transpose(perm = var_742, x = x_119)[name = tensor<string, []>("transpose_83")];
            tensor<fp32, [1, 12, 512, 32]> attn_output_37 = matmul(transpose_x = attn_output_37_transpose_x_0, transpose_y = attn_output_37_transpose_y_0, x = softmax_9, y = value_layer_19)[name = tensor<string, []>("attn_output_37")];
            tensor<int32, [4]> attn_output_39_perm_0 = const()[name = tensor<string, []>("attn_output_39_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_746 = const()[name = tensor<string, []>("op_746"), val = tensor<int32, [3]>([1, 512, 384])];
            tensor<fp32, [1, 512, 12, 32]> attn_output_39 = transpose(perm = attn_output_39_perm_0, x = attn_output_37)[name = tensor<string, []>("transpose_80")];
            tensor<fp32, [1, 512, 384]> input_153 = reshape(shape = var_746, x = attn_output_39)[name = tensor<string, []>("input_153")];
            tensor<fp32, [1, 512, 384]> input_155 = linear(bias = model_encoder_layer_9_attention_output_dense_bias, weight = model_encoder_layer_9_attention_output_dense_weight, x = input_153)[name = tensor<string, []>("linear_57")];
            tensor<fp32, [1, 512, 384]> input_157 = add(x = input_155, y = hidden_states_55)[name = tensor<string, []>("input_157")];
            tensor<int32, [1]> input_159_axes_0 = const()[name = tensor<string, []>("input_159_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp32, [1, 512, 384]> input_159 = layer_norm(axes = input_159_axes_0, beta = model_encoder_layer_9_attention_output_LayerNorm_bias, epsilon = var_17, gamma = model_encoder_layer_9_attention_output_LayerNorm_weight, x = input_157)[name = tensor<string, []>("input_159")];
            tensor<fp32, [1, 512, 1536]> input_161 = linear(bias = model_encoder_layer_9_intermediate_dense_bias, weight = model_encoder_layer_9_intermediate_dense_weight, x = input_159)[name = tensor<string, []>("linear_58")];
            tensor<string, []> input_163_mode_0 = const()[name = tensor<string, []>("input_163_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp32, [1, 512, 1536]> input_163 = gelu(mode = input_163_mode_0, x = input_161)[name = tensor<string, []>("input_163")];
            tensor<fp32, [1, 512, 384]> input_165 = linear(bias = model_encoder_layer_9_output_dense_bias, weight = model_encoder_layer_9_output_dense_weight, x = input_163)[name = tensor<string, []>("linear_59")];
            tensor<fp32, [1, 512, 384]> input_167 = add(x = input_165, y = input_159)[name = tensor<string, []>("input_167")];
            tensor<int32, [1]> hidden_states_61_axes_0 = const()[name = tensor<string, []>("hidden_states_61_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp32, [1, 512, 384]> hidden_states_61 = layer_norm(axes = hidden_states_61_axes_0, beta = model_encoder_layer_9_output_LayerNorm_bias, epsilon = var_17, gamma = model_encoder_layer_9_output_LayerNorm_weight, x = input_167)[name = tensor<string, []>("hidden_states_61")];
            tensor<fp32, [1, 512, 384]> x_121 = linear(bias = model_encoder_layer_10_attention_self_query_bias, weight = model_encoder_layer_10_attention_self_query_weight, x = hidden_states_61)[name = tensor<string, []>("linear_60")];
            tensor<int32, [4]> var_790 = const()[name = tensor<string, []>("op_790"), val = tensor<int32, [4]>([1, 512, 12, 32])];
            tensor<fp32, [1, 512, 12, 32]> x_123 = reshape(shape = var_790, x = x_121)[name = tensor<string, []>("x_123")];
            tensor<fp32, [1, 512, 384]> x_125 = linear(bias = model_encoder_layer_10_attention_self_key_bias, weight = model_encoder_layer_10_attention_self_key_weight, x = hidden_states_61)[name = tensor<string, []>("linear_61")];
            tensor<int32, [4]> var_799 = const()[name = tensor<string, []>("op_799"), val = tensor<int32, [4]>([1, 512, 12, 32])];
            tensor<fp32, [1, 512, 12, 32]> x_127 = reshape(shape = var_799, x = x_125)[name = tensor<string, []>("x_127")];
            tensor<fp32, [1, 512, 384]> x_129 = linear(bias = model_encoder_layer_10_attention_self_value_bias, weight = model_encoder_layer_10_attention_self_value_weight, x = hidden_states_61)[name = tensor<string, []>("linear_62")];
            tensor<int32, [4]> var_808 = const()[name = tensor<string, []>("op_808"), val = tensor<int32, [4]>([1, 512, 12, 32])];
            tensor<fp32, [1, 512, 12, 32]> x_131 = reshape(shape = var_808, x = x_129)[name = tensor<string, []>("x_131")];
            tensor<int32, [4]> var_810 = const()[name = tensor<string, []>("op_810"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp32, []> mul_10_y_0 = const()[name = tensor<string, []>("mul_10_y_0"), val = tensor<fp32, []>(0x1.6a09e6p-3)];
            tensor<fp32, [1, 512, 12, 32]> mul_10 = mul(x = x_123, y = mul_10_y_0)[name = tensor<string, []>("mul_10")];
            tensor<bool, []> matmul_10_transpose_y_0 = const()[name = tensor<string, []>("matmul_10_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> matmul_10_transpose_x_0 = const()[name = tensor<string, []>("matmul_10_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_68_perm_0 = const()[name = tensor<string, []>("transpose_68_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_69_perm_0 = const()[name = tensor<string, []>("transpose_69_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<fp32, [1, 12, 512, 32]> transpose_69 = transpose(perm = transpose_69_perm_0, x = x_127)[name = tensor<string, []>("transpose_77")];
            tensor<fp32, [1, 12, 512, 32]> transpose_68 = transpose(perm = transpose_68_perm_0, x = mul_10)[name = tensor<string, []>("transpose_78")];
            tensor<fp32, [1, 12, 512, 512]> matmul_10 = matmul(transpose_x = matmul_10_transpose_x_0, transpose_y = matmul_10_transpose_y_0, x = transpose_68, y = transpose_69)[name = tensor<string, []>("matmul_10")];
            tensor<fp32, [1, 12, 512, 512]> add_10 = add(x = matmul_10, y = attention_mask_1)[name = tensor<string, []>("add_10")];
            tensor<int32, []> softmax_10_axis_0 = const()[name = tensor<string, []>("softmax_10_axis_0"), val = tensor<int32, []>(-1)];
            tensor<fp32, [1, 12, 512, 512]> softmax_10 = softmax(axis = softmax_10_axis_0, x = add_10)[name = tensor<string, []>("softmax_10")];
            tensor<bool, []> attn_output_41_transpose_x_0 = const()[name = tensor<string, []>("attn_output_41_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_41_transpose_y_0 = const()[name = tensor<string, []>("attn_output_41_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp32, [1, 12, 512, 32]> value_layer_21 = transpose(perm = var_810, x = x_131)[name = tensor<string, []>("transpose_79")];
            tensor<fp32, [1, 12, 512, 32]> attn_output_41 = matmul(transpose_x = attn_output_41_transpose_x_0, transpose_y = attn_output_41_transpose_y_0, x = softmax_10, y = value_layer_21)[name = tensor<string, []>("attn_output_41")];
            tensor<int32, [4]> attn_output_43_perm_0 = const()[name = tensor<string, []>("attn_output_43_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_814 = const()[name = tensor<string, []>("op_814"), val = tensor<int32, [3]>([1, 512, 384])];
            tensor<fp32, [1, 512, 12, 32]> attn_output_43 = transpose(perm = attn_output_43_perm_0, x = attn_output_41)[name = tensor<string, []>("transpose_76")];
            tensor<fp32, [1, 512, 384]> input_169 = reshape(shape = var_814, x = attn_output_43)[name = tensor<string, []>("input_169")];
            tensor<fp32, [1, 512, 384]> input_171 = linear(bias = model_encoder_layer_10_attention_output_dense_bias, weight = model_encoder_layer_10_attention_output_dense_weight, x = input_169)[name = tensor<string, []>("linear_63")];
            tensor<fp32, [1, 512, 384]> input_173 = add(x = input_171, y = hidden_states_61)[name = tensor<string, []>("input_173")];
            tensor<int32, [1]> input_175_axes_0 = const()[name = tensor<string, []>("input_175_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp32, [1, 512, 384]> input_175 = layer_norm(axes = input_175_axes_0, beta = model_encoder_layer_10_attention_output_LayerNorm_bias, epsilon = var_17, gamma = model_encoder_layer_10_attention_output_LayerNorm_weight, x = input_173)[name = tensor<string, []>("input_175")];
            tensor<fp32, [1, 512, 1536]> input_177 = linear(bias = model_encoder_layer_10_intermediate_dense_bias, weight = model_encoder_layer_10_intermediate_dense_weight, x = input_175)[name = tensor<string, []>("linear_64")];
            tensor<string, []> input_179_mode_0 = const()[name = tensor<string, []>("input_179_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp32, [1, 512, 1536]> input_179 = gelu(mode = input_179_mode_0, x = input_177)[name = tensor<string, []>("input_179")];
            tensor<fp32, [1, 512, 384]> input_181 = linear(bias = model_encoder_layer_10_output_dense_bias, weight = model_encoder_layer_10_output_dense_weight, x = input_179)[name = tensor<string, []>("linear_65")];
            tensor<fp32, [1, 512, 384]> input_183 = add(x = input_181, y = input_175)[name = tensor<string, []>("input_183")];
            tensor<int32, [1]> hidden_states_67_axes_0 = const()[name = tensor<string, []>("hidden_states_67_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp32, [1, 512, 384]> hidden_states_67 = layer_norm(axes = hidden_states_67_axes_0, beta = model_encoder_layer_10_output_LayerNorm_bias, epsilon = var_17, gamma = model_encoder_layer_10_output_LayerNorm_weight, x = input_183)[name = tensor<string, []>("hidden_states_67")];
            tensor<fp32, [1, 512, 384]> x_133 = linear(bias = model_encoder_layer_11_attention_self_query_bias, weight = model_encoder_layer_11_attention_self_query_weight, x = hidden_states_67)[name = tensor<string, []>("linear_66")];
            tensor<int32, [4]> var_858 = const()[name = tensor<string, []>("op_858"), val = tensor<int32, [4]>([1, 512, 12, 32])];
            tensor<fp32, [1, 512, 12, 32]> x_135 = reshape(shape = var_858, x = x_133)[name = tensor<string, []>("x_135")];
            tensor<fp32, [1, 512, 384]> x_137 = linear(bias = model_encoder_layer_11_attention_self_key_bias, weight = model_encoder_layer_11_attention_self_key_weight, x = hidden_states_67)[name = tensor<string, []>("linear_67")];
            tensor<int32, [4]> var_867 = const()[name = tensor<string, []>("op_867"), val = tensor<int32, [4]>([1, 512, 12, 32])];
            tensor<fp32, [1, 512, 12, 32]> x_139 = reshape(shape = var_867, x = x_137)[name = tensor<string, []>("x_139")];
            tensor<fp32, [1, 512, 384]> x_141 = linear(bias = model_encoder_layer_11_attention_self_value_bias, weight = model_encoder_layer_11_attention_self_value_weight, x = hidden_states_67)[name = tensor<string, []>("linear_68")];
            tensor<int32, [4]> var_876 = const()[name = tensor<string, []>("op_876"), val = tensor<int32, [4]>([1, 512, 12, 32])];
            tensor<fp32, [1, 512, 12, 32]> x = reshape(shape = var_876, x = x_141)[name = tensor<string, []>("x")];
            tensor<int32, [4]> var_878 = const()[name = tensor<string, []>("op_878"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<fp32, []> mul_11_y_0 = const()[name = tensor<string, []>("mul_11_y_0"), val = tensor<fp32, []>(0x1.6a09e6p-3)];
            tensor<fp32, [1, 512, 12, 32]> mul_11 = mul(x = x_135, y = mul_11_y_0)[name = tensor<string, []>("mul_11")];
            tensor<bool, []> matmul_11_transpose_y_0 = const()[name = tensor<string, []>("matmul_11_transpose_y_0"), val = tensor<bool, []>(true)];
            tensor<bool, []> matmul_11_transpose_x_0 = const()[name = tensor<string, []>("matmul_11_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<int32, [4]> transpose_70_perm_0 = const()[name = tensor<string, []>("transpose_70_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<int32, [4]> transpose_71_perm_0 = const()[name = tensor<string, []>("transpose_71_perm_0"), val = tensor<int32, [4]>([0, 2, -3, -1])];
            tensor<fp32, [1, 12, 512, 32]> transpose_71 = transpose(perm = transpose_71_perm_0, x = x_139)[name = tensor<string, []>("transpose_73")];
            tensor<fp32, [1, 12, 512, 32]> transpose_70 = transpose(perm = transpose_70_perm_0, x = mul_11)[name = tensor<string, []>("transpose_74")];
            tensor<fp32, [1, 12, 512, 512]> matmul_11 = matmul(transpose_x = matmul_11_transpose_x_0, transpose_y = matmul_11_transpose_y_0, x = transpose_70, y = transpose_71)[name = tensor<string, []>("matmul_11")];
            tensor<fp32, [1, 12, 512, 512]> add_11 = add(x = matmul_11, y = attention_mask_1)[name = tensor<string, []>("add_11")];
            tensor<int32, []> softmax_11_axis_0 = const()[name = tensor<string, []>("softmax_11_axis_0"), val = tensor<int32, []>(-1)];
            tensor<fp32, [1, 12, 512, 512]> softmax_11 = softmax(axis = softmax_11_axis_0, x = add_11)[name = tensor<string, []>("softmax_11")];
            tensor<bool, []> attn_output_45_transpose_x_0 = const()[name = tensor<string, []>("attn_output_45_transpose_x_0"), val = tensor<bool, []>(false)];
            tensor<bool, []> attn_output_45_transpose_y_0 = const()[name = tensor<string, []>("attn_output_45_transpose_y_0"), val = tensor<bool, []>(false)];
            tensor<fp32, [1, 12, 512, 32]> value_layer = transpose(perm = var_878, x = x)[name = tensor<string, []>("transpose_75")];
            tensor<fp32, [1, 12, 512, 32]> attn_output_45 = matmul(transpose_x = attn_output_45_transpose_x_0, transpose_y = attn_output_45_transpose_y_0, x = softmax_11, y = value_layer)[name = tensor<string, []>("attn_output_45")];
            tensor<int32, [4]> attn_output_perm_0 = const()[name = tensor<string, []>("attn_output_perm_0"), val = tensor<int32, [4]>([0, 2, 1, 3])];
            tensor<int32, [3]> var_882 = const()[name = tensor<string, []>("op_882"), val = tensor<int32, [3]>([1, 512, 384])];
            tensor<fp32, [1, 512, 12, 32]> attn_output = transpose(perm = attn_output_perm_0, x = attn_output_45)[name = tensor<string, []>("transpose_72")];
            tensor<fp32, [1, 512, 384]> input_185 = reshape(shape = var_882, x = attn_output)[name = tensor<string, []>("input_185")];
            tensor<fp32, [1, 512, 384]> input_187 = linear(bias = model_encoder_layer_11_attention_output_dense_bias, weight = model_encoder_layer_11_attention_output_dense_weight, x = input_185)[name = tensor<string, []>("linear_69")];
            tensor<fp32, [1, 512, 384]> input_189 = add(x = input_187, y = hidden_states_67)[name = tensor<string, []>("input_189")];
            tensor<int32, [1]> input_191_axes_0 = const()[name = tensor<string, []>("input_191_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp32, [1, 512, 384]> input_191 = layer_norm(axes = input_191_axes_0, beta = model_encoder_layer_11_attention_output_LayerNorm_bias, epsilon = var_17, gamma = model_encoder_layer_11_attention_output_LayerNorm_weight, x = input_189)[name = tensor<string, []>("input_191")];
            tensor<fp32, [1, 512, 1536]> input_193 = linear(bias = model_encoder_layer_11_intermediate_dense_bias, weight = model_encoder_layer_11_intermediate_dense_weight, x = input_191)[name = tensor<string, []>("linear_70")];
            tensor<string, []> input_195_mode_0 = const()[name = tensor<string, []>("input_195_mode_0"), val = tensor<string, []>("EXACT")];
            tensor<fp32, [1, 512, 1536]> input_195 = gelu(mode = input_195_mode_0, x = input_193)[name = tensor<string, []>("input_195")];
            tensor<fp32, [1, 512, 384]> input_197 = linear(bias = model_encoder_layer_11_output_dense_bias, weight = model_encoder_layer_11_output_dense_weight, x = input_195)[name = tensor<string, []>("linear_71")];
            tensor<fp32, [1, 512, 384]> input_199 = add(x = input_197, y = input_191)[name = tensor<string, []>("input_199")];
            tensor<int32, [1]> hidden_states_axes_0 = const()[name = tensor<string, []>("hidden_states_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<fp32, [1, 512, 384]> hidden_states = layer_norm(axes = hidden_states_axes_0, beta = model_encoder_layer_11_output_LayerNorm_bias, epsilon = var_17, gamma = model_encoder_layer_11_output_LayerNorm_weight, x = input_199)[name = tensor<string, []>("hidden_states")];
            tensor<int32, [1]> var_912_axes_0 = const()[name = tensor<string, []>("op_912_axes_0"), val = tensor<int32, [1]>([-1])];
            tensor<int32, [1, 512, 1]> var_912 = expand_dims(axes = var_912_axes_0, x = attention_mask)[name = tensor<string, []>("op_912")];
            tensor<int32, [3]> var_927_reps_0 = const()[name = tensor<string, []>("op_927_reps_0"), val = tensor<int32, [3]>([1, 1, 384])];
            tensor<int32, [1, 512, 384]> var_927 = tile(reps = var_927_reps_0, x = var_912)[name = tensor<string, []>("op_927")];
            tensor<string, []> cast_53_dtype_0 = const()[name = tensor<string, []>("cast_53_dtype_0"), val = tensor<string, []>("fp32")];
            tensor<fp32, [1, 512, 384]> cast_53 = cast(dtype = cast_53_dtype_0, x = var_927)[name = tensor<string, []>("cast_58")];
            tensor<fp32, [1, 512, 384]> var_933 = mul(x = hidden_states, y = cast_53)[name = tensor<string, []>("op_933")];
            tensor<int32, [1]> sum_embeddings_axes_0 = const()[name = tensor<string, []>("sum_embeddings_axes_0"), val = tensor<int32, [1]>([1])];
            tensor<bool, []> sum_embeddings_keep_dims_0 = const()[name = tensor<string, []>("sum_embeddings_keep_dims_0"), val = tensor<bool, []>(false)];
            tensor<fp32, [1, 384]> sum_embeddings = reduce_sum(axes = sum_embeddings_axes_0, keep_dims = sum_embeddings_keep_dims_0, x = var_933)[name = tensor<string, []>("sum_embeddings")];
            tensor<int32, [1]> var_943_axes_0 = const()[name = tensor<string, []>("op_943_axes_0"), val = tensor<int32, [1]>([1])];
            tensor<bool, []> var_943_keep_dims_0 = const()[name = tensor<string, []>("op_943_keep_dims_0"), val = tensor<bool, []>(false)];
            tensor<fp32, [1, 384]> var_943 = reduce_sum(axes = var_943_axes_0, keep_dims = var_943_keep_dims_0, x = cast_53)[name = tensor<string, []>("op_943")];
            tensor<fp32, []> var_944 = const()[name = tensor<string, []>("op_944"), val = tensor<fp32, []>(0x1.12e0bep-30)];
            tensor<fp32, []> const_104 = const()[name = tensor<string, []>("const_104"), val = tensor<fp32, []>(0x1.fffffep+127)];
            tensor<fp32, [1, 384]> clip_0 = clip(alpha = var_944, beta = const_104, x = var_943)[name = tensor<string, []>("clip_0")];
            tensor<fp32, [1, 384]> input = real_div(x = sum_embeddings, y = clip_0)[name = tensor<string, []>("input")];
            tensor<int32, [1]> var_950 = const()[name = tensor<string, []>("op_950"), val = tensor<int32, [1]>([1])];
            tensor<bool, []> var_951 = const()[name = tensor<string, []>("op_951"), val = tensor<bool, []>(true)];
            tensor<fp32, [1, 1]> var_953 = reduce_l2_norm(axes = var_950, keep_dims = var_951, x = input)[name = tensor<string, []>("op_953")];
            tensor<fp32, []> var_954 = const()[name = tensor<string, []>("op_954"), val = tensor<fp32, []>(0x1.197998p-40)];
            tensor<fp32, [1, 1]> var_955 = maximum(x = var_953, y = var_954)[name = tensor<string, []>("op_955")];
            tensor<int32, [2]> denom_reps_0 = const()[name = tensor<string, []>("denom_reps_0"), val = tensor<int32, [2]>([1, 384])];
            tensor<fp32, [1, 384]> denom = tile(reps = denom_reps_0, x = var_955)[name = tensor<string, []>("denom")];
            tensor<fp32, [1, 384]> sentence_embedding = real_div(x = input, y = denom)[name = tensor<string, []>("op_957")];
        } -> (sentence_embedding);
}