{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 384)\n",
      "[[-0.02603657 -0.04028142 -0.0407016  -0.0567059   0.09808024 -0.00689326  0.00147932  0.04843688  0.11323299 -0.02740479 -0.00866384  0.0041722   0.05230619 -0.04768711 -0.06603136  0.08920389\n",
      "   0.06334062 -0.0531108   0.00967995 -0.10728    -0.00384981 -0.02598385 -0.00927944  0.07551413  0.06361946  0.01656309  0.04170515  0.01730528  0.01455702 -0.04344152 -0.05670433 -0.04429421\n",
      "   0.07144866 -0.03361619  0.04803946 -0.00959462 -0.08393569 -0.04850754  0.05855654 -0.05139397  0.01839359  0.05547391  0.00980077  0.04608278  0.02681234  0.07292694 -0.06347434  0.05774028\n",
      "   0.00521451 -0.0223504  -0.04456337  0.06401621  0.0201432   0.04503602  0.07350688 -0.04566628 -0.01399929 -0.04260228 -0.08010492 -0.05667777  0.06421689 -0.0662206  -0.01281161  0.00306563\n",
      "   0.06230233  0.06887282 -0.02185547  0.02037258 -0.06924744 -0.05492327 -0.05856651  0.04827426  0.02585801 -0.04206208  0.07226781 -0.00066223  0.02808696 -0.04768767 -0.02578073 -0.0346549\n",
      "  -0.05184536 -0.02213816 -0.02603409  0.00418784 -0.04014505  0.06438648  0.04306499 -0.06464734  0.07835005 -0.04775861  0.03871155 -0.0021935  -0.0278965  -0.02316781 -0.03081977 -0.05162852\n",
      "  -0.06317411  0.06501403  0.03302044 -0.03495993  0.04030043 -0.00946298  0.0334175  -0.06045863 -0.04164437  0.05242613  0.02311893 -0.08106455  0.04201822 -0.07920428 -0.06128573  0.01361946\n",
      "   0.05605038  0.05132582 -0.02488028 -0.00724886 -0.02829193 -0.04666114  0.0488531  -0.04127707  0.1195737  -0.00543758 -0.0664471  -0.0615606  -0.0596544  -0.03149877  0.00002124  0.02896381\n",
      "  -0.00570548  0.01163812  0.0529829   0.05715987  0.03742851  0.07244842 -0.00867338  0.07250956 -0.06899954 -0.05157423 -0.02404262 -0.04570679 -0.03795758  0.05116563 -0.05705468  0.02825828\n",
      "   0.119       0.06702526  0.07962912  0.0138034   0.09016916 -0.06509225  0.02724551 -0.01657289  0.02802205  0.05316252  0.03034372 -0.00838121 -0.03119651 -0.03582877  0.07752741  0.02368231\n",
      "  -0.03352488 -0.08365101 -0.045632   -0.01239439 -0.04529971 -0.05366283 -0.00508505  0.08052137 -0.02365416 -0.05088639 -0.07034076  0.04437143 -0.05328837  0.06672926 -0.02946305  0.04549774\n",
      "  -0.03047303  0.10325804  0.05995305  0.0332171  -0.03317452 -0.01909105 -0.04186944 -0.05407609 -0.03550963 -0.03281735 -0.03436183  0.02623798  0.08710829 -0.03221209  0.06011893  0.02914844\n",
      "  -0.05684852 -0.06085463 -0.03613582  0.00576996 -0.02940009  0.0664039   0.07087301  0.04929261  0.01318032 -0.00586378  0.0495975   0.00660807  0.00326954 -0.03995712 -0.07330823  0.03976686\n",
      "  -0.05351673  0.00975103  0.0657343  -0.02739752 -0.09327185  0.04945796 -0.02640922 -0.04811662 -0.02023635  0.06447945 -0.03439062  0.01399239  0.04641354  0.00337576  0.02538466 -0.06651058\n",
      "  -0.04496679  0.08389921  0.01286559 -0.05759912 -0.03575672  0.04870738 -0.04739233 -0.03980496 -0.03625781 -0.03805088 -0.08773074 -0.06959508 -0.00847899  0.0605951   0.07969318 -0.07081246\n",
      "  -0.08936931 -0.06057398  0.07137255 -0.01208803  0.06577875 -0.03820341 -0.00926073  0.03320891  0.03371769  0.0274949   0.02222546 -0.03850091 -0.06819282 -0.03207812 -0.06575747  0.05194921\n",
      "   0.04517644  0.02427208 -0.03203684  0.01011544  0.03549727  0.01011584  0.09121119  0.05085946  0.05217327  0.07686596 -0.04503369 -0.05324338 -0.05853691 -0.09454808 -0.06227062  0.01004668\n",
      "   0.04691439 -0.08155394 -0.07039263 -0.06269535  0.04923292  0.10943374 -0.09563533 -0.04455083  0.04119622 -0.01810255  0.05851314  0.10388673  0.0561914  -0.03728972 -0.01278675  0.0175415\n",
      "   0.0167901  -0.0243589  -0.00674845 -0.06429786  0.03328782 -0.05609737  0.10601847 -0.02594045  0.0014952   0.04106184 -0.05370851  0.00284642 -0.05031592 -0.02407182  0.06772645  0.09178522\n",
      "  -0.02538844  0.01290046 -0.02147715  0.00510707 -0.01601206  0.04254686  0.11457691  0.07298045 -0.06978742 -0.0778845   0.03534267  0.03449354 -0.01572116  0.04929536 -0.03750179 -0.02385612\n",
      "  -0.02329657 -0.0278185  -0.00166891 -0.04054142  0.04809564  0.02998439 -0.07266621 -0.02555503  0.04405425 -0.03032563  0.02375165 -0.00824628 -0.02347079 -0.00650779 -0.04389343 -0.01901838\n",
      "  -0.01131402  0.01689959 -0.07772236 -0.02221465  0.05264399  0.04042237 -0.05456492  0.04826215 -0.01202582 -0.03829446  0.09095757 -0.08251435 -0.02401281  0.03748612  0.08460325 -0.0638821\n",
      "  -0.00170379  0.04327488 -0.02785971  0.0452118   0.00906494 -0.06582072  0.1295968   0.02732123 -0.0723638  -0.05259331  0.02212602  0.02882134  0.07441573  0.08277623 -0.05466759  0.00978202\n",
      "   0.03124883 -0.03526705  0.03662859  0.07094468 -0.0402846   0.01564865 -0.00978889 -0.06183674 -0.08637218  0.07227731 -0.06914753 -0.06059679  0.01716776  0.06575119  0.04593194  0.05799318]]\n"
     ]
    }
   ],
   "source": [
    "#REFERENCE EMBEDDING OUTPUT FROM ORIGINAL MODEL EXECUTION USING TRANSFORMERS LIBRARY\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "# AD NOTE: I had to drop the sentence_transformers because of keras incompatibility \n",
    "# But I was able to get the same output as sentence-transformers by using the mean pooling method.\n",
    "# Set print options\n",
    "torch.set_printoptions(precision=8, sci_mode=False, linewidth=200, threshold=1000)\n",
    "np.set_printoptions(precision=8, suppress=True, linewidth=200, threshold=1000)\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_name = 'intfloat/multilingual-e5-small'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "model.eval()\n",
    "\n",
    "input_texts = [\n",
    "    \"passage: As a general guideline, the CDC's average requirement of protein for women ages 19 to 70 is 46 grams per day. But, as you can see from this chart, you'll need to increase that if you're expecting or traini     ng for a marathon. Check out the chart below to see how much protein you should be eating each day.\",\n",
    "]\n",
    "\n",
    "# Tokenize inputs\n",
    "inputs = tokenizer(input_texts, padding=True, truncation=True, \n",
    "                  return_tensors='pt', max_length=512)\n",
    "\n",
    "# Get embeddings\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    #AD: note that model outputs are in the shape of [batch_size, sequence_length_max, hidden_size]\n",
    "    #sequence length is always padded to the max length of the sequence (512 in this case)\n",
    "    #we need to use mean pooling to get the embedding for the entire sequence \n",
    "    #and finally normalize the embeddings to have a unit vector length of 1 (L2 norm)\n",
    "    #attention mask is always token 0 for padding tokens and 1 for non-padding tokens [batch_size, sequence_length_max]\n",
    "    #so we need to first expand the attention mask to the size of the token embeddings\n",
    "    #and then use it to mask the token embeddings\n",
    "    #and finally use the attention mask to mask the token embeddings\n",
    "    \n",
    "    # Use mean pooling (attention-masked)\n",
    "    token_embeddings = outputs.last_hidden_state\n",
    "    attention_mask = inputs['attention_mask']\n",
    "    \n",
    "    # prepare attention mask by expanding the attention mask to the size of the token embeddings\n",
    "    attention_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "\n",
    "    #apply attention mask and do mean pooling along the sequence length dimension to get the embedding for the entire sequence \n",
    "    sentence_embedding = torch.sum(token_embeddings * attention_mask_expanded, 1) / torch.clamp(attention_mask_expanded.sum(1), min=1e-9)\n",
    "    \n",
    "    # Normalize the sentence embedding to have a unit vector length of 1 (L2 norm)\n",
    "    sentence_embedding = F.normalize(sentence_embedding, p=2, dim=1)\n",
    "\n",
    "# Convert to numpy for same output format as sentence-transformers\n",
    "sentence_embedding_hf = sentence_embedding.numpy()\n",
    "\n",
    "print(sentence_embedding_hf.shape)\n",
    "print(sentence_embedding_hf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer's output:\n",
      "input_ids: torch.Size([1, 512])\n",
      "\n",
      "attention_mask: torch.Size([1, 512])\n",
      "\n",
      "Running the Pytorch Embeddings Neural Network program...\n",
      "\n",
      "\n",
      "\n",
      "torch.int64\n",
      "torch.int64\n",
      "torch.Size([1, 512])\n",
      "torch.Size([1, 512])\n",
      "Export-time input shape: torch.Size([1, 512])\n",
      "Export-time attention shape: torch.Size([1, 512])\n",
      "INFO:tensorflow:Assets written to: /var/folders/2v/7m66d7dj3q71w4mx7vh6xgf40000gn/T/tmpjjllzqq9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/2v/7m66d7dj3q71w4mx7vh6xgf40000gn/T/tmpjjllzqq9/assets\n",
      "W0000 00:00:1749452264.342669 19994713 tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "W0000 00:00:1749452264.342691 19994713 tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting to ./e5_embedding_model.tflite...\n",
      "TFLite model exported successfully: 470394716 bytes\n",
      "Direct TFLite conversion successful!\n",
      "Running the TFLite Neural Network program...\n",
      "\n",
      "\n",
      "\n",
      "torch.int64\n",
      "torch.int64\n",
      "torch.Size([1, 512])\n",
      "torch.Size([1, 512])\n",
      "Edge model output shape: (1, 384)\n",
      "Edge model output: [[-0.02603654 -0.04028143 -0.04070158 -0.05670586  0.09808024 -0.00689328  0.00147928  0.04843687  0.11323302 -0.02740473 -0.00866385  0.00417222  0.05230613 -0.04768719 -0.0660314   0.08920392\n",
      "   0.06334058 -0.05311074  0.00967995 -0.10727999 -0.00384988 -0.02598386 -0.00927937  0.07551409  0.06361946  0.01656306  0.04170508  0.0173052   0.01455698 -0.04344153 -0.05670442 -0.04429423\n",
      "   0.0714488  -0.03361628  0.04803939 -0.00959461 -0.08393559 -0.04850765  0.05855655 -0.05139392  0.01839353  0.05547389  0.00980082  0.04608277  0.02681228  0.07292698 -0.06347436  0.05774029\n",
      "   0.00521456 -0.02235041 -0.04456339  0.06401615  0.02014327  0.045036    0.07350691 -0.04566626 -0.01399923 -0.04260222 -0.08010497 -0.05667784  0.06421687 -0.06622055 -0.0128117   0.00306563\n",
      "   0.06230233  0.06887282 -0.02185559  0.02037256 -0.06924748 -0.05492333 -0.0585665   0.04827423  0.02585807 -0.0420621   0.07226792 -0.00066228  0.02808692 -0.04768771 -0.02578083 -0.03465485\n",
      "  -0.05184525 -0.02213817 -0.02603407  0.00418786 -0.04014497  0.06438644  0.043065   -0.06464736  0.0783501  -0.04775865  0.03871152 -0.00219345 -0.0278965  -0.02316777 -0.03081975 -0.05162846\n",
      "  -0.0631742   0.06501399  0.03302041 -0.0349599   0.04030042 -0.00946299  0.03341753 -0.06045857 -0.04164434  0.05242629  0.02311891 -0.08106454  0.04201825 -0.07920423 -0.0612857   0.01361953\n",
      "   0.05605033  0.05132569 -0.02488032 -0.00724879 -0.02829196 -0.04666113  0.04885306 -0.0412771   0.11957371 -0.00543749 -0.06644703 -0.06156058 -0.0596544  -0.03149873  0.00002119  0.02896376\n",
      "  -0.00570549  0.01163817  0.05298294  0.05715987  0.03742859  0.07244838 -0.00867335  0.07250954 -0.06899946 -0.05157417 -0.0240427  -0.04570671 -0.03795746  0.0511656  -0.05705471  0.02825827\n",
      "   0.119       0.06702528  0.07962923  0.01380337  0.09016923 -0.06509222  0.02724545 -0.0165728   0.02802203  0.05316261  0.03034374 -0.00838121 -0.0311965  -0.03582879  0.07752742  0.02368232\n",
      "  -0.03352492 -0.08365101 -0.04563198 -0.01239443 -0.04529968 -0.05366286 -0.00508511  0.08052144 -0.02365413 -0.05088635 -0.0703407   0.04437146 -0.0532883   0.06672934 -0.02946305  0.04549772\n",
      "  -0.0304731   0.10325802  0.05995304  0.03321702 -0.03317444 -0.01909098 -0.04186939 -0.05407609 -0.03550968 -0.03281742 -0.03436181  0.02623795  0.08710831 -0.03221209  0.06011892  0.02914837\n",
      "  -0.05684855 -0.06085461 -0.03613582  0.00576994 -0.02940015  0.06640384  0.07087307  0.04929266  0.01318027 -0.00586376  0.04959744  0.00660809  0.00326954 -0.03995717 -0.07330828  0.03976692\n",
      "  -0.05351664  0.00975106  0.06573427 -0.02739749 -0.09327179  0.04945787 -0.02640928 -0.04811666 -0.02023635  0.06447937 -0.03439065  0.0139924   0.0464136   0.00337566  0.02538461 -0.06651063\n",
      "  -0.04496676  0.0838992   0.01286556 -0.05759917 -0.03575674  0.04870736 -0.04739238 -0.03980498 -0.03625782 -0.03805096 -0.08773073 -0.06959508 -0.00847899  0.06059518  0.07969318 -0.0708125\n",
      "  -0.0893693  -0.06057403  0.07137258 -0.01208807  0.06577881 -0.03820333 -0.0092607   0.03320887  0.03371763  0.02749492  0.0222254  -0.0385009  -0.06819282 -0.03207813 -0.06575748  0.05194928\n",
      "   0.04517641  0.02427202 -0.03203683  0.01011538  0.03549726  0.01011589  0.09121121  0.05085948  0.0521733   0.07686589 -0.04503366 -0.05324352 -0.05853685 -0.09454808 -0.06227051  0.01004666\n",
      "   0.04691439 -0.08155395 -0.07039268 -0.0626953   0.04923284  0.10943376 -0.09563538 -0.04455084  0.04119632 -0.01810255  0.05851319  0.10388672  0.05619141 -0.03728981 -0.01278691  0.01754151\n",
      "   0.01679015 -0.02435889 -0.00674845 -0.06429783  0.03328788 -0.05609738  0.10601854 -0.0259404   0.00149522  0.04106174 -0.05370849  0.0028464  -0.05031592 -0.02407174  0.06772646  0.09178518\n",
      "  -0.02538849  0.01290044 -0.02147716  0.00510707 -0.01601212  0.04254682  0.11457694  0.0729804  -0.06978741 -0.07788446  0.03534267  0.03449352 -0.01572119  0.04929534 -0.03750178 -0.02385621\n",
      "  -0.02329657 -0.02781849 -0.001669   -0.04054138  0.0480957   0.02998433 -0.07266621 -0.02555498  0.04405433 -0.03032568  0.0237516  -0.00824624 -0.02347079 -0.00650779 -0.04389346 -0.01901838\n",
      "  -0.01131411  0.01689962 -0.07772244 -0.02221462  0.05264394  0.04042242 -0.05456498  0.0482622  -0.01202585 -0.03829448  0.09095762 -0.08251437 -0.02401281  0.03748619  0.08460325 -0.06388205\n",
      "  -0.00170378  0.04327493 -0.02785972  0.04521184  0.00906501 -0.06582078  0.12959684  0.02732117 -0.0723638  -0.05259325  0.02212598  0.02882136  0.07441571  0.08277625 -0.05466751  0.00978202\n",
      "   0.03124879 -0.03526711  0.03662866  0.07094477 -0.04028454  0.0156486  -0.00978891 -0.06183676 -0.08637214  0.07227733 -0.06914746 -0.0605968   0.01716767  0.06575125  0.04593194  0.05799318]]\n",
      "CONVERSION SUMMARY\n",
      "HF Transformers: Sentence Embedding shape: (1, 384)\n",
      "PYTORCH: Sentence Embedding shape: torch.Size([1, 384])\n",
      "TFLite:  Sentence Embedding shape: (1, 384)\n",
      "TFLite - HF Transformers Mean Difference: 4.057159e-08\n",
      "PYTORCH - HF Transformers Mean Difference: 1.7363291e-08\n",
      "PYTORCH - TFLite Mean Difference: 4.325806e-08\n"
     ]
    }
   ],
   "source": [
    "#TFLITE CONVERSION AND EXECUTION OF CONVERTED MODEL\n",
    "\n",
    "import torch\n",
    "from torch.fx import symbolic_trace\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import numpy as np\n",
    "import ai_edge_torch\n",
    "import tensorflow as tf\n",
    "import os \n",
    "\n",
    "tflite_model_path = \"./e5_embedding_model.tflite\"\n",
    "\n",
    "torch.set_printoptions(precision=8, sci_mode=False, linewidth=200, threshold=1000)\n",
    "np.set_printoptions(precision=8, suppress=True, linewidth=200, threshold=1000)\n",
    "class E5EmbeddingModel(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super().__init__()\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        #model outputs are in the shape of [batch_size, sequence_length_max, hidden_size] i.e. padded token embeddings \n",
    "        #mean pooling is done by summing the token embeddings and dividing by the number of non-padding tokens\n",
    "        #this gives us a single the embedding for the entire sequence\n",
    "        token_embeddings = outputs.last_hidden_state\n",
    "        mask = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        sum_embeddings = torch.sum(token_embeddings * mask, dim=1)\n",
    "        sum_mask = mask.sum(dim=1).clamp(min=1e-9)\n",
    "        pooled = sum_embeddings / sum_mask\n",
    "        return torch.nn.functional.normalize(pooled, p=2, dim=1)\n",
    "\n",
    "# Create the complete model\n",
    "complete_model = E5EmbeddingModel('intfloat/multilingual-e5-small')\n",
    "complete_model.eval()\n",
    "\n",
    "\n",
    "input_texts = [\n",
    "    \"passage: As a general guideline, the CDC's average requirement of protein for women ages 19 to 70 is 46 grams per day. But, as you can see from this chart, you'll need to increase that if you're expecting or traini     ng for a marathon. Check out the chart below to see how much protein you should be eating each day.\",    \n",
    "]\n",
    "\n",
    "# 3. Tokenize the text\n",
    "inputs = complete_model.tokenizer(\n",
    "    input_texts,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=512\n",
    ")\n",
    "# tokenizer outputs a dictionary with input_ids and attention_mask\n",
    "print(\"Tokenizer's output:\")\n",
    "for key, value in inputs.items():\n",
    "    print(f\"{key}: {value.shape}\\n\")\n",
    "\n",
    "\n",
    "print (\"Running the Pytorch Embeddings Neural Network program...\")\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(inputs['input_ids'].dtype)         # Should be torch.int64\n",
    "print(inputs['attention_mask'].dtype)    # Should be torch.int64\n",
    "print(inputs['input_ids'].shape)         # e.g., torch.Size([1, 16])\n",
    "print(inputs['attention_mask'].shape)    # Same\n",
    "\n",
    "#4. Generate embedding with PyTorch\n",
    "with torch.no_grad():\n",
    "    sentence_embedding_pytorch = complete_model(inputs[\"input_ids\"], inputs[\"attention_mask\"])\n",
    "\n",
    "\n",
    "# # 5. Print or use the embedding\n",
    "# print(\"PYTORCH: Embedding shape:\", sentence_embedding_pytorch.shape)  # shape: (1, hidden_size)\n",
    "# print(\"PYTORCH: Embedding:\", sentence_embedding_pytorch)\n",
    "\n",
    "print(\"Export-time input shape:\", inputs['input_ids'].shape)\n",
    "print(\"Export-time attention shape:\", inputs['attention_mask'].shape)\n",
    "\n",
    "#Convert to TFLite using ai_edge_torch\n",
    "try:\n",
    "    #TODO AD: note that it's possible to do FP16 quantization here - but it's not done by default\n",
    "    edge_model = ai_edge_torch.convert(\n",
    "        complete_model,(inputs['input_ids'], inputs['attention_mask'])\n",
    "    )\n",
    "    \n",
    "    edge_model.export(tflite_model_path)\n",
    "    print(f\"Exporting to {tflite_model_path}...\")\n",
    "    \n",
    "    #Verify file was created\n",
    "    if os.path.exists(tflite_model_path):\n",
    "         file_size = os.path.getsize(tflite_model_path)\n",
    "         print(f\"TFLite model exported successfully: {file_size} bytes\")\n",
    "    else:\n",
    "         print(\"ERROR: TFLite file was not created\")\n",
    "        \n",
    "    print(\"Direct TFLite conversion successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"TFLiteConversion failed: {e}\")\n",
    "    \n",
    "\n",
    "print(\"Running the TFLite Neural Network program...\")\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(inputs['input_ids'].dtype)         # Should be torch.int64\n",
    "print(inputs['attention_mask'].dtype)    # Should be torch.int64\n",
    "print(inputs['input_ids'].shape)         # e.g., torch.Size([1, 16])\n",
    "print(inputs['attention_mask'].shape)    # Same\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Method 1: Call it like a function\n",
    "    sentence_embedding_tflite = edge_model(inputs['input_ids'], inputs['attention_mask'])\n",
    "    print(\"Edge model output shape:\", sentence_embedding_tflite.shape)\n",
    "    print(\"Edge model output:\", sentence_embedding_tflite)\n",
    "\n",
    "#pytorch returns torch tensor, tflite returns numpy array, sentence_embedding_hf is numpy array already converted\n",
    "print(\"CONVERSION SUMMARY\")\n",
    "print(\"HF Transformers: Sentence Embedding shape:\", sentence_embedding_hf.shape)  # shape: (1, hidden_size)\n",
    "print(\"PYTORCH: Sentence Embedding shape:\", sentence_embedding_pytorch.shape)  # shape: (1, hidden_size)\n",
    "print(\"TFLite:  Sentence Embedding shape:\", sentence_embedding_tflite.shape)\n",
    "print(\"TFLite - HF Transformers Mean Difference:\", np.mean(np.abs(sentence_embedding_tflite - sentence_embedding_hf)))\n",
    "print(\"PYTORCH - HF Transformers Mean Difference:\", np.mean(np.abs(sentence_embedding_pytorch.numpy() - sentence_embedding_hf)))\n",
    "print(\"PYTORCH - TFLite Mean Difference:\", np.mean(np.abs(sentence_embedding_pytorch.numpy() - sentence_embedding_tflite)))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tflite_conversion_venv)",
   "language": "python",
   "name": "tflite_conversion_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
