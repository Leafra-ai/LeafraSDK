{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arifdikici/Documents/Squirrel/LeafraSDK/sdk/utility/model_conversion/executorch/executorch_conversion_venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 384)\n",
      "[[-0.02770221 -0.03813099 -0.0398256  -0.05757588  0.09452219 -0.00440195\n",
      "  -0.00121109  0.0479796   0.11293583 -0.02816084 -0.00840986  0.00278697\n",
      "   0.05210911 -0.0479064  -0.06440714  0.08867694  0.06003449 -0.05546542\n",
      "   0.01060416 -0.10622071 -0.00074917 -0.02652234 -0.00850196  0.07526896\n",
      "   0.06317414  0.01844089  0.04177358  0.01911454  0.01219684 -0.0425988\n",
      "  -0.05273764 -0.04504282  0.07244772 -0.03342383  0.04650453 -0.01180932\n",
      "  -0.08239587 -0.04839655  0.0592964  -0.05031675  0.01825628  0.05641181\n",
      "   0.01202095  0.04509379  0.02488489  0.07455293 -0.06399445  0.05743225\n",
      "   0.00253773 -0.02408612 -0.04169365  0.06357355  0.02231303  0.04851863\n",
      "   0.07581113 -0.04902857 -0.01477868 -0.04722577 -0.08053476 -0.05552473\n",
      "   0.06340043 -0.06567129 -0.01058714  0.00549461  0.05940748  0.06786209\n",
      "  -0.02164334  0.02354763 -0.06624272 -0.05330627 -0.05857437  0.04967235\n",
      "   0.02746254 -0.03966729  0.07234168  0.00053671  0.02721862 -0.04905777\n",
      "  -0.0278952  -0.03555537 -0.05229253 -0.0232862  -0.02478277  0.00449746\n",
      "  -0.04013076  0.06087972  0.04480276 -0.06587248  0.07937454 -0.04721905\n",
      "   0.04032631  0.0014749  -0.03042594 -0.025867   -0.02994005 -0.05580973\n",
      "  -0.060806    0.06390736  0.03436925 -0.0348019   0.04004368 -0.00662425\n",
      "   0.03491098 -0.05809834 -0.04098739  0.05424322  0.02063288 -0.07735572\n",
      "   0.04283679 -0.0755023  -0.06340546  0.01051446  0.05304069  0.04833924\n",
      "  -0.02799372 -0.00382987 -0.02815943 -0.04821436  0.04599935 -0.03984922\n",
      "   0.11794984 -0.00617181 -0.0658878  -0.06178902 -0.06074701 -0.03427229\n",
      "  -0.00335001  0.03030449 -0.00520515  0.01368313  0.05388852  0.05501134\n",
      "   0.04022947  0.06936859 -0.01122334  0.07116794 -0.06883465 -0.05066582\n",
      "  -0.02499835 -0.04799357 -0.0385614   0.05182253 -0.0574561   0.02819802\n",
      "   0.11997031  0.06407916  0.0792346   0.01301863  0.09150435 -0.06506351\n",
      "   0.02555789 -0.01771322  0.02857727  0.05210132  0.02984548 -0.00880767\n",
      "  -0.03170262 -0.03684917  0.08111642  0.02231921 -0.03649987 -0.08025018\n",
      "  -0.04519829 -0.01286735 -0.04556464 -0.05247847 -0.00603792  0.0815153\n",
      "  -0.02092829 -0.05214318 -0.0704104   0.04361044 -0.05477502  0.06657538\n",
      "  -0.03255586  0.04808008 -0.03145198  0.10403938  0.05944986  0.03516466\n",
      "  -0.03567813 -0.01982473 -0.04257784 -0.05254317 -0.03692529 -0.03095564\n",
      "  -0.03150494  0.02968515  0.08813399 -0.02967994  0.06399583  0.02735557\n",
      "  -0.05251073 -0.0584395  -0.04052009  0.0065007  -0.03169296  0.06468228\n",
      "   0.07073887  0.05056228  0.01327519 -0.00558642  0.05155321  0.00590239\n",
      "   0.00290634 -0.04073397 -0.07162567  0.03862573 -0.05314816  0.00758648\n",
      "   0.06595861 -0.03165583 -0.09574864  0.04636238 -0.02180873 -0.05215802\n",
      "  -0.0238762   0.06541751 -0.03585904  0.0124878   0.04729455  0.00316024\n",
      "   0.02616153 -0.06694043 -0.04688171  0.08386032  0.01162245 -0.0555544\n",
      "  -0.0342833   0.04990344 -0.04711832 -0.04288657 -0.03423479 -0.03690019\n",
      "  -0.08858894 -0.06629456 -0.0081091   0.06257579  0.07819794 -0.06933147\n",
      "  -0.08650567 -0.06011324  0.0689663  -0.01375619  0.06547443 -0.03961124\n",
      "  -0.0099582   0.03677532  0.03092806  0.02966359  0.02353894 -0.03876304\n",
      "  -0.07044956 -0.02567155 -0.06693362  0.05092112  0.04748764  0.02597373\n",
      "  -0.03175817  0.00993676  0.03563998  0.01105975  0.09246381  0.05328328\n",
      "   0.05154686  0.07427409 -0.0470722  -0.0511823  -0.06214401 -0.09449697\n",
      "  -0.06373236  0.00551739  0.04472705 -0.08306095 -0.07132776 -0.0638497\n",
      "   0.05112895  0.10848299 -0.09652202 -0.04432761  0.04503002 -0.0187958\n",
      "   0.05660676  0.10492269  0.05290086 -0.03842956 -0.01334013  0.01727985\n",
      "   0.01711045 -0.02393679 -0.00228012 -0.06067932  0.03397346 -0.05516957\n",
      "   0.10595795 -0.02512352 -0.00261812  0.04444156 -0.05497003  0.00489738\n",
      "  -0.05146418 -0.02692145  0.06709895  0.09232602 -0.0288228   0.01320717\n",
      "  -0.0177598   0.00726971 -0.01167697  0.03874204  0.11603303  0.07368324\n",
      "  -0.07301914 -0.07707358  0.03797553  0.0367219  -0.0181331   0.05282933\n",
      "  -0.0392982  -0.02372157 -0.02344573 -0.02983666 -0.00524226 -0.03850904\n",
      "   0.0486369   0.02945218 -0.0722929  -0.02564312  0.04249496 -0.02969273\n",
      "   0.02608336 -0.00448464 -0.02199706 -0.00504114 -0.04401718 -0.01810723\n",
      "  -0.01512216  0.01627919 -0.07759485 -0.02418244  0.05299563  0.04079905\n",
      "  -0.05430418  0.04754711 -0.01180447 -0.0390158   0.0901697  -0.08201458\n",
      "  -0.02138627  0.03323985  0.08471511 -0.06031765 -0.00254269  0.04005131\n",
      "  -0.02874938  0.04655666  0.00685251 -0.06673285  0.1282948   0.02500632\n",
      "  -0.07365733 -0.04836563  0.02282355  0.02996596  0.07646614  0.08297542\n",
      "  -0.05453291  0.00732016  0.03038924 -0.03189693  0.03741466  0.07381641\n",
      "  -0.04240407  0.01563142 -0.00795011 -0.0614148  -0.08799549  0.06956033\n",
      "  -0.06911936 -0.05953288  0.01824844  0.06744719  0.05041988  0.05880518]]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "import transformers\n",
    "# print(\"CWD:\", os.getcwd())\n",
    "# print(\"Cache:\", os.getenv(\"HF_HOME\", \"~/.cache/huggingface\"))\n",
    "# print(\"Transformers path:\", transformers.__file__)\n",
    "\n",
    "\n",
    "model = SentenceTransformer('intfloat/multilingual-e5-small')\n",
    "input_texts = [\n",
    "    \"passage: As a general guideline, the CDC's average requirement of protein for women ages 19 to 70 i     s 46 grams per day. But, as you can see from this chart, you'll need to increase that if you're expecting or traini     ng for a marathon. Check out the chart below to see how much protein you should be eating each day.\",\n",
    "]\n",
    "\n",
    "\n",
    "embeddings = model.encode(input_texts, normalize_embeddings=True)\n",
    "print(embeddings.shape)\n",
    "print(embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.fx import symbolic_trace\n",
    "import torch.nn as nn\n",
    "import executorch.exir as exir\n",
    "from executorch.extension.pybindings.portable_lib import _load_for_executorch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "class E5EmbeddingModel(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super().__init__()\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        token_embeddings = outputs.last_hidden_state\n",
    "        mask = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        sum_embeddings = torch.sum(token_embeddings * mask, dim=1)\n",
    "        sum_mask = mask.sum(dim=1).clamp(min=1e-9)\n",
    "        pooled = sum_embeddings / sum_mask\n",
    "        return torch.nn.functional.normalize(pooled, p=2, dim=1)\n",
    "\n",
    "# Create the complete model\n",
    "complete_model = E5EmbeddingModel('intfloat/multilingual-e5-small')\n",
    "complete_model.eval()\n",
    "\n",
    "\n",
    "input_texts = [\n",
    "    \"passage: As a general guideline, the CDC's average requirement of protein for women ages 19 to 70 i     s 46 grams per day. But, as you can see from this chart, you'll need to increase that if you're expecting or traini     ng for a marathon. Check out the chart below to see how much protein you should be eating each day.\",    \n",
    "]\n",
    "\n",
    "# 3. Tokenize the text\n",
    "inputs = complete_model.tokenizer(\n",
    "    input_texts,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=512\n",
    ")\n",
    "# tokenizer outputs a dictionary with input_ids and attention_mask\n",
    "print(\"Tokenizer's output:\")\n",
    "for key, value in inputs.items():\n",
    "    print(f\"{key}: {value.shape}\\n\")\n",
    "\n",
    "\n",
    "print (\"Running the Pytorch Embeddings Neural Network program...\")\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(inputs['input_ids'].dtype)         # Should be torch.int64\n",
    "print(inputs['attention_mask'].dtype)    # Should be torch.int64\n",
    "print(inputs['input_ids'].shape)         # e.g., torch.Size([1, 16])\n",
    "print(inputs['attention_mask'].shape)    # Same\n",
    "\n",
    "# 4. Generate embedding\n",
    "with torch.no_grad():\n",
    "    embedding = complete_model(inputs[\"input_ids\"], inputs[\"attention_mask\"])\n",
    "\n",
    "\n",
    "# 5. Print or use the embedding\n",
    "print(\"PYTORCH: Embedding shape:\", embedding.shape)  # shape: (1, hidden_size)\n",
    "print(\"PYTORCH: Embedding:\", embedding)\n",
    "\n",
    "print(\"Export-time input shape:\", inputs['input_ids'].shape)\n",
    "print(\"Export-time attention shape:\", inputs['attention_mask'].shape)\n",
    "#Export to ExecuTorch\n",
    "with torch.no_grad():\n",
    "    exported_program = torch.export.export(\n",
    "        complete_model,\n",
    "        (inputs['input_ids'], inputs['attention_mask'])\n",
    "    )\n",
    "\n",
    "# Print the exported program's graph\n",
    "# print(\"Exported Program Graph:\")\n",
    "# print(exported_program.graph_module.graph)\n",
    "\n",
    "edge_program = exir.to_edge(exported_program)\n",
    "executorch_program = edge_program.to_executorch()\n",
    "\n",
    "\n",
    "with open(\"e5_complete.pte\", \"wb\") as f:\n",
    "     executorch_program.write_to_file(f)\n",
    "\n",
    "\n",
    "print (\"Exported to ExecuTorch successfully!\")\n",
    "print (\"Running the Executorch Neural Network program...\")\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(inputs['input_ids'].dtype)         # Should be torch.int64\n",
    "print(inputs['attention_mask'].dtype)    # Should be torch.int64\n",
    "print(inputs['input_ids'].shape)         # e.g., torch.Size([1, 16])\n",
    "print(inputs['attention_mask'].shape)    # Same\n",
    "\n",
    "\n",
    "\n",
    "# Load model\n",
    "model = _load_for_executorch(\"e5_complete.pte\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    embedding_et = model.forward((inputs['input_ids'], inputs['attention_mask']))[0]  # typically returns a tuple\n",
    "# 5. Print or use the embedding\n",
    "print(\"EXECUTORCH: Embedding shape:\", embedding_et.shape)  # shape: (1, hidden_size)\n",
    "print(\"PYTORCH: Embedding:\", embedding_et)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.fx import symbolic_trace\n",
    "import torch.nn as nn\n",
    "import executorch.exir as exir\n",
    "from executorch.extension.pybindings.portable_lib import _load_for_executorch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import sys \n",
    "class E5EmbeddingModel(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super().__init__()\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        token_embeddings = outputs.last_hidden_state\n",
    "        mask = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        sum_embeddings = torch.sum(token_embeddings * mask, dim=1)\n",
    "        sum_mask = mask.sum(dim=1).clamp(min=1e-9)\n",
    "        pooled = sum_embeddings / sum_mask\n",
    "        return torch.nn.functional.normalize(pooled, p=2, dim=1)\n",
    "\n",
    "# Create the complete model\n",
    "complete_model = E5EmbeddingModel('intfloat/multilingual-e5-small')\n",
    "complete_model.eval()\n",
    "\n",
    "input_texts = [\n",
    "    \"passage: test text for analysis\",    \n",
    "]\n",
    "\n",
    "# Tokenize the text\n",
    "inputs = complete_model.tokenizer(\n",
    "    input_texts,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=512\n",
    ")\n",
    "\n",
    "print(\"=== ANALYZING OPERATORS NEEDED ===\")\n",
    "\n",
    "# Export to ExecuTorch and analyze operators\n",
    "with torch.no_grad():\n",
    "    exported_program = torch.export.export(\n",
    "        complete_model,\n",
    "        (inputs['input_ids'], inputs['attention_mask'])\n",
    "    )\n",
    "\n",
    "print(\"\\n=== ALL EXPORTED PROGRAM OPERATORS ===\")\n",
    "# Print all operators used in the exported program\n",
    "ops_used = set()\n",
    "for node in exported_program.graph_module.graph.nodes:\n",
    "    if node.op == 'call_function':\n",
    "        ops_used.add(str(node.target))\n",
    "\n",
    "# Sort and print all operators\n",
    "sorted_ops = sorted(list(ops_used))\n",
    "for i, op in enumerate(sorted_ops, 1):\n",
    "    print(f\"{i:2d}. {op}\")\n",
    "\n",
    "print(f\"\\nTotal unique operators: {len(ops_used)}\")\n",
    "\n",
    "print(\"\\n=== CONVERTING TO EDGE ===\")\n",
    "edge_program = exir.to_edge(exported_program)\n",
    "\n",
    "print(\"\\n=== ALL EDGE PROGRAM OPERATORS ===\")\n",
    "# Print operators in edge program\n",
    "edge_ops_used = set()\n",
    "for node in edge_program.exported_program().graph_module.graph.nodes:\n",
    "    if node.op == 'call_function':\n",
    "        edge_ops_used.add(str(node.target))\n",
    "\n",
    "# Sort and print all edge operators\n",
    "sorted_edge_ops = sorted(list(edge_ops_used))\n",
    "for i, op in enumerate(sorted_edge_ops, 1):\n",
    "    print(f\"{i:2d}. {op}\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "print(f\"\\nTotal unique edge operators: {len(edge_ops_used)}\")\n",
    "\n",
    "print(\"\\n=== CHECKING FOR PROBLEMATIC OPERATORS ===\")\n",
    "# Check for operators that might not be supported in portable kernels\n",
    "problematic_ops = [\n",
    "    'aten.scaled_dot_product_attention',\n",
    "    'aten.gelu', \n",
    "    'aten.silu',\n",
    "    'aten.baddbmm',\n",
    "    'aten._native_batch_norm_legit',\n",
    "    'aten.native_batch_norm',\n",
    "    'aten.group_norm',\n",
    "    'aten.instance_norm'\n",
    "]\n",
    "\n",
    "found_problematic = []\n",
    "for op in sorted_edge_ops:\n",
    "    for prob_op in problematic_ops:\n",
    "        if prob_op in op:\n",
    "            found_problematic.append(op)\n",
    "\n",
    "if found_problematic:\n",
    "    print(\"Found potentially problematic operators:\")\n",
    "    for op in found_problematic:\n",
    "        print(f\"  - {op}\")\n",
    "else:\n",
    "    print(\"No obviously problematic operators found\")\n",
    "\n",
    "print(\"\\n=== CONVERTING TO EXECUTORCH ===\")\n",
    "try:\n",
    "    executorch_program = edge_program.to_executorch()\n",
    "    print(\"SUCCESS: Model converted to ExecuTorch\")\n",
    "    \n",
    "    # Try to save and load\n",
    "    with open(\"analysis_test.pte\", \"wb\") as f:\n",
    "        executorch_program.write_to_file(f)\n",
    "    \n",
    "    print(\"SUCCESS: Model saved to file\")\n",
    "    \n",
    "    # Try to load with ExecuTorch\n",
    "    try:\n",
    "        model = _load_for_executorch(\"analysis_test.pte\")\n",
    "        print(\"SUCCESS: Model loaded in ExecuTorch runtime\")\n",
    "        \n",
    "        # Try to run\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                result = model.forward((inputs['input_ids'], inputs['attention_mask']))\n",
    "            print(\"SUCCESS: Model executed successfully\")\n",
    "            print(f\"Output shape: {result[0].shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"FAILED: Model execution failed: {e}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"FAILED: Model loading failed: {e}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"FAILED: to_executorch() failed: {e}\")\n",
    "\n",
    "print(\"\\n=== ANALYSIS COMPLETE ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Check what operators are available in Apple prebuilt ExecuTorch libraries\n",
    "\"\"\"\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import sys\n",
    "\n",
    "def run_command(cmd):\n",
    "    \"\"\"Run a shell command and return output\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "        return result.stdout, result.stderr, result.returncode\n",
    "    except Exception as e:\n",
    "        return \"\", str(e), 1\n",
    "\n",
    "def check_library_exists(lib_path):\n",
    "    \"\"\"Check if library file exists\"\"\"\n",
    "    return os.path.exists(lib_path)\n",
    "\n",
    "def analyze_library_symbols(lib_path, lib_name):\n",
    "    \"\"\"Analyze symbols in a library file\"\"\"\n",
    "    print(f\"\\n=== ANALYZING {lib_name} ===\")\n",
    "    print(f\"Path: {lib_path}\")\n",
    "    \n",
    "    if not check_library_exists(lib_path):\n",
    "        print(f\"‚ùå Library not found: {lib_path}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"‚úÖ Library found\")\n",
    "    \n",
    "    # Get file info\n",
    "    stdout, stderr, code = run_command(f\"file '{lib_path}'\")\n",
    "    if code == 0:\n",
    "        print(f\"File type: {stdout.strip()}\")\n",
    "    \n",
    "    # Get total symbol count\n",
    "    stdout, stderr, code = run_command(f\"nm '{lib_path}' 2>/dev/null | wc -l\")\n",
    "    if code == 0:\n",
    "        print(f\"Total symbols: {stdout.strip()}\")\n",
    "    \n",
    "    # Check for specific operators we need\n",
    "    operators_to_check = [\n",
    "        'gelu',\n",
    "        'layer_norm', \n",
    "        'bmm',\n",
    "        'softmax',\n",
    "        'addmm',\n",
    "        'embedding'\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nChecking for required operators:\")\n",
    "    found_operators = []\n",
    "    \n",
    "    for op in operators_to_check:\n",
    "        stdout, stderr, code = run_command(f\"nm '{lib_path}' 2>/dev/null | grep -i '{op}'\")\n",
    "        if stdout.strip():\n",
    "            found_operators.append(op)\n",
    "            print(f\"  ‚úÖ {op}: FOUND\")\n",
    "            # Show first few matches\n",
    "            lines = stdout.strip().split('\\n')[:3]\n",
    "            for line in lines:\n",
    "                print(f\"    {line}\")\n",
    "        else:\n",
    "            print(f\"  ‚ùå {op}: NOT FOUND\")\n",
    "    \n",
    "    # Check for aten namespace symbols\n",
    "    stdout, stderr, code = run_command(f\"nm '{lib_path}' 2>/dev/null | grep 'aten::' | head -5\")\n",
    "    if stdout.strip():\n",
    "        print(f\"\\nSample aten:: symbols found:\")\n",
    "        for line in stdout.strip().split('\\n'):\n",
    "            print(f\"  {line}\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå No aten:: symbols found\")\n",
    "    \n",
    "    # List object files in the archive\n",
    "    stdout, stderr, code = run_command(f\"ar -t '{lib_path}' | head -10\")\n",
    "    if code == 0 and stdout.strip():\n",
    "        print(f\"\\nSample object files in archive:\")\n",
    "        for line in stdout.strip().split('\\n'):\n",
    "            print(f\"  {line}\")\n",
    "    \n",
    "    return found_operators\n",
    "\n",
    "def check_specific_operators():\n",
    "    \"\"\"Check for the exact operators your model needs\"\"\"\n",
    "    required_ops = [\n",
    "        \"aten.gelu.default\",\n",
    "        \"aten.native_layer_norm.default\", \n",
    "        \"aten.bmm.default\",\n",
    "        \"aten._softmax.default\",\n",
    "        \"aten.addmm.default\",\n",
    "        \"aten.embedding.default\",\n",
    "        \"dim_order_ops._to_dim_order_copy.default\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"OPERATORS REQUIRED BY YOUR MODEL:\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for i, op in enumerate(required_ops, 1):\n",
    "        print(f\"{i:2d}. {op}\")\n",
    "    \n",
    "    return required_ops\n",
    "\n",
    "def main():\n",
    "    print(\"üîç EXECUTORCH APPLE LIBRARY ANALYZER\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Define library paths\n",
    "    libraries = {\n",
    "        \"ExecuTorch Main\": \"../../corecpp/third_party/prebuilt/executorch/apple/executorch.xcframework/macos-arm64/libexecutorch_macos.a\",\n",
    "        \"Portable Kernels\": \"../../corecpp/third_party/prebuilt/executorch/apple/kernels_portable.xcframework/macos-arm64/libkernels_portable_macos.a\", \n",
    "        \"Optimized Kernels\": \"../../corecpp/third_party/prebuilt/executorch/apple/kernels_optimized.xcframework/macos-arm64/libkernels_optimized_macos.a\"\n",
    "    }\n",
    "    \n",
    "    all_found_operators = []\n",
    "    \n",
    "    # Analyze each library\n",
    "    for lib_name, lib_path in libraries.items():\n",
    "        found_ops = analyze_library_symbols(lib_path, lib_name)\n",
    "        if found_ops:\n",
    "            all_found_operators.extend(found_ops)\n",
    "    \n",
    "    # Show required operators\n",
    "    required_ops = check_specific_operators()\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"SUMMARY:\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    unique_found = list(set(all_found_operators))\n",
    "    print(f\"‚úÖ Found operator types: {len(unique_found)}\")\n",
    "    for op in unique_found:\n",
    "        print(f\"   - {op}\")\n",
    "    \n",
    "    print(f\"\\n‚ùì Required operator types: {len(required_ops)}\")\n",
    "    \n",
    "    # Check coverage\n",
    "    missing_ops = []\n",
    "    for req_op in required_ops:\n",
    "        found = False\n",
    "        for found_op in unique_found:\n",
    "            if found_op.lower() in req_op.lower():\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            missing_ops.append(req_op)\n",
    "    \n",
    "    if missing_ops:\n",
    "        print(f\"\\n‚ùå LIKELY MISSING OPERATORS:\")\n",
    "        for op in missing_ops:\n",
    "            print(f\"   - {op}\")\n",
    "        print(f\"\\nüí° RECOMMENDATION: Build ExecuTorch from source to get full operator support\")\n",
    "    else:\n",
    "        print(f\"\\n‚úÖ All required operator types appear to be available!\")\n",
    "        print(f\"üí° The error might be due to a different issue (memory, model format, etc.)\")\n",
    "    \n",
    "    # Additional checks\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ADDITIONAL DIAGNOSTICS:\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Check if nm command is available\n",
    "    stdout, stderr, code = run_command(\"which nm\")\n",
    "    if code != 0:\n",
    "        print(\"‚ùå 'nm' command not found. Install Xcode Command Line Tools:\")\n",
    "        print(\"   xcode-select --install\")\n",
    "    else:\n",
    "        print(\"‚úÖ 'nm' command available\")\n",
    "    \n",
    "    # Check if ar command is available  \n",
    "    stdout, stderr, code = run_command(\"which ar\")\n",
    "    if code != 0:\n",
    "        print(\"‚ùå 'ar' command not found\")\n",
    "    else:\n",
    "        print(\"‚úÖ 'ar' command available\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Check ExecuTorch version and build details\n",
    "\"\"\"\n",
    "\n",
    "import executorch\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "print(\"=== EXECUTORCH VERSION INFORMATION ===\")\n",
    "\n",
    "# Check ExecuTorch version\n",
    "try:\n",
    "    print(f\"ExecuTorch version: {executorch.__version__}\")\n",
    "except AttributeError:\n",
    "    print(\"ExecuTorch version: Unknown (no __version__ attribute)\")\n",
    "\n",
    "# Check if we can import key modules\n",
    "try:\n",
    "    from executorch.exir import to_edge\n",
    "    print(\"‚úÖ executorch.exir module available\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå executorch.exir import failed: {e}\")\n",
    "\n",
    "try:\n",
    "    from executorch.extension.pybindings.portable_lib import _load_for_executorch\n",
    "    print(\"‚úÖ executorch.extension.pybindings.portable_lib available\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå portable_lib import failed: {e}\")\n",
    "\n",
    "# Check PyTorch version\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Check installation path\n",
    "print(f\"ExecuTorch installed at: {executorch.__file__}\")\n",
    "\n",
    "# Try to get git commit if available\n",
    "try:\n",
    "    import subprocess\n",
    "    import os\n",
    "    \n",
    "    # Check if we're in a git repo\n",
    "    executorch_path = os.path.dirname(executorch.__file__)\n",
    "    result = subprocess.run(['git', 'rev-parse', 'HEAD'], \n",
    "                          cwd=executorch_path, \n",
    "                          capture_output=True, \n",
    "                          text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(f\"Git commit: {result.stdout.strip()}\")\n",
    "    else:\n",
    "        print(\"Not in a git repository or git not available\")\n",
    "except:\n",
    "    print(\"Could not determine git commit\")\n",
    "\n",
    "print(\"\\n=== SOURCE CODE VERSION ===\")\n",
    "# Check the source code version\n",
    "try:\n",
    "    source_path = \"../../corecpp/third_party/executorch\"\n",
    "    result = subprocess.run(['git', 'rev-parse', 'HEAD'], \n",
    "                          cwd=source_path, \n",
    "                          capture_output=True, \n",
    "                          text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(f\"Source git commit: {result.stdout.strip()}\")\n",
    "        \n",
    "        # Check if it's on branch 0.6.0\n",
    "        result = subprocess.run(['git', 'branch', '--show-current'], \n",
    "                              cwd=source_path, \n",
    "                              capture_output=True, \n",
    "                              text=True)\n",
    "        if result.returncode == 0:\n",
    "            print(f\"Source branch: {result.stdout.strip()}\")\n",
    "    else:\n",
    "        print(\"Source: Not in a git repository\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not check source version: {e}\")\n",
    "\n",
    "print(\"\\n=== TESTING BASIC EXPORT ===\")\n",
    "# Try a simple export to see if it works\n",
    "try:\n",
    "    import torch\n",
    "    from executorch.exir import to_edge\n",
    "    \n",
    "    class SimpleModel(torch.nn.Module):\n",
    "        def forward(self, x, y):\n",
    "            return x + y\n",
    "    \n",
    "    model = SimpleModel()\n",
    "    example_inputs = (torch.ones(2, 2), torch.ones(2, 2))\n",
    "    \n",
    "    # Export\n",
    "    exported_program = torch.export.export(model, example_inputs)\n",
    "    edge_program = to_edge(exported_program)\n",
    "    executorch_program = edge_program.to_executorch()\n",
    "    \n",
    "    # Save test model\n",
    "    with open(\"version_test.pte\", \"wb\") as f:\n",
    "        executorch_program.write_to_file(f)\n",
    "    \n",
    "    print(\"‚úÖ Simple export successful - created version_test.pte\")\n",
    "    \n",
    "    # Try to load it\n",
    "    from executorch.extension.pybindings.portable_lib import _load_for_executorch\n",
    "    test_model = _load_for_executorch(\"version_test.pte\")\n",
    "    result = test_model.forward(example_inputs)\n",
    "    print(\"‚úÖ Python runtime execution successful\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Export/execution failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (executorch_conversion_venv)",
   "language": "python",
   "name": "executorch_conversion_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
