{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 384)\n",
      "[[-0.02603655 -0.04028144 -0.04070155 -0.0567059   0.09808026 -0.00689323  0.00147932  0.04843692  0.11323304 -0.02740478 -0.00866384  0.00417224  0.05230614 -0.04768718 -0.06603133  0.08920387\n",
      "   0.06334063 -0.0531108   0.00967995 -0.10728    -0.00384986 -0.02598386 -0.00927936  0.07551409  0.06361943  0.01656303  0.04170512  0.01730527  0.01455697 -0.04344153 -0.05670437 -0.04429426\n",
      "   0.07144874 -0.03361619  0.04803945 -0.00959459 -0.08393562 -0.04850756  0.05855655 -0.05139393  0.01839355  0.05547392  0.00980078  0.04608281  0.02681232  0.07292694 -0.06347433  0.05774029\n",
      "   0.00521458 -0.02235039 -0.04456336  0.06401616  0.02014326  0.04503598  0.07350688 -0.04566624 -0.01399923 -0.04260228 -0.08010491 -0.05667784  0.0642169  -0.06622052 -0.01281164  0.00306561\n",
      "   0.06230231  0.0688728  -0.0218556   0.02037258 -0.06924745 -0.05492332 -0.05856651  0.04827423  0.025858   -0.04206206  0.07226792 -0.00066225  0.02808699 -0.0476877  -0.02578075 -0.03465487\n",
      "  -0.0518453  -0.02213822 -0.02603402  0.00418787 -0.04014497  0.0643865   0.04306506 -0.06464735  0.07835013 -0.04775865  0.03871156 -0.00219345 -0.02789641 -0.02316778 -0.03081978 -0.05162839\n",
      "  -0.06317416  0.06501402  0.03302038 -0.03495993  0.04030039 -0.00946296  0.03341752 -0.06045856 -0.04164435  0.05242623  0.02311889 -0.08106453  0.04201825 -0.07920422 -0.06128573  0.01361952\n",
      "   0.05605029  0.05132575 -0.02488029 -0.00724884 -0.02829197 -0.04666113  0.04885308 -0.04127707  0.11957366 -0.0054375  -0.06644704 -0.06156052 -0.0596544  -0.03149875  0.00002121  0.02896379\n",
      "  -0.00570551  0.01163817  0.05298286  0.05715989  0.03742853  0.07244841 -0.00867338  0.07250952 -0.06899952 -0.05157417 -0.02404265 -0.04570673 -0.03795753  0.05116559 -0.05705473  0.02825825\n",
      "   0.11900002  0.06702527  0.07962915  0.01380344  0.09016922 -0.06509221  0.02724556 -0.01657279  0.02802205  0.05316261  0.03034369 -0.00838119 -0.03119645 -0.03582878  0.0775274   0.02368235\n",
      "  -0.03352492 -0.08365104 -0.04563202 -0.01239439 -0.04529971 -0.05366284 -0.00508509  0.08052137 -0.02365418 -0.05088636 -0.07034072  0.04437151 -0.05328833  0.06672931 -0.02946307  0.04549769\n",
      "  -0.03047306  0.10325804  0.05995309  0.03321702 -0.03317445 -0.01909104 -0.04186945 -0.05407607 -0.03550967 -0.0328174  -0.03436184  0.02623802  0.08710828 -0.03221205  0.0601189   0.02914839\n",
      "  -0.05684852 -0.06085462 -0.03613584  0.00576991 -0.02940011  0.06640384  0.070873    0.04929258  0.01318029 -0.00586375  0.04959746  0.00660807  0.00326954 -0.03995718 -0.07330822  0.03976692\n",
      "  -0.05351668  0.00975109  0.06573437 -0.02739749 -0.09327181  0.0494579  -0.02640927 -0.04811666 -0.02023636  0.06447934 -0.03439064  0.01399239  0.04641359  0.00337577  0.02538465 -0.0665106\n",
      "  -0.04496676  0.08389917  0.01286561 -0.05759916 -0.03575667  0.04870737 -0.04739236 -0.03980495 -0.03625781 -0.03805093 -0.08773074 -0.06959507 -0.00847902  0.06059515  0.07969317 -0.07081252\n",
      "  -0.08936933 -0.060574    0.07137256 -0.01208804  0.06577878 -0.03820335 -0.00926075  0.03320886  0.03371762  0.02749489  0.02222538 -0.03850089 -0.06819282 -0.03207812 -0.06575751  0.05194921\n",
      "   0.04517644  0.02427204 -0.03203683  0.0101154   0.03549729  0.01011592  0.09121115  0.05085946  0.05217326  0.07686593 -0.04503367 -0.0532435  -0.05853687 -0.09454808 -0.06227056  0.01004665\n",
      "   0.04691435 -0.08155397 -0.07039271 -0.06269538  0.04923289  0.10943372 -0.09563541 -0.04455088  0.04119623 -0.01810258  0.05851317  0.10388672  0.05619137 -0.03728978 -0.01278685  0.01754142\n",
      "   0.01679009 -0.02435897 -0.00674845 -0.06429782  0.03328787 -0.05609741  0.10601849 -0.02594035  0.00149524  0.04106174 -0.05370853  0.00284644 -0.05031585 -0.02407178  0.06772643  0.09178521\n",
      "  -0.02538845  0.01290044 -0.02147722  0.00510704 -0.01601206  0.04254684  0.11457688  0.07298045 -0.06978744 -0.07788445  0.03534272  0.03449349 -0.01572118  0.04929537 -0.03750179 -0.02385619\n",
      "  -0.02329658 -0.02781848 -0.00166893 -0.04054139  0.04809567  0.0299844  -0.07266621 -0.02555504  0.04405433 -0.03032565  0.02375163 -0.00824626 -0.02347083 -0.00650781 -0.04389343 -0.01901837\n",
      "  -0.01131412  0.01689962 -0.0777224  -0.02221466  0.05264395  0.04042241 -0.05456492  0.04826221 -0.01202584 -0.03829444  0.09095756 -0.08251439 -0.02401282  0.03748613  0.08460324 -0.06388212\n",
      "  -0.00170382  0.04327488 -0.02785969  0.04521183  0.00906497 -0.06582072  0.12959681  0.02732125 -0.07236378 -0.05259329  0.02212603  0.02882127  0.07441574  0.08277624 -0.05466752  0.00978209\n",
      "   0.03124883 -0.03526711  0.0366286   0.07094473 -0.04028458  0.01564861 -0.00978891 -0.06183672 -0.08637219  0.07227728 -0.06914752 -0.06059679  0.01716772  0.06575124  0.04593194  0.05799318]]\n"
     ]
    }
   ],
   "source": [
    "#REFERENCE EMBEDDING OUTPUT FROM ORIGINAL MODEL EXECUTION USING SENTENCE-TRANSFORMERS LIBRARY\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "import transformers\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=8, suppress=True, linewidth=200, threshold=1000)\n",
    "# print(\"CWD:\", os.getcwd())\n",
    "# print(\"Cache:\", os.getenv(\"HF_HOME\", \"~/.cache/huggingface\"))\n",
    "# print(\"Transformers path:\", transformers.__file__)\n",
    "\n",
    "\n",
    "model = SentenceTransformer('intfloat/multilingual-e5-small')\n",
    "input_texts = [\n",
    "    \"passage: As a general guideline, the CDC's average requirement of protein for women ages 19 to 70 is 46 grams per day. But, as you can see from this chart, you'll need to increase that if you're expecting or traini     ng for a marathon. Check out the chart below to see how much protein you should be eating each day.\",\n",
    "]\n",
    "\n",
    "\n",
    "embeddings = model.encode(input_texts, normalize_embeddings=True)\n",
    "print(embeddings.shape)\n",
    "print(embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer's output:\n",
      "input_ids: torch.Size([1, 512])\n",
      "\n",
      "attention_mask: torch.Size([1, 512])\n",
      "\n",
      "Running the Pytorch Embeddings Neural Network program...\n",
      "\n",
      "\n",
      "\n",
      "torch.int64\n",
      "torch.int64\n",
      "torch.Size([1, 512])\n",
      "torch.Size([1, 512])\n",
      "PYTORCH: Embedding shape: torch.Size([1, 384])\n",
      "PYTORCH: Embedding: tensor([[    -0.02603654,     -0.04028142,     -0.04070162,     -0.05670591,      0.09808024,     -0.00689321,      0.00147931,      0.04843691,      0.11323303,     -0.02740477,     -0.00866385,\n",
      "              0.00417218,      0.05230618,     -0.04768714,     -0.06603138,      0.08920392,      0.06334060,     -0.05311080,      0.00967994,     -0.10728002,     -0.00384983,     -0.02598386,\n",
      "             -0.00927947,      0.07551411,      0.06361943,      0.01656309,      0.04170514,      0.01730530,      0.01455700,     -0.04344149,     -0.05670431,     -0.04429422,      0.07144865,\n",
      "             -0.03361622,      0.04803947,     -0.00959462,     -0.08393569,     -0.04850755,      0.05855654,     -0.05139395,      0.01839360,      0.05547388,      0.00980077,      0.04608275,\n",
      "              0.02681234,      0.07292692,     -0.06347438,      0.05774029,      0.00521452,     -0.02235040,     -0.04456339,      0.06401623,      0.02014322,      0.04503597,      0.07350690,\n",
      "             -0.04566626,     -0.01399927,     -0.04260229,     -0.08010494,     -0.05667775,      0.06421690,     -0.06622060,     -0.01281160,      0.00306564,      0.06230237,      0.06887284,\n",
      "             -0.02185549,      0.02037259,     -0.06924743,     -0.05492330,     -0.05856655,      0.04827426,      0.02585804,     -0.04206212,      0.07226782,     -0.00066226,      0.02808697,\n",
      "             -0.04768767,     -0.02578074,     -0.03465486,     -0.05184539,     -0.02213818,     -0.02603411,      0.00418779,     -0.04014503,      0.06438649,      0.04306499,     -0.06464734,\n",
      "              0.07835005,     -0.04775864,      0.03871157,     -0.00219349,     -0.02789650,     -0.02316783,     -0.03081976,     -0.05162852,     -0.06317410,      0.06501407,      0.03302047,\n",
      "             -0.03495993,      0.04030040,     -0.00946297,      0.03341748,     -0.06045861,     -0.04164434,      0.05242613,      0.02311894,     -0.08106458,      0.04201819,     -0.07920428,\n",
      "             -0.06128576,      0.01361946,      0.05605039,      0.05132586,     -0.02488027,     -0.00724885,     -0.02829192,     -0.04666111,      0.04885310,     -0.04127705,      0.11957365,\n",
      "             -0.00543759,     -0.06644708,     -0.06156057,     -0.05965436,     -0.03149879,      0.00002125,      0.02896382,     -0.00570550,      0.01163811,      0.05298289,      0.05715986,\n",
      "              0.03742850,      0.07244842,     -0.00867338,      0.07250962,     -0.06899954,     -0.05157419,     -0.02404262,     -0.04570682,     -0.03795760,      0.05116563,     -0.05705470,\n",
      "              0.02825828,      0.11899995,      0.06702526,      0.07962912,      0.01380342,      0.09016915,     -0.06509224,      0.02724550,     -0.01657289,      0.02802208,      0.05316253,\n",
      "              0.03034372,     -0.00838121,     -0.03119650,     -0.03582878,      0.07752744,      0.02368230,     -0.03352489,     -0.08365104,     -0.04563198,     -0.01239441,     -0.04529968,\n",
      "             -0.05366280,     -0.00508503,      0.08052137,     -0.02365417,     -0.05088640,     -0.07034076,      0.04437143,     -0.05328833,      0.06672927,     -0.02946304,      0.04549776,\n",
      "             -0.03047307,      0.10325804,      0.05995299,      0.03321712,     -0.03317452,     -0.01909108,     -0.04186944,     -0.05407612,     -0.03550963,     -0.03281734,     -0.03436188,\n",
      "              0.02623796,      0.08710831,     -0.03221207,      0.06011893,      0.02914840,     -0.05684856,     -0.06085458,     -0.03613581,      0.00576996,     -0.02940011,      0.06640390,\n",
      "              0.07087300,      0.04929260,      0.01318032,     -0.00586378,      0.04959748,      0.00660806,      0.00326956,     -0.03995709,     -0.07330821,      0.03976687,     -0.05351669,\n",
      "              0.00975102,      0.06573430,     -0.02739751,     -0.09327186,      0.04945796,     -0.02640924,     -0.04811662,     -0.02023636,      0.06447943,     -0.03439065,      0.01399238,\n",
      "              0.04641354,      0.00337578,      0.02538465,     -0.06651056,     -0.04496680,      0.08389919,      0.01286561,     -0.05759916,     -0.03575669,      0.04870737,     -0.04739233,\n",
      "             -0.03980495,     -0.03625784,     -0.03805088,     -0.08773076,     -0.06959505,     -0.00847897,      0.06059513,      0.07969315,     -0.07081245,     -0.08936933,     -0.06057396,\n",
      "              0.07137258,     -0.01208803,      0.06577872,     -0.03820338,     -0.00926073,      0.03320896,      0.03371768,      0.02749489,      0.02222546,     -0.03850087,     -0.06819285,\n",
      "             -0.03207813,     -0.06575747,      0.05194925,      0.04517645,      0.02427205,     -0.03203686,      0.01011544,      0.03549724,      0.01011581,      0.09121118,      0.05085950,\n",
      "              0.05217327,      0.07686595,     -0.04503366,     -0.05324343,     -0.05853690,     -0.09454813,     -0.06227057,      0.01004671,      0.04691438,     -0.08155393,     -0.07039262,\n",
      "             -0.06269536,      0.04923290,      0.10943376,     -0.09563534,     -0.04455084,      0.04119623,     -0.01810255,      0.05851316,      0.10388673,      0.05619138,     -0.03728972,\n",
      "             -0.01278675,      0.01754150,      0.01679016,     -0.02435895,     -0.00674842,     -0.06429787,      0.03328783,     -0.05609738,      0.10601845,     -0.02594045,      0.00149524,\n",
      "              0.04106181,     -0.05370849,      0.00284640,     -0.05031594,     -0.02407186,      0.06772643,      0.09178524,     -0.02538843,      0.01290048,     -0.02147715,      0.00510707,\n",
      "             -0.01601205,      0.04254687,      0.11457685,      0.07298043,     -0.06978742,     -0.07788447,      0.03534267,      0.03449351,     -0.01572118,      0.04929532,     -0.03750177,\n",
      "             -0.02385611,     -0.02329656,     -0.02781851,     -0.00166891,     -0.04054140,      0.04809561,      0.02998442,     -0.07266622,     -0.02555504,      0.04405427,     -0.03032563,\n",
      "              0.02375165,     -0.00824627,     -0.02347077,     -0.00650778,     -0.04389345,     -0.01901837,     -0.01131402,      0.01689957,     -0.07772235,     -0.02221461,      0.05264404,\n",
      "              0.04042237,     -0.05456491,      0.04826215,     -0.01202584,     -0.03829443,      0.09095759,     -0.08251437,     -0.02401279,      0.03748612,      0.08460327,     -0.06388209,\n",
      "             -0.00170378,      0.04327489,     -0.02785967,      0.04521178,      0.00906492,     -0.06582072,      0.12959681,      0.02732124,     -0.07236381,     -0.05259330,      0.02212605,\n",
      "              0.02882132,      0.07441574,      0.08277621,     -0.05466756,      0.00978205,      0.03124880,     -0.03526704,      0.03662859,      0.07094468,     -0.04028463,      0.01564865,\n",
      "             -0.00978887,     -0.06183670,     -0.08637214,      0.07227731,     -0.06914753,     -0.06059681,      0.01716775,      0.06575122,      0.04593188,      0.05799319]])\n",
      "Export-time input shape: torch.Size([1, 512])\n",
      "Export-time attention shape: torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "[program.cpp:136] InternalConsistency verification requested but not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported to ExecuTorch successfully!\n",
      "Running the Executorch Neural Network program...\n",
      "\n",
      "\n",
      "\n",
      "torch.int64\n",
      "torch.int64\n",
      "torch.Size([1, 512])\n",
      "torch.Size([1, 512])\n",
      "EXECUTORCH: Embedding shape: torch.Size([1, 384])\n",
      "PYTORCH: Embedding: tensor([[    -0.02603655,     -0.04028144,     -0.04070156,     -0.05670594,      0.09808026,     -0.00689320,      0.00147931,      0.04843688,      0.11323297,     -0.02740476,     -0.00866380,\n",
      "              0.00417223,      0.05230611,     -0.04768713,     -0.06603133,      0.08920388,      0.06334060,     -0.05311083,      0.00967993,     -0.10727998,     -0.00384990,     -0.02598385,\n",
      "             -0.00927935,      0.07551410,      0.06361939,      0.01656306,      0.04170506,      0.01730528,      0.01455700,     -0.04344152,     -0.05670435,     -0.04429421,      0.07144874,\n",
      "             -0.03361620,      0.04803943,     -0.00959457,     -0.08393567,     -0.04850760,      0.05855652,     -0.05139390,      0.01839354,      0.05547387,      0.00980076,      0.04608280,\n",
      "              0.02681230,      0.07292694,     -0.06347431,      0.05774028,      0.00521453,     -0.02235043,     -0.04456334,      0.06401616,      0.02014329,      0.04503598,      0.07350690,\n",
      "             -0.04566627,     -0.01399924,     -0.04260229,     -0.08010491,     -0.05667781,      0.06421689,     -0.06622053,     -0.01281167,      0.00306560,      0.06230232,      0.06887282,\n",
      "             -0.02185557,      0.02037256,     -0.06924748,     -0.05492334,     -0.05856651,      0.04827422,      0.02585801,     -0.04206213,      0.07226791,     -0.00066224,      0.02808697,\n",
      "             -0.04768766,     -0.02578074,     -0.03465488,     -0.05184531,     -0.02213819,     -0.02603408,      0.00418788,     -0.04014498,      0.06438645,      0.04306501,     -0.06464734,\n",
      "              0.07835010,     -0.04775865,      0.03871157,     -0.00219346,     -0.02789646,     -0.02316777,     -0.03081978,     -0.05162843,     -0.06317411,      0.06501403,      0.03302045,\n",
      "             -0.03495996,      0.04030043,     -0.00946296,      0.03341749,     -0.06045856,     -0.04164434,      0.05242623,      0.02311893,     -0.08106454,      0.04201820,     -0.07920425,\n",
      "             -0.06128571,      0.01361950,      0.05605035,      0.05132574,     -0.02488027,     -0.00724884,     -0.02829196,     -0.04666111,      0.04885311,     -0.04127708,      0.11957370,\n",
      "             -0.00543753,     -0.06644701,     -0.06156052,     -0.05965440,     -0.03149875,      0.00002126,      0.02896379,     -0.00570551,      0.01163813,      0.05298284,      0.05715987,\n",
      "              0.03742853,      0.07244842,     -0.00867339,      0.07250953,     -0.06899951,     -0.05157419,     -0.02404265,     -0.04570673,     -0.03795755,      0.05116554,     -0.05705471,\n",
      "              0.02825830,      0.11899997,      0.06702529,      0.07962916,      0.01380346,      0.09016921,     -0.06509217,      0.02724548,     -0.01657285,      0.02802209,      0.05316260,\n",
      "              0.03034379,     -0.00838119,     -0.03119651,     -0.03582880,      0.07752744,      0.02368236,     -0.03352492,     -0.08365102,     -0.04563198,     -0.01239438,     -0.04529971,\n",
      "             -0.05366283,     -0.00508507,      0.08052139,     -0.02365419,     -0.05088636,     -0.07034070,      0.04437151,     -0.05328835,      0.06672933,     -0.02946307,      0.04549769,\n",
      "             -0.03047305,      0.10325804,      0.05995302,      0.03321700,     -0.03317446,     -0.01909106,     -0.04186944,     -0.05407612,     -0.03550963,     -0.03281740,     -0.03436187,\n",
      "              0.02623797,      0.08710833,     -0.03221208,      0.06011892,      0.02914842,     -0.05684850,     -0.06085459,     -0.03613586,      0.00576995,     -0.02940014,      0.06640383,\n",
      "              0.07087298,      0.04929261,      0.01318029,     -0.00586372,      0.04959743,      0.00660809,      0.00326954,     -0.03995717,     -0.07330822,      0.03976692,     -0.05351666,\n",
      "              0.00975105,      0.06573434,     -0.02739751,     -0.09327181,      0.04945790,     -0.02640930,     -0.04811662,     -0.02023635,      0.06447937,     -0.03439066,      0.01399237,\n",
      "              0.04641356,      0.00337574,      0.02538462,     -0.06651060,     -0.04496681,      0.08389919,      0.01286562,     -0.05759918,     -0.03575668,      0.04870737,     -0.04739234,\n",
      "             -0.03980498,     -0.03625778,     -0.03805090,     -0.08773074,     -0.06959505,     -0.00847903,      0.06059518,      0.07969318,     -0.07081251,     -0.08936927,     -0.06057404,\n",
      "              0.07137253,     -0.01208803,      0.06577877,     -0.03820334,     -0.00926073,      0.03320889,      0.03371762,      0.02749490,      0.02222539,     -0.03850090,     -0.06819282,\n",
      "             -0.03207814,     -0.06575745,      0.05194927,      0.04517645,      0.02427204,     -0.03203683,      0.01011538,      0.03549727,      0.01011592,      0.09121118,      0.05085949,\n",
      "              0.05217329,      0.07686595,     -0.04503370,     -0.05324344,     -0.05853690,     -0.09454812,     -0.06227055,      0.01004667,      0.04691435,     -0.08155396,     -0.07039274,\n",
      "             -0.06269538,      0.04923290,      0.10943374,     -0.09563537,     -0.04455090,      0.04119625,     -0.01810257,      0.05851313,      0.10388669,      0.05619142,     -0.03728972,\n",
      "             -0.01278686,      0.01754146,      0.01679014,     -0.02435895,     -0.00674843,     -0.06429783,      0.03328785,     -0.05609738,      0.10601845,     -0.02594040,      0.00149525,\n",
      "              0.04106176,     -0.05370849,      0.00284643,     -0.05031587,     -0.02407181,      0.06772646,      0.09178524,     -0.02538849,      0.01290044,     -0.02147721,      0.00510709,\n",
      "             -0.01601206,      0.04254682,      0.11457691,      0.07298043,     -0.06978742,     -0.07788444,      0.03534266,      0.03449349,     -0.01572118,      0.04929535,     -0.03750177,\n",
      "             -0.02385615,     -0.02329656,     -0.02781851,     -0.00166897,     -0.04054138,      0.04809565,      0.02998441,     -0.07266621,     -0.02555502,      0.04405435,     -0.03032566,\n",
      "              0.02375161,     -0.00824628,     -0.02347080,     -0.00650781,     -0.04389345,     -0.01901837,     -0.01131409,      0.01689961,     -0.07772241,     -0.02221467,      0.05264394,\n",
      "              0.04042241,     -0.05456498,      0.04826222,     -0.01202582,     -0.03829447,      0.09095758,     -0.08251435,     -0.02401278,      0.03748618,      0.08460335,     -0.06388205,\n",
      "             -0.00170386,      0.04327490,     -0.02785967,      0.04521181,      0.00906497,     -0.06582076,      0.12959680,      0.02732121,     -0.07236379,     -0.05259328,      0.02212601,\n",
      "              0.02882127,      0.07441571,      0.08277626,     -0.05466751,      0.00978211,      0.03124882,     -0.03526711,      0.03662860,      0.07094471,     -0.04028456,      0.01564859,\n",
      "             -0.00978889,     -0.06183677,     -0.08637217,      0.07227726,     -0.06914748,     -0.06059681,      0.01716773,      0.06575122,      0.04593192,      0.05799321]])\n"
     ]
    }
   ],
   "source": [
    "#EXECUTORCH CONVERSION AND EXECUTION OF CONVERTED MODEL\n",
    "import torch\n",
    "from torch.fx import symbolic_trace\n",
    "import torch.nn as nn\n",
    "import executorch.exir as exir\n",
    "from executorch.extension.pybindings.portable_lib import _load_for_executorch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "torch.set_printoptions(precision=8, sci_mode=False, linewidth=200, threshold=1000)\n",
    "np.set_printoptions(precision=8, suppress=True, linewidth=200, threshold=1000)\n",
    "\n",
    "class E5EmbeddingModel(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super().__init__()\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        token_embeddings = outputs.last_hidden_state\n",
    "        mask = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        sum_embeddings = torch.sum(token_embeddings * mask, dim=1)\n",
    "        sum_mask = mask.sum(dim=1).clamp(min=1e-9)\n",
    "        pooled = sum_embeddings / sum_mask\n",
    "        return torch.nn.functional.normalize(pooled, p=2, dim=1)\n",
    "\n",
    "# Create the complete model\n",
    "complete_model = E5EmbeddingModel('intfloat/multilingual-e5-small')\n",
    "complete_model.eval()\n",
    "\n",
    "\n",
    "input_texts = [\n",
    "    \"passage: As a general guideline, the CDC's average requirement of protein for women ages 19 to 70 is 46 grams per day. But, as you can see from this chart, you'll need to increase that if you're expecting or traini     ng for a marathon. Check out the chart below to see how much protein you should be eating each day.\",    \n",
    "]\n",
    "\n",
    "# 3. Tokenize the text\n",
    "inputs = complete_model.tokenizer(\n",
    "    input_texts,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=512\n",
    ")\n",
    "# tokenizer outputs a dictionary with input_ids and attention_mask\n",
    "print(\"Tokenizer's output:\")\n",
    "for key, value in inputs.items():\n",
    "    print(f\"{key}: {value.shape}\\n\")\n",
    "\n",
    "\n",
    "print (\"Running the Pytorch Embeddings Neural Network program...\")\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(inputs['input_ids'].dtype)         # Should be torch.int64\n",
    "print(inputs['attention_mask'].dtype)    # Should be torch.int64\n",
    "print(inputs['input_ids'].shape)         # e.g., torch.Size([1, 16])\n",
    "print(inputs['attention_mask'].shape)    # Same\n",
    "\n",
    "# 4. Generate embedding\n",
    "with torch.no_grad():\n",
    "    embedding = complete_model(inputs[\"input_ids\"], inputs[\"attention_mask\"])\n",
    "\n",
    "\n",
    "# 5. Print or use the embedding\n",
    "print(\"PYTORCH: Embedding shape:\", embedding.shape)  # shape: (1, hidden_size)\n",
    "print(\"PYTORCH: Embedding:\", embedding)\n",
    "\n",
    "print(\"Export-time input shape:\", inputs['input_ids'].shape)\n",
    "print(\"Export-time attention shape:\", inputs['attention_mask'].shape)\n",
    "#Export to ExecuTorch\n",
    "with torch.no_grad():\n",
    "    exported_program = torch.export.export(\n",
    "        complete_model,\n",
    "        (inputs['input_ids'], inputs['attention_mask'])\n",
    "    )\n",
    "\n",
    "# Print the exported program's graph\n",
    "# print(\"Exported Program Graph:\")\n",
    "# print(exported_program.graph_module.graph)\n",
    "\n",
    "edge_program = exir.to_edge(exported_program)\n",
    "executorch_program = edge_program.to_executorch()\n",
    "\n",
    "\n",
    "with open(\"e5_complete.pte\", \"wb\") as f:\n",
    "     executorch_program.write_to_file(f)\n",
    "\n",
    "\n",
    "print (\"Exported to ExecuTorch successfully!\")\n",
    "print (\"Running the Executorch Neural Network program...\")\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(inputs['input_ids'].dtype)         # Should be torch.int64\n",
    "print(inputs['attention_mask'].dtype)    # Should be torch.int64\n",
    "print(inputs['input_ids'].shape)         # e.g., torch.Size([1, 16])\n",
    "print(inputs['attention_mask'].shape)    # Same\n",
    "\n",
    "\n",
    "\n",
    "# Load model\n",
    "model = _load_for_executorch(\"e5_complete.pte\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    embedding_et = model.forward((inputs['input_ids'], inputs['attention_mask']))[0]  # typically returns a tuple\n",
    "# 5. Print or use the embedding\n",
    "print(\"EXECUTORCH: Embedding shape:\", embedding_et.shape)  # shape: (1, hidden_size)\n",
    "print(\"PYTORCH: Embedding:\", embedding_et)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UTILITY TO CHECK IF THE MODEL CAN BE CONVERTED TO EXECUTORCH\n",
    "import torch\n",
    "from torch.fx import symbolic_trace\n",
    "import torch.nn as nn\n",
    "import executorch.exir as exir\n",
    "from executorch.extension.pybindings.portable_lib import _load_for_executorch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import sys \n",
    "class E5EmbeddingModel(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super().__init__()\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        token_embeddings = outputs.last_hidden_state\n",
    "        mask = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        sum_embeddings = torch.sum(token_embeddings * mask, dim=1)\n",
    "        sum_mask = mask.sum(dim=1).clamp(min=1e-9)\n",
    "        pooled = sum_embeddings / sum_mask\n",
    "        return torch.nn.functional.normalize(pooled, p=2, dim=1)\n",
    "\n",
    "# Create the complete model\n",
    "complete_model = E5EmbeddingModel('intfloat/multilingual-e5-small')\n",
    "complete_model.eval()\n",
    "\n",
    "input_texts = [\n",
    "    \"passage: test text for analysis\",    \n",
    "]\n",
    "\n",
    "# Tokenize the text\n",
    "inputs = complete_model.tokenizer(\n",
    "    input_texts,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=512\n",
    ")\n",
    "\n",
    "print(\"=== ANALYZING OPERATORS NEEDED ===\")\n",
    "\n",
    "# Export to ExecuTorch and analyze operators\n",
    "with torch.no_grad():\n",
    "    exported_program = torch.export.export(\n",
    "        complete_model,\n",
    "        (inputs['input_ids'], inputs['attention_mask'])\n",
    "    )\n",
    "\n",
    "print(\"\\n=== ALL EXPORTED PROGRAM OPERATORS ===\")\n",
    "# Print all operators used in the exported program\n",
    "ops_used = set()\n",
    "for node in exported_program.graph_module.graph.nodes:\n",
    "    if node.op == 'call_function':\n",
    "        ops_used.add(str(node.target))\n",
    "\n",
    "# Sort and print all operators\n",
    "sorted_ops = sorted(list(ops_used))\n",
    "for i, op in enumerate(sorted_ops, 1):\n",
    "    print(f\"{i:2d}. {op}\")\n",
    "\n",
    "print(f\"\\nTotal unique operators: {len(ops_used)}\")\n",
    "\n",
    "print(\"\\n=== CONVERTING TO EDGE ===\")\n",
    "edge_program = exir.to_edge(exported_program)\n",
    "\n",
    "print(\"\\n=== ALL EDGE PROGRAM OPERATORS ===\")\n",
    "# Print operators in edge program\n",
    "edge_ops_used = set()\n",
    "for node in edge_program.exported_program().graph_module.graph.nodes:\n",
    "    if node.op == 'call_function':\n",
    "        edge_ops_used.add(str(node.target))\n",
    "\n",
    "# Sort and print all edge operators\n",
    "sorted_edge_ops = sorted(list(edge_ops_used))\n",
    "for i, op in enumerate(sorted_edge_ops, 1):\n",
    "    print(f\"{i:2d}. {op}\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "print(f\"\\nTotal unique edge operators: {len(edge_ops_used)}\")\n",
    "\n",
    "print(\"\\n=== CHECKING FOR PROBLEMATIC OPERATORS ===\")\n",
    "# Check for operators that might not be supported in portable kernels\n",
    "problematic_ops = [\n",
    "    'aten.scaled_dot_product_attention',\n",
    "    'aten.gelu', \n",
    "    'aten.silu',\n",
    "    'aten.baddbmm',\n",
    "    'aten._native_batch_norm_legit',\n",
    "    'aten.native_batch_norm',\n",
    "    'aten.group_norm',\n",
    "    'aten.instance_norm'\n",
    "]\n",
    "\n",
    "found_problematic = []\n",
    "for op in sorted_edge_ops:\n",
    "    for prob_op in problematic_ops:\n",
    "        if prob_op in op:\n",
    "            found_problematic.append(op)\n",
    "\n",
    "if found_problematic:\n",
    "    print(\"Found potentially problematic operators:\")\n",
    "    for op in found_problematic:\n",
    "        print(f\"  - {op}\")\n",
    "else:\n",
    "    print(\"No obviously problematic operators found\")\n",
    "\n",
    "print(\"\\n=== CONVERTING TO EXECUTORCH ===\")\n",
    "try:\n",
    "    executorch_program = edge_program.to_executorch()\n",
    "    print(\"SUCCESS: Model converted to ExecuTorch\")\n",
    "    \n",
    "    # Try to save and load\n",
    "    with open(\"analysis_test.pte\", \"wb\") as f:\n",
    "        executorch_program.write_to_file(f)\n",
    "    \n",
    "    print(\"SUCCESS: Model saved to file\")\n",
    "    \n",
    "    # Try to load with ExecuTorch\n",
    "    try:\n",
    "        model = _load_for_executorch(\"analysis_test.pte\")\n",
    "        print(\"SUCCESS: Model loaded in ExecuTorch runtime\")\n",
    "        \n",
    "        # Try to run\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                result = model.forward((inputs['input_ids'], inputs['attention_mask']))\n",
    "            print(\"SUCCESS: Model executed successfully\")\n",
    "            print(f\"Output shape: {result[0].shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"FAILED: Model execution failed: {e}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"FAILED: Model loading failed: {e}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"FAILED: to_executorch() failed: {e}\")\n",
    "\n",
    "print(\"\\n=== ANALYSIS COMPLETE ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UTILITY TO CHECK THE SUPPORTED OPERATORS IN THE EXECUTORCH LIBRARIES\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Check what operators are available in Apple prebuilt ExecuTorch libraries\n",
    "\"\"\"\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import sys\n",
    "\n",
    "def run_command(cmd):\n",
    "    \"\"\"Run a shell command and return output\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "        return result.stdout, result.stderr, result.returncode\n",
    "    except Exception as e:\n",
    "        return \"\", str(e), 1\n",
    "\n",
    "def check_library_exists(lib_path):\n",
    "    \"\"\"Check if library file exists\"\"\"\n",
    "    return os.path.exists(lib_path)\n",
    "\n",
    "def analyze_library_symbols(lib_path, lib_name):\n",
    "    \"\"\"Analyze symbols in a library file\"\"\"\n",
    "    print(f\"\\n=== ANALYZING {lib_name} ===\")\n",
    "    print(f\"Path: {lib_path}\")\n",
    "    \n",
    "    if not check_library_exists(lib_path):\n",
    "        print(f\"‚ùå Library not found: {lib_path}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"‚úÖ Library found\")\n",
    "    \n",
    "    # Get file info\n",
    "    stdout, stderr, code = run_command(f\"file '{lib_path}'\")\n",
    "    if code == 0:\n",
    "        print(f\"File type: {stdout.strip()}\")\n",
    "    \n",
    "    # Get total symbol count\n",
    "    stdout, stderr, code = run_command(f\"nm '{lib_path}' 2>/dev/null | wc -l\")\n",
    "    if code == 0:\n",
    "        print(f\"Total symbols: {stdout.strip()}\")\n",
    "    \n",
    "    # Check for specific operators we need\n",
    "    operators_to_check = [\n",
    "        'gelu',\n",
    "        'layer_norm', \n",
    "        'bmm',\n",
    "        'softmax',\n",
    "        'addmm',\n",
    "        'embedding'\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nChecking for required operators:\")\n",
    "    found_operators = []\n",
    "    \n",
    "    for op in operators_to_check:\n",
    "        stdout, stderr, code = run_command(f\"nm '{lib_path}' 2>/dev/null | grep -i '{op}'\")\n",
    "        if stdout.strip():\n",
    "            found_operators.append(op)\n",
    "            print(f\"  ‚úÖ {op}: FOUND\")\n",
    "            # Show first few matches\n",
    "            lines = stdout.strip().split('\\n')[:3]\n",
    "            for line in lines:\n",
    "                print(f\"    {line}\")\n",
    "        else:\n",
    "            print(f\"  ‚ùå {op}: NOT FOUND\")\n",
    "    \n",
    "    # Check for aten namespace symbols\n",
    "    stdout, stderr, code = run_command(f\"nm '{lib_path}' 2>/dev/null | grep 'aten::' | head -5\")\n",
    "    if stdout.strip():\n",
    "        print(f\"\\nSample aten:: symbols found:\")\n",
    "        for line in stdout.strip().split('\\n'):\n",
    "            print(f\"  {line}\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå No aten:: symbols found\")\n",
    "    \n",
    "    # List object files in the archive\n",
    "    stdout, stderr, code = run_command(f\"ar -t '{lib_path}' | head -10\")\n",
    "    if code == 0 and stdout.strip():\n",
    "        print(f\"\\nSample object files in archive:\")\n",
    "        for line in stdout.strip().split('\\n'):\n",
    "            print(f\"  {line}\")\n",
    "    \n",
    "    return found_operators\n",
    "\n",
    "def check_specific_operators():\n",
    "    \"\"\"Check for the exact operators your model needs\"\"\"\n",
    "    required_ops = [\n",
    "        \"aten.gelu.default\",\n",
    "        \"aten.native_layer_norm.default\", \n",
    "        \"aten.bmm.default\",\n",
    "        \"aten._softmax.default\",\n",
    "        \"aten.addmm.default\",\n",
    "        \"aten.embedding.default\",\n",
    "        \"dim_order_ops._to_dim_order_copy.default\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"OPERATORS REQUIRED BY YOUR MODEL:\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for i, op in enumerate(required_ops, 1):\n",
    "        print(f\"{i:2d}. {op}\")\n",
    "    \n",
    "    return required_ops\n",
    "\n",
    "def main():\n",
    "    print(\"üîç EXECUTORCH APPLE LIBRARY ANALYZER\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Define library paths\n",
    "    libraries = {\n",
    "        \"ExecuTorch Main\": \"../../corecpp/third_party/prebuilt/executorch/apple/executorch.xcframework/macos-arm64/libexecutorch_macos.a\",\n",
    "        \"Portable Kernels\": \"../../corecpp/third_party/prebuilt/executorch/apple/kernels_portable.xcframework/macos-arm64/libkernels_portable_macos.a\", \n",
    "        \"Optimized Kernels\": \"../../corecpp/third_party/prebuilt/executorch/apple/kernels_optimized.xcframework/macos-arm64/libkernels_optimized_macos.a\"\n",
    "    }\n",
    "    \n",
    "    all_found_operators = []\n",
    "    \n",
    "    # Analyze each library\n",
    "    for lib_name, lib_path in libraries.items():\n",
    "        found_ops = analyze_library_symbols(lib_path, lib_name)\n",
    "        if found_ops:\n",
    "            all_found_operators.extend(found_ops)\n",
    "    \n",
    "    # Show required operators\n",
    "    required_ops = check_specific_operators()\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"SUMMARY:\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    unique_found = list(set(all_found_operators))\n",
    "    print(f\"‚úÖ Found operator types: {len(unique_found)}\")\n",
    "    for op in unique_found:\n",
    "        print(f\"   - {op}\")\n",
    "    \n",
    "    print(f\"\\n‚ùì Required operator types: {len(required_ops)}\")\n",
    "    \n",
    "    # Check coverage\n",
    "    missing_ops = []\n",
    "    for req_op in required_ops:\n",
    "        found = False\n",
    "        for found_op in unique_found:\n",
    "            if found_op.lower() in req_op.lower():\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            missing_ops.append(req_op)\n",
    "    \n",
    "    if missing_ops:\n",
    "        print(f\"\\n‚ùå LIKELY MISSING OPERATORS:\")\n",
    "        for op in missing_ops:\n",
    "            print(f\"   - {op}\")\n",
    "        print(f\"\\nüí° RECOMMENDATION: Build ExecuTorch from source to get full operator support\")\n",
    "    else:\n",
    "        print(f\"\\n‚úÖ All required operator types appear to be available!\")\n",
    "        print(f\"üí° The error might be due to a different issue (memory, model format, etc.)\")\n",
    "    \n",
    "    # Additional checks\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ADDITIONAL DIAGNOSTICS:\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Check if nm command is available\n",
    "    stdout, stderr, code = run_command(\"which nm\")\n",
    "    if code != 0:\n",
    "        print(\"‚ùå 'nm' command not found. Install Xcode Command Line Tools:\")\n",
    "        print(\"   xcode-select --install\")\n",
    "    else:\n",
    "        print(\"‚úÖ 'nm' command available\")\n",
    "    \n",
    "    # Check if ar command is available  \n",
    "    stdout, stderr, code = run_command(\"which ar\")\n",
    "    if code != 0:\n",
    "        print(\"‚ùå 'ar' command not found\")\n",
    "    else:\n",
    "        print(\"‚úÖ 'ar' command available\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UTILITY TO CHECK THE EXECUTORCH VERSION AND BUILD DETAILS\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Check ExecuTorch version and build details\n",
    "\"\"\"\n",
    "\n",
    "import executorch\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "print(\"=== EXECUTORCH VERSION INFORMATION ===\")\n",
    "\n",
    "# Check ExecuTorch version\n",
    "try:\n",
    "    print(f\"ExecuTorch version: {executorch.__version__}\")\n",
    "except AttributeError:\n",
    "    print(\"ExecuTorch version: Unknown (no __version__ attribute)\")\n",
    "\n",
    "# Check if we can import key modules\n",
    "try:\n",
    "    from executorch.exir import to_edge\n",
    "    print(\"‚úÖ executorch.exir module available\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå executorch.exir import failed: {e}\")\n",
    "\n",
    "try:\n",
    "    from executorch.extension.pybindings.portable_lib import _load_for_executorch\n",
    "    print(\"‚úÖ executorch.extension.pybindings.portable_lib available\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå portable_lib import failed: {e}\")\n",
    "\n",
    "# Check PyTorch version\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Check installation path\n",
    "print(f\"ExecuTorch installed at: {executorch.__file__}\")\n",
    "\n",
    "# Try to get git commit if available\n",
    "try:\n",
    "    import subprocess\n",
    "    import os\n",
    "    \n",
    "    # Check if we're in a git repo\n",
    "    executorch_path = os.path.dirname(executorch.__file__)\n",
    "    result = subprocess.run(['git', 'rev-parse', 'HEAD'], \n",
    "                          cwd=executorch_path, \n",
    "                          capture_output=True, \n",
    "                          text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(f\"Git commit: {result.stdout.strip()}\")\n",
    "    else:\n",
    "        print(\"Not in a git repository or git not available\")\n",
    "except:\n",
    "    print(\"Could not determine git commit\")\n",
    "\n",
    "print(\"\\n=== SOURCE CODE VERSION ===\")\n",
    "# Check the source code version\n",
    "try:\n",
    "    source_path = \"../../corecpp/third_party/executorch\"\n",
    "    result = subprocess.run(['git', 'rev-parse', 'HEAD'], \n",
    "                          cwd=source_path, \n",
    "                          capture_output=True, \n",
    "                          text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(f\"Source git commit: {result.stdout.strip()}\")\n",
    "        \n",
    "        # Check if it's on branch 0.6.0\n",
    "        result = subprocess.run(['git', 'branch', '--show-current'], \n",
    "                              cwd=source_path, \n",
    "                              capture_output=True, \n",
    "                              text=True)\n",
    "        if result.returncode == 0:\n",
    "            print(f\"Source branch: {result.stdout.strip()}\")\n",
    "    else:\n",
    "        print(\"Source: Not in a git repository\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not check source version: {e}\")\n",
    "\n",
    "print(\"\\n=== TESTING BASIC EXPORT ===\")\n",
    "# Try a simple export to see if it works\n",
    "try:\n",
    "    import torch\n",
    "    from executorch.exir import to_edge\n",
    "    \n",
    "    class SimpleModel(torch.nn.Module):\n",
    "        def forward(self, x, y):\n",
    "            return x + y\n",
    "    \n",
    "    model = SimpleModel()\n",
    "    example_inputs = (torch.ones(2, 2), torch.ones(2, 2))\n",
    "    \n",
    "    # Export\n",
    "    exported_program = torch.export.export(model, example_inputs)\n",
    "    edge_program = to_edge(exported_program)\n",
    "    executorch_program = edge_program.to_executorch()\n",
    "    \n",
    "    # Save test model\n",
    "    with open(\"version_test.pte\", \"wb\") as f:\n",
    "        executorch_program.write_to_file(f)\n",
    "    \n",
    "    print(\"‚úÖ Simple export successful - created version_test.pte\")\n",
    "    \n",
    "    # Try to load it\n",
    "    from executorch.extension.pybindings.portable_lib import _load_for_executorch\n",
    "    test_model = _load_for_executorch(\"version_test.pte\")\n",
    "    result = test_model.forward(example_inputs)\n",
    "    print(\"‚úÖ Python runtime execution successful\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Export/execution failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (executorch_conversion_venv)",
   "language": "python",
   "name": "executorch_conversion_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
